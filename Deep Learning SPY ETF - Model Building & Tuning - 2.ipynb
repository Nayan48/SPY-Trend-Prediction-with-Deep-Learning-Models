{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f84928",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf0c70d",
   "metadata": {},
   "source": [
    "### Content of this notebook: \n",
    "\n",
    "### Step 5) Data Handling\n",
    "   - This step involves the necessary preprocessing steps to prepare the data for input into the LSTM models. It includes:\n",
    "\n",
    "     - **Proper Data Handling:** Ensuring that all missing values are dealt with and the dataset is clean and ready for analysis.\n",
    "     - **Train-Test Split:** The data is divided into training and testing sets. The training set will be used to train the models, while the testing set will be used to evaluate the models' performance.\n",
    "     - **Scaling (Min-Max):**  Scaling the features to a range [0, 1] using MinMaxScaler to ensure that the LSTM model, which is sensitive to the scale of the data, can perform optimally.\n",
    "     - **Reshaping to 3D as LSTM Input Requires:** Since LSTMs expect 3D input in the form of [samples, timesteps, features], the data is reshaped accordingly to meet these requirements.\n",
    "     - **Defining Lookback Length:** The lookback length determines how many previous time steps are used to predict the next value. It is a crucial parameter in sequence data.\n",
    "     - **Sequence Data Generation Using Time Series Generator:** The TimeseriesGenerator is used to generate sequences of data along with their corresponding labels, which the LSTM models will use for training.\n",
    "\n",
    "### Step 6) Model Building & Hyperparameter Optimization\n",
    "  - This step outlines the process of building various deep learning models to predict SPY ETF trends and optimizing their performance.\n",
    "\n",
    "     - **Model Building:**\n",
    "         - Several models are constructed, including:\n",
    "            - **Base LSTM:** A simple LSTM model with a single LSTM layer.\n",
    "            - **LSTM with 2 layers:** This model includes two LSTM layers stacked together.\n",
    "            - **LSTM with 5 layers:** A deeper model with five LSTM layers.\n",
    "            - **GRU:** A model using Gated Recurrent Units (GRU), which is an alternative to LSTM.\n",
    "            - **LSTM combined with CNN:** A hybrid model that combines LSTM layers with Convolutional Neural Network (CNN) layers.\n",
    "\n",
    "     - **Hyperparameter Tuning:**\n",
    "        - For each model, hyperparameters like the number of units in LSTM/GRU layers, dropout rates, learning rates, and CNN filter sizes are optimized using **RandomSearch.**\n",
    "           - **Early Stopping:** This is used to prevent the model from overfitting by stopping the training process once the performance on the validation set stops improving.\n",
    "           - **TensorBoard Integration:** TensorBoard is integrated to visualize the training process, including the loss and accuracy over epochs.\n",
    "           \n",
    "           \n",
    "### Step 7) Model Evaluation\n",
    "    \n",
    "**Evaluation Metrics and Trading Strategy Backtesting**\n",
    "\n",
    "   - After building and optimizing the LSTM models, we evaluate the performance of the model with Evaluatioon Metrics and by simulating a trading strategy based on the LSTM model’s signals. This is done by backtesting the strategy on the test period from April 2023 to June 2024.\n",
    "\n",
    "\n",
    "- **7.1) Evaluation Metrics:**\n",
    "  - Before implementing the trading strategy backtest, we evaluated the LSTM models' performance using various classification metrics. These included:\n",
    "\n",
    "    - **Accuracy:** Measures the percentage of correct predictions made by the model.\n",
    "    - **F1 Score:** Provides a balance between precision and recall, offering a single metric to evaluate the model’s overall performance.\n",
    "    - **Precision:** Indicates the ratio of correctly predicted positive observations to the total predicted positives.\n",
    "    - **Recall:** Reflects the ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "    - **AUC and ROC:** Used to measure the model’s ability to distinguish between classes.\n",
    "    - **Confusion Matrix:** Provides insight into the true positive, true negative, false positive, and false negative predictions.\n",
    "    - **Balanced Accuracy:** Adjusts accuracy for any imbalanced classes, ensuring a more reliable evaluation.\n",
    "- **These metrics were crucial in selecting the best model, which was then used for backtesting the trading strategy.**\n",
    "\n",
    "### Please note that Complete Trading Strategy and Backtest part of the project is in Notebook-3 (CQF-DL-Trading-Backtest) ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b603b24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4fd49e",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229325dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is 2.17.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "# Check TensorFlow version\n",
    "print(\"TensorFlow version is\", tf.version.VERSION)\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.CRITICAL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "01992590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Base libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pydot\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "# Scikit-learn modules\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# TensorFlow and Keras modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten, GRU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.metrics import Metric, BinaryAccuracy, Precision, Recall, AUC, TruePositives, TrueNegatives, FalsePositives, FalseNegatives\n",
    "\n",
    "\n",
    "# Plotting & outputs\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "from pprint import pprint\n",
    "\n",
    "# Keras Tuner for hyperparameter optimization\n",
    "import keras_tuner as kt\n",
    "\n",
    "# QuantStats for backtesting report\n",
    "import quantstats as qs\n",
    "\n",
    "# Alphavantage for fetching data\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199cf1b8",
   "metadata": {},
   "source": [
    "#### Loading TensorBoard Extension\n",
    "\n",
    "- **TensorBoard Integration:** TensorBoard is a powerful visualization tool designed to help in monitoring and debugging deep learning models during training. By loading this extension, you can launch TensorBoard directly within the notebook, allowing you to visualize metrics such as loss, accuracy, and other relevant statistics in real-time as your models train.\n",
    "\n",
    "- **Real-Time Monitoring:** This integration provides a convenient way to track model performance, monitor the effects of hyperparameter tuning, and detect issues like overfitting during the training process. By visualizing metrics in real time, you can make informed decisions about when to stop training or when to adjust parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa7e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21b0c3",
   "metadata": {},
   "source": [
    "### Step 5) Data Handling\n",
    "- This step involves the necessary preprocessing steps to prepare the data for input into the LSTM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8372e65",
   "metadata": {},
   "source": [
    "- **5.1) Loading the Dataset:** Loading the dataset SPY_Final_Features_Dataset.csv into a pandas DataFrame named df.      This dataset contains the final set of 24 features that were selected after performing feature engineering and selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb646c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>yield_spread</th>\n",
       "      <th>VXX_daily_return</th>\n",
       "      <th>UUP_daily_return</th>\n",
       "      <th>volume_tech</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>AOBV_SR_2</th>\n",
       "      <th>...</th>\n",
       "      <th>PDIST</th>\n",
       "      <th>PIVOTS_TRAD_D_P</th>\n",
       "      <th>PIVOTS_TRAD_D_R3</th>\n",
       "      <th>PSL_12</th>\n",
       "      <th>PVOL</th>\n",
       "      <th>PVT</th>\n",
       "      <th>SLOPE_1</th>\n",
       "      <th>SMCtp_14_50_20_5</th>\n",
       "      <th>STDEV_30</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>54427600.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.442760e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.321339e+10</td>\n",
       "      <td>3.855400e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.203386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>-0.009144</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.051123</td>\n",
       "      <td>-0.004416</td>\n",
       "      <td>65400800.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.097320e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.920015</td>\n",
       "      <td>242.493332</td>\n",
       "      <td>245.113328</td>\n",
       "      <td>99.085554</td>\n",
       "      <td>1.573216e+10</td>\n",
       "      <td>-5.980551e+07</td>\n",
       "      <td>-2.220001</td>\n",
       "      <td>-7.203386</td>\n",
       "      <td>1.360001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-0.036109</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>56062000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.508880e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.200012</td>\n",
       "      <td>240.973333</td>\n",
       "      <td>244.353339</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.357317e+10</td>\n",
       "      <td>-2.344858e+07</td>\n",
       "      <td>1.559998</td>\n",
       "      <td>-7.203386</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.024465</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>36663274.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.175207e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820001</td>\n",
       "      <td>241.649999</td>\n",
       "      <td>245.090001</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>8.886078e+09</td>\n",
       "      <td>-1.951135e+07</td>\n",
       "      <td>0.259999</td>\n",
       "      <td>-7.203386</td>\n",
       "      <td>1.200002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>-0.003622</td>\n",
       "      <td>50290920.0</td>\n",
       "      <td>2.419980e+02</td>\n",
       "      <td>241.998002</td>\n",
       "      <td>3.146115e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>242.310000</td>\n",
       "      <td>244.390000</td>\n",
       "      <td>99.925733</td>\n",
       "      <td>1.217996e+10</td>\n",
       "      <td>-2.324629e+07</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>-7.203386</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.007972</td>\n",
       "      <td>-0.003436</td>\n",
       "      <td>45528654.0</td>\n",
       "      <td>3.742017e+07</td>\n",
       "      <td>26.137312</td>\n",
       "      <td>1.641817e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>544.393333</td>\n",
       "      <td>549.653333</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>2.471022e+10</td>\n",
       "      <td>-1.149704e+10</td>\n",
       "      <td>-1.770000</td>\n",
       "      <td>-7.034976</td>\n",
       "      <td>7.967939</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>38273346.0</td>\n",
       "      <td>3.392215e+07</td>\n",
       "      <td>26.493766</td>\n",
       "      <td>1.680090e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.930000</td>\n",
       "      <td>544.103333</td>\n",
       "      <td>552.763333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2.085247e+10</td>\n",
       "      <td>-1.148231e+10</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>-10.189487</td>\n",
       "      <td>7.897289</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.010909</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>38550637.0</td>\n",
       "      <td>3.609444e+07</td>\n",
       "      <td>27.023626</td>\n",
       "      <td>1.718641e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.740000</td>\n",
       "      <td>544.156667</td>\n",
       "      <td>549.676667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.102976e+10</td>\n",
       "      <td>-1.147750e+10</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>-20.033204</td>\n",
       "      <td>7.778476</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>35041480.0</td>\n",
       "      <td>3.925285e+07</td>\n",
       "      <td>27.653751</td>\n",
       "      <td>1.753682e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>544.926667</td>\n",
       "      <td>551.346667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.914561e+10</td>\n",
       "      <td>-1.147197e+10</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>-25.013835</td>\n",
       "      <td>7.748247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>-0.003935</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76144535.0</td>\n",
       "      <td>2.114413e+07</td>\n",
       "      <td>28.820181</td>\n",
       "      <td>1.677537e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.510000</td>\n",
       "      <td>545.980000</td>\n",
       "      <td>550.680000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>4.143938e+10</td>\n",
       "      <td>-1.150193e+10</td>\n",
       "      <td>-2.150000</td>\n",
       "      <td>-39.769611</td>\n",
       "      <td>7.824571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1746 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  daily_return  yield_spread  VXX_daily_return  \\\n",
       "0    2017-07-05      0.002312          0.92          0.000775   \n",
       "1    2017-07-06     -0.009144          0.97          0.051123   \n",
       "2    2017-07-07      0.006485          0.99         -0.036109   \n",
       "3    2017-07-10      0.001074          0.98         -0.024465   \n",
       "4    2017-07-11     -0.000743          1.00         -0.003918   \n",
       "...         ...           ...           ...               ...   \n",
       "1741 2024-06-24     -0.003251         -0.46         -0.007972   \n",
       "1742 2024-06-25      0.003851         -0.42         -0.017857   \n",
       "1743 2024-06-26      0.001248         -0.39         -0.010909   \n",
       "1744 2024-06-27      0.001577         -0.41         -0.006434   \n",
       "1745 2024-06-28     -0.003935         -0.35          0.010176   \n",
       "\n",
       "      UUP_daily_return  volume_tech    ADOSC_3_10      ADX_14           OBV  \\\n",
       "0             0.000402   54427600.0  0.000000e+00    0.000000  5.442760e+07   \n",
       "1            -0.004416   65400800.0  0.000000e+00    0.000000 -1.097320e+07   \n",
       "2             0.001613   56062000.0  0.000000e+00    0.000000  4.508880e+07   \n",
       "3             0.000403   36663274.0  0.000000e+00    0.000000  8.175207e+07   \n",
       "4            -0.003622   50290920.0  2.419980e+02  241.998002  3.146115e+07   \n",
       "...                ...          ...           ...         ...           ...   \n",
       "1741         -0.003436   45528654.0  3.742017e+07   26.137312  1.641817e+09   \n",
       "1742          0.001034   38273346.0  3.392215e+07   26.493766  1.680090e+09   \n",
       "1743          0.004823   38550637.0  3.609444e+07   27.023626  1.718641e+09   \n",
       "1744         -0.001371   35041480.0  3.925285e+07   27.653751  1.753682e+09   \n",
       "1745          0.000000   76144535.0  2.114413e+07   28.820181  1.677537e+09   \n",
       "\n",
       "      AOBV_SR_2  ...      PDIST  PIVOTS_TRAD_D_P  PIVOTS_TRAD_D_R3  \\\n",
       "0           0.0  ...   0.020000         0.020000          0.020000   \n",
       "1           0.0  ...   2.920015       242.493332        245.113328   \n",
       "2           0.0  ...   3.200012       240.973333        244.353339   \n",
       "3           0.0  ...   1.820001       241.649999        245.090001   \n",
       "4           0.0  ...   3.580000       242.310000        244.390000   \n",
       "...         ...  ...        ...              ...               ...   \n",
       "1741        1.0  ...   7.250000       544.393333        549.653333   \n",
       "1742        1.0  ...   5.930000       544.103333        552.763333   \n",
       "1743        0.0  ...   5.740000       544.156667        549.676667   \n",
       "1744        0.0  ...   3.840000       544.926667        551.346667   \n",
       "1745        0.0  ...  12.510000       545.980000        550.680000   \n",
       "\n",
       "          PSL_12          PVOL           PVT   SLOPE_1  SMCtp_14_50_20_5  \\\n",
       "0     100.000000  1.321339e+10  3.855400e+00  0.000000         -7.203386   \n",
       "1      99.085554  1.573216e+10 -5.980551e+07 -2.220001         -7.203386   \n",
       "2     100.000000  1.357317e+10 -2.344858e+07  1.559998         -7.203386   \n",
       "3     100.000000  8.886078e+09 -1.951135e+07  0.259999         -7.203386   \n",
       "4      99.925733  1.217996e+10 -2.324629e+07 -0.180000         -7.203386   \n",
       "...          ...           ...           ...       ...               ...   \n",
       "1741   58.333333  2.471022e+10 -1.149704e+10 -1.770000         -7.034976   \n",
       "1742   66.666667  2.085247e+10 -1.148231e+10  2.090000        -10.189487   \n",
       "1743   75.000000  2.102976e+10 -1.147750e+10  0.680000        -20.033204   \n",
       "1744   75.000000  1.914561e+10 -1.147197e+10  0.860000        -25.013835   \n",
       "1745   66.666667  4.143938e+10 -1.150193e+10 -2.150000        -39.769611   \n",
       "\n",
       "      STDEV_30  Target  \n",
       "0     0.000000     1.0  \n",
       "1     1.360001     0.0  \n",
       "2     0.250000     1.0  \n",
       "3     1.200002     0.0  \n",
       "4     0.910000     0.0  \n",
       "...        ...     ...  \n",
       "1741  7.967939     0.0  \n",
       "1742  7.897289     1.0  \n",
       "1743  7.778476     0.0  \n",
       "1744  7.748247     0.0  \n",
       "1745  7.824571     0.0  \n",
       "\n",
       "[1746 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('SPY_Final_Features_Dataset.csv')\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df8c702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                datetime64[ns]\n",
       "daily_return               float64\n",
       "yield_spread               float64\n",
       "VXX_daily_return           float64\n",
       "UUP_daily_return           float64\n",
       "volume_tech                float64\n",
       "ADOSC_3_10                 float64\n",
       "ADX_14                     float64\n",
       "OBV                        float64\n",
       "AOBV_SR_2                  float64\n",
       "BBP_5_2.0                  float64\n",
       "BOP                        float64\n",
       "CCI_14_0.015               float64\n",
       "DEC_1                      float64\n",
       "BULLP_13                   float64\n",
       "KVO_34_55_13               float64\n",
       "PDIST                      float64\n",
       "PIVOTS_TRAD_D_P            float64\n",
       "PIVOTS_TRAD_D_R3           float64\n",
       "PSL_12                     float64\n",
       "PVOL                       float64\n",
       "PVT                        float64\n",
       "SLOPE_1                    float64\n",
       "SMCtp_14_50_20_5           float64\n",
       "STDEV_30                   float64\n",
       "Target                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb7792",
   "metadata": {},
   "source": [
    " - **Data Type Consistency:** Ensuring that all features are in float64 format guarantees that the data is ready for numerical computations, particularly important for machine learning algorithms that expect numerical input.\n",
    " - **Time-Series Operations:** The correct conversion of the 'date' column allows for more sophisticated time-based analyses, such as creating time lags, generating sequences for LSTM, and ensuring that the model training respects the temporal order of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4e695",
   "metadata": {},
   "source": [
    "#### 5.2) Setting the Target Variable\n",
    "\n",
    "-  the target variable is defined as whether the S\\&P 500 ETF (SPY) will experience a significant positive return based on a threshold of 0.20% in its daily return. If the daily return exceeds this threshold, the label is set to +1 (indicating a buy signal). Otherwise, it is set to 0. The target can be mathematically described as:\n",
    "\n",
    "$$\n",
    "y_t = \n",
    "\\begin{cases} \n",
    "+1, & \\text{if } r_t > 0.002 \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- where \\( r_t \\) is the daily return of the SPY ETF on day \\( t \\), calculated as:\n",
    "\n",
    "$$\n",
    "r_t = \\frac{P_t - P_{t-1}}{P_{t-1}}\n",
    "$$\n",
    "\n",
    "- Here, $( P_t )$ is the closing price of SPY on day $( t )$, and $( P_{t-1}) $ is the closing price on the previous trading day.\n",
    "\n",
    "- The target variable $( y_t )$ is then used in the model to predict whether the SPY ETF's price will increase significantly based on the defined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9276274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target variable\n",
    "y = df['Target'].values\n",
    "X = df.drop(columns=['Target', 'date']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f007b07e",
   "metadata": {},
   "source": [
    "- **Defining Input and Output:** This step clearly separates the inputs (features) and the output (target variable), which is essential for training machine learning models. By excluding the 'date' column, which is not a feature used for prediction, and focusing on the numerical features, you ensure that the model is trained on the correct data.\n",
    "\n",
    "- **Model Training Preparation:** With X containing the features and y containing the target variable, the data is now ready to be split into training and testing sets, scaled, and reshaped as needed for the LSTM models. This separation is crucial for the model to learn the relationship between the input features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e56c772",
   "metadata": {},
   "source": [
    "#### 5.3) Train-Test Split\n",
    "\n",
    " -  The dataset is split into training and testing sets. Here, X_train and y_train represent the features and target variable for the training set, while X_test and y_test represent the same for the testing set. The split is done with 80% of the data allocated to training and 20% to testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf6101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaadf62",
   "metadata": {},
   "source": [
    " - **Maintaining Temporal Order:** In time-series forecasting, it is essential to maintain the chronological order of the data to ensure that the model learns from past data to predict future events. By setting **shuffle=False**, the split respects the time-based sequence, making the model's predictions more reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ec0aa",
   "metadata": {},
   "source": [
    "#### 5.4) Handling Class Imbalance using Weights Calculations\n",
    "\n",
    "   - In classification problems, especially in financial data, class imbalance is a common issue where one class (e.g., uptrend) significantly outnumbers the other (e.g., downtrend). This imbalance can cause the model to be biased towards the majority class, leading to poor performance in predicting the minority class.\n",
    "   - This function calculates the weights for each class to balance the dataset. The balanced mode automatically adjusts the weights inversely proportional to the class frequencies in the input data.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c2cd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies: [786 610]\n",
      "Weighted balance: 698.0, 698.0\n"
     ]
    }
   ],
   "source": [
    "#Handle Class Imbalance\n",
    "y_int = y_train.astype(int)\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_int), y=y_int)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Verify the weighted balance\n",
    "c = np.bincount(y_int)\n",
    "print(f\"Class frequencies: {c}\")\n",
    "print(f\"Weighted balance: {class_weight_dict[0] * c[0]}, {class_weight_dict[1] * c[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b79cc",
   "metadata": {},
   "source": [
    " - Handling class imbalance effectively leads to a model that performs better across all classes, particularly in cases where the minority class is critical (e.g., predicting rare market downturns). This balanced approach helps prevent the model from becoming skewed and improves its ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103dc6c6",
   "metadata": {},
   "source": [
    "#### 5.5) Scaling the features\n",
    "\n",
    "  **Scaling Method (MinMaxScaler):**\n",
    "  \n",
    "   - The MinMaxScaler scales the features to a specified range, typically [0, 1]. It transforms each feature individually such that it is within this range, which is particularly important for models like LSTM that are sensitive to the scale of input data.\n",
    "      \n",
    "   - **Chosen After EDA Observation:**\n",
    "       - The decision to use MinMaxScaler was made after conducting Exploratory Data Analysis (EDA), where it was observed that the features have different scales and ranges. In particular, some features may have had wide ranges, while others were more narrowly distributed.\n",
    "       - MinMax scaling is effective in this context because it preserves the relationships between data points by scaling all features to the same range, without distorting the underlying data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c12911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Training Data: (1396, 24), Scaled Test Data: (350, 24)\n"
     ]
    }
   ],
   "source": [
    "#Scale the Features\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit on the training data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the scaler fitted on the training data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify the scaled data\n",
    "print(f\"Scaled Training Data: {X_train_scaled.shape}, Scaled Test Data: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b5b27",
   "metadata": {},
   "source": [
    " - **Consistent and Balanced Input:** By scaling the features using MinMaxScaler, the input data is now in a consistent range, improving the performance and stability of the LSTM model during training. This step is crucial for ensuring that the model can effectively learn from the data without being influenced by the scale differences between features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c02649a",
   "metadata": {},
   "source": [
    "#### 5.6) Defining Lookback Length and Adjusting Data Lengths for Alignment\n",
    "\n",
    " - **Lookback Period (lookback = 21):**\n",
    "     - The lookback period defines the number of previous time steps the model will use to predict the next time step. In this case, a 21-day lookback is chosen, meaning the model will use the past 21 days of data to predict whether the SPY ETF will experience a **daily uptrend.**\n",
    "- **Market Cycle Consideration:**\n",
    "     - Monthly Cycle: 21 days correspond to approximately one trading month, capturing short-term market cycles that often influence SPY ETF trends.\n",
    "- **Pattern Recognition:**\n",
    "    - This period helps the model identify patterns within a monthly cycle, such as earnings reports and economic data releases.\n",
    "- **Balancing Data Availability and Information:**\n",
    "    - Sufficient Historical Context: 21 days provide enough historical data to detect meaningful trends without introducing too much lag or noise.\n",
    "    - Information Density: It offers a balanced view, allowing the model to learn from recent data without being overwhelmed by older, potentially less relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b7d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sequence Length (lookback period)\n",
    "lookback = 21\n",
    "\n",
    "# Adjust Data Lengths to Ensure Alignment\n",
    "min_samples_train = min(X_train_scaled.shape[0] - lookback + 1, y_train.shape[0])\n",
    "min_samples_test = min(X_test_scaled.shape[0] - lookback + 1, y_test.shape[0])\n",
    "\n",
    "X_train_scaled = X_train_scaled[:min_samples_train + lookback - 1]\n",
    "y_train = y_train[:min_samples_train]\n",
    "\n",
    "X_test_scaled = X_test_scaled[:min_samples_test + lookback - 1]\n",
    "y_test = y_test[:min_samples_test]\n",
    "\n",
    "# Ensure both X and y have the same length\n",
    "if X_train_scaled.shape[0] > y_train.shape[0]:\n",
    "    X_train_scaled = X_train_scaled[-y_train.shape[0]:]\n",
    "elif y_train.shape[0] > X_train_scaled.shape[0]:\n",
    "    y_train = y_train[-X_train_scaled.shape[0]:]\n",
    "\n",
    "if X_test_scaled.shape[0] > y_test.shape[0]:\n",
    "    X_test_scaled = X_test_scaled[-y_test.shape[0]:]\n",
    "elif y_test.shape[0] > X_test_scaled.shape[0]:\n",
    "    y_test = y_test[-X_test_scaled.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a6a94",
   "metadata": {},
   "source": [
    "- **Ensuring Alignment:**\n",
    "   - After defining the lookback period, the code adjusts the lengths of the scaled training and testing data to ensure they align correctly with the target variables. \n",
    "   - This involves trimming the sequences so that the input features (X_train_scaled, X_test_scaled) and corresponding labels (y_train, y_test) are properly aligned, allowing the model to be trained and evaluated without any mismatch between the inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f85a79",
   "metadata": {},
   "source": [
    "#### 5.7) Generate Sequences Using TimeseriesGenerator\n",
    "\n",
    " - **Sequence Generation:** In this step, we're using the TimeseriesGenerator class from Keras to generate sequences of data from the scaled training and test sets. This is essential for training the LSTM model, which expects input data in the form of sequences.\n",
    " - **Parameters:**\n",
    "    - Length: The lookback period (21 days) defines the length of the sequence.\n",
    "    - Batch Size: Set a batch size of 32, meaning the data will be processed in batches of 32 sequences at a time during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93cb5d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence 0 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 1 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 2 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 3 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 4 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 5 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 0 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 1 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 2 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 3 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 4 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 5 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 6 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 7 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 8 - X shape: (32, 21, 24), y shape: (32,)\n",
      "Generated sequence 9 - X shape: (21, 21, 24), y shape: (21,)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Generate Sequences Using TimeseriesGenerator\n",
    "train_generator = TimeseriesGenerator(X_train_scaled, y_train, length=lookback, batch_size=32)\n",
    "test_generator = TimeseriesGenerator(X_test_scaled, y_test, length=lookback, batch_size=32)\n",
    "\n",
    "\n",
    "# Confirm the dimensions of the generated data\n",
    "for i in range(len(train_generator)):\n",
    "    X, y = train_generator[i]\n",
    "    print(f\"Generated sequence {i} - X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "for i in range(len(test_generator)):\n",
    "    try:\n",
    "        X, y = test_generator[i]\n",
    "        print(f\"Generated sequence {i} - X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error at sequence {i}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22543e7",
   "metadata": {},
   "source": [
    "- **Output Verification:**\n",
    "   - The code prints out the shapes of the generated sequences for both the training and test datasets to confirm that the sequences are being generated correctly. Each sequence has a shape of (32, 21, 24), where:\n",
    "      - 32: Number of sequences in a batch (batch size).\n",
    "      - 21: Number of time steps (lookback period).\n",
    "      - 24: Number of features in each sequence.\n",
    "- This step ensures that the input data is correctly formatted into sequences that the LSTM model can use for training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1d07d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca042f9a",
   "metadata": {},
   "source": [
    "### Step 6) Model Building & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05aaba6",
   "metadata": {},
   "source": [
    "- The goal of this step is to build and optimize an LSTM model to predict the daily uptrend of the SPY ETF. We will design the architecture, configure the hyperparameters, and optimize the model using a random search technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80818836",
   "metadata": {},
   "source": [
    "### Model 1) Base Model - LSTM Single Layer\n",
    "\n",
    "**Architecture Overview:**\n",
    "\n",
    " - The LSTM (Long Short-Term Memory) network is a type of recurrent neural network (RNN) that is well-suited for time series prediction due to its ability to remember long-term dependencies. For this base model, we are using a single-layer LSTM, which serves as the foundation for more complex models we might develop later.\n",
    "\n",
    "**How the Single-Layer LSTM Works:**\n",
    "\n",
    " - **1) Input Data Flow:**\n",
    "      - The input to the LSTM layer is a sequence of data points (features) over a specified lookback period (21 days in our case). Each sequence consists of multiple features, where each feature represents a different aspect of the SPY ETF’s historical data (e.g., daily return, volume, technical indicators).\n",
    "     - The input shape for the LSTM layer is (lookback, number_of_features). For our model, this means 21 time steps with the features that have been selected after feature engineering.\n",
    " - **2) LSTM Layer:**\n",
    "     - The LSTM layer processes this sequence data, step by step, maintaining a hidden state that captures information about past data points. This hidden state is crucial because it allows the LSTM to \"remember\" important patterns or trends over time, which helps in making accurate predictions.\n",
    "     - The LSTM cells contain gates that control the flow of information:\n",
    "        - Input Gate decides what information from the current input should be added to the cell state.\n",
    "        - Forget Gate determines what information should be discarded from the cell state.\n",
    "        - Output Gate controls what information should be outputted from the current cell state.\n",
    "   - The output of the LSTM layer is a vector that encapsulates the learned patterns from the 21-day input sequence.\n",
    "- **3) Dropout Layer:**\n",
    "   - After the LSTM layer, we add a Dropout layer to prevent overfitting. The Dropout layer randomly sets a fraction of the input units to zero during training, which forces the model to learn more robust features that generalize better to unseen data.\n",
    " - **4) Output Layer:**\n",
    "  - Finally, a Dense layer with a sigmoid activation function is added. This layer outputs a single probability value between 0 and 1, indicating the likelihood of an uptrend (1) or no uptrend (0) for the next day.\n",
    "\n",
    "- **5) Model Compilation:**\n",
    "   - The model is compiled with the Adam optimizer, a popular choice for training neural networks because it adapts the learning rate during training, making it effective in most cases. \n",
    "   - The loss function is binary cross-entropy, which is appropriate for binary classification tasks like ours.        - Additionally, accuracy, precision, and recall metrics are used to evaluate the model’s performance during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a199ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build the Model with Hyperparameter Tuning\n",
    "def build_model(hp):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the number of units for the single LSTM layer\n",
    "    hp_units = hp.Int('units', min_value=4, max_value=32, step=4)\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    hp_dropout = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Add the single LSTM layer\n",
    "    model.add(LSTM(units=hp_units, input_shape=(lookback, X_train_scaled.shape[1]), \n",
    "                   activation='relu', return_sequences=False))\n",
    "    \n",
    "    # Add Dropout layer\n",
    "    model.add(Dropout(hp_dropout))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate, epsilon=1e-08, decay=0.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdc7f5",
   "metadata": {},
   "source": [
    "**Detailed Code Breakdown**\n",
    "\n",
    "  - **Clear Session:**\n",
    "     - tf.keras.backend.clear_session() is used to clear the previous models and layers from memory. This ensures that each time we build a model, we start fresh without any remnants of previous models, which is particularly important when tuning hyperparameters.\n",
    " - **Instantiate the Model:**\n",
    "    - model = Sequential() initializes a Sequential model, which means we can stack layers in a linear fashion.\n",
    " - **Tune the LSTM Layer:**\n",
    "    - hp_units = hp.Int('units', min_value=4, max_value=32, step=4) tunes the number of units (neurons) in the LSTM layer. This is critical because the number of units determines the model's capacity to learn complex patterns. We explore different numbers of units between 4 and 32 to find the optimal size.\n",
    "    - model.add(LSTM(units=hp_units, input_shape=(lookback, X_train_scaled.shape[1]), activation='relu', return_sequences=False)) adds the LSTM layer with the specified number of units. The input shape is determined by the lookback period and the number of features. activation='relu' is used to introduce non-linearity, which helps the model learn more complex patterns.\n",
    "- **Tune the Dropout Layer:**\n",
    "    - hp_dropout = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1) tunes the dropout rate, which is the fraction of input units to drop to prevent overfitting. A higher dropout rate can reduce overfitting but might also lead to underfitting if too much information is lost.\n",
    "    - model.add(Dropout(hp_dropout)) adds the Dropout layer to the model.\n",
    "- **Output Layer:**\n",
    "   - model.add(Dense(1, activation='sigmoid')) adds the final Dense layer with a sigmoid activation function. This layer outputs a probability that the next day's trend is an uptrend (1) or not (0).\n",
    "- **Tune the Learning Rate:**\n",
    "   - hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]) tunes the learning rate of the Adam optimizer, which is crucial for balancing the speed of learning and the stability of the model.\n",
    "- **Compile the Model:**\n",
    "   - The model is compiled using the Adam optimizer with the tuned learning rate. The loss function is set to binary cross-entropy, suitable for binary classification tasks. Accuracy, precision, and recall are the metrics used to evaluate the model during training and testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0684e99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2dc9b3",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning: \n",
    "\n",
    "  - In machine learning, hyperparameters are the parameters that are not learned from the data but are set before the learning process begins. These include parameters like the number of layers in a neural network, the number of units in each layer, learning rates, batch sizes, etc. Hyperparameter tuning is the process of finding the best combination of these parameters to optimize the model's performance on unseen data.\n",
    "\n",
    "  - Tuning these hyperparameters manually can be time-consuming and inefficient, as it often involves trial and error. This is where automated hyperparameter tuning techniques like Random Search come in, allowing us to explore a vast hyperparameter space more effectively.\n",
    "\n",
    "### Random Search:\n",
    "\n",
    " - Random Search is an approach for hyperparameter optimization that randomly samples the hyperparameter space rather than searching through all possible combinations (like Grid Search). The key idea is to explore more combinations in less time, hoping that some of the randomly selected combinations will perform well.\n",
    "\n",
    " - **How Random Search Works:**\n",
    "\n",
    " - **Define Hyperparameter Space:**\n",
    "    - Before starting, you need to define the range or set of values that each hyperparameter can take. For instance, the number of units in an LSTM layer might range from 4 to 32, the dropout rate might range from 0 to 0.5, and the learning rate might take values like 1e-2, 1e-3, or 1e-4.\n",
    " - **Random Sampling:**\n",
    "   - The Random Search algorithm then randomly samples a set of hyperparameters from this defined space. Unlike Grid Search, which evaluates all possible combinations, Random Search only evaluates a subset. The sampling process is entirely random, which allows the search to explore the hyperparameter space more diversely.\n",
    "- **Model Evaluation:**\n",
    "  - For each sampled set of hyperparameters, a model is built and trained on the training data. The model is then evaluated on validation data to estimate its performance. The primary metric for evaluation in our case is the validation loss (val_loss), but other metrics like accuracy, precision, or recall can also be used depending on the objective.\n",
    "- **Repeat Trials:**\n",
    "  - This process is repeated for a specified number of trials. Each trial represents a different combination of hyperparameters. After completing all the trials, the set of hyperparameters that resulted in the best performance (lowest validation loss) is selected.\n",
    "- **Optimal Model Selection:**\n",
    "  - The best-performing model, based on the evaluation metric, is then selected as the final model, and its hyperparameters are used for training on the full dataset or for further fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8a832a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setup RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',  # Use loss as the primary metric\n",
    "    max_trials=50,  # Maximum number of trials\n",
    "    directory='./keras',\n",
    "    project_name='rs_base_lstm',  # Change this to distinguish between trials\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f676f03",
   "metadata": {},
   "source": [
    "- **Detailed Breakdown:**\n",
    "\n",
    " - **kt.RandomSearch:**\n",
    "     - This initializes the Random Search tuner from Keras Tuner (kt). The tuner is responsible for running the hyperparameter tuning process.\n",
    " - **build_model:**\n",
    "    - The function build_model (which we defined earlier) is passed to the tuner. This function constructs the model according to the hyperparameters sampled by the tuner.\n",
    "- **Objective:**\n",
    "   - The objective='val_loss' indicates that the tuner should optimize for the validation loss. This means that the tuner will attempt to find the set of hyperparameters that minimize the loss on the validation dataset, making the model generalize better to unseen data.\n",
    "- **max_trials=50:**\n",
    "  - The max_trials parameter specifies the maximum number of different hyperparameter combinations the tuner will evaluate. In this case, the tuner will try 50 different combinations. Each trial corresponds to training a model with a different set of hyperparameters.\n",
    "- **directory='./keras':**\n",
    "  - The directory parameter specifies where to save the results of each trial. This allows the tuner to resume tuning or access the results later.\n",
    "- **project_name='rs_base_lstm':**\n",
    "  - The project_name is used to distinguish between different tuning projects. This is helpful if you are tuning multiple models or experimenting with different objectives.\n",
    "- **overwrite=True:**\n",
    "  - The overwrite parameter, when set to True, ensures that previous tuning results are overwritten if they exist. This is useful if you want to restart the tuning process from scratch.\n",
    "\n",
    "- **Impact of Random Search on Model Performance:**\n",
    "\n",
    "   - By using Random Search for hyperparameter tuning, we can efficiently explore a wide range of hyperparameter combinations, potentially discovering high-performing models that might have been missed with manual tuning or more rigid approaches like Grid Search. The randomness allows for a diverse exploration of the hyperparameter space, increasing the chances of finding an optimal or near-optimal solution for our LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f74ec87",
   "metadata": {},
   "source": [
    "#### Setting Up Logging for Model Training with TensorBoard\n",
    "- Defining a unique log directory for each model ensures that the training logs for different models do not overwrite each other. This organization is critical when experimenting with different models or hyperparameter configurations. It allows you to easily review and compare the performance of each model in TensorBoard, facilitating a more informed selection of the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9cc7fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a unique log directory for each model\n",
    "model_number = 1  # Update this for each LSTM model\n",
    "log_dir = f\"./logs/lstm_model_{model_number}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d35ccb",
   "metadata": {},
   "source": [
    "#### Setting Up Callbacks for Early Stopping and TensorBoard\n",
    "\n",
    "- Callbacks in TensorFlow/Keras are powerful tools that can help you manage the training process by taking specific actions at different points during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ac0dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Setup Callbacks for Early Stopping and TensorBoard\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c4f01",
   "metadata": {},
   "source": [
    "- **EarlyStopping Callback:**\n",
    "  - monitor='val_loss':\n",
    "    - Specifies that the validation loss is the metric to be monitored. This means the early stopping will trigger if the validation loss stops improving.\n",
    "  - patience=5:\n",
    "    - Sets the number of epochs with no improvement after which training will be stopped. In this case, if the validation loss does not decrease for 5 consecutive epochs, training will stop.\n",
    "  - mode='min':\n",
    "    - Indicates that the callback should stop training when the validation loss has stopped decreasing (min mode). This is the correct mode when monitoring a loss, as you want to minimize it.\n",
    "  - verbose=1:\n",
    "    - Controls the verbosity of the output. Setting it to 1 means that the callback will print a message when training stops early.\n",
    "\n",
    "**Impact:**\n",
    "\n",
    " - The Early Stopping callback helps to ensure that the model does not overfit and that the training process is efficient by halting early if no further improvement is seen.\n",
    " - This is particularly useful when training deep learning models, where overfitting is a common concern. By setting up Early Stopping, you can automatically revert to the best model encountered during training, ensuring optimal performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2cdbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard callback with the unique log directory\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52507ac1",
   "metadata": {},
   "source": [
    "#### TensorBoard Callback:\n",
    "   - Purpose: TensorBoard callback is used to visualize metrics such as loss and accuracy, compare different models, and track the training progress in real-time.\n",
    "   - How it Works: TensorBoard records logs during training, and these logs can be visualized to see how the model's performance is evolving over time. By setting up a log directory (as mentioned earlier), you can store these logs and later load them into TensorBoard for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e730bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the callbacks in the model training\n",
    "callbacks = [early_stopping, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fb400",
   "metadata": {},
   "source": [
    "#### Performing Hyperparameter Search with Random Search Tuner\n",
    "\n",
    "- **tuner.search():**\n",
    "  - **train_generator:**\n",
    "    - The training data generator created earlier that provides batches of input sequences and their corresponding targets during training.\n",
    "  - **epochs=100:**\n",
    "    - Specifies that each model configuration will be trained for up to 100 epochs. However, due to Early Stopping, the training might halt before 100 epochs if no improvement is observed in the validation loss.\n",
    "  - **validation_data=test_generator:**\n",
    "     - Provides the validation data generator to the tuner, which is used to evaluate the model's performance on unseen data after each epoch.\n",
    "  - **class_weight=class_weight_dict:**\n",
    "     - Incorporates class weights to handle class imbalance, ensuring that the model does not become biased towards the more frequent class.\n",
    "   - **callbacks=[early_stopping, tensorboard_callback]:**\n",
    "      - The callbacks include Early Stopping to prevent overfitting and TensorBoard for tracking the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7f67912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 22s]\n",
      "val_loss: 0.6897996068000793\n",
      "\n",
      "Best val_loss So Far: 0.24344857037067413\n",
      "Total elapsed time: 00h 15m 48s\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform the Hyperparameter Search\n",
    "tuner.search(train_generator, epochs=100, validation_data=test_generator,\n",
    "             class_weight=class_weight_dict,\n",
    "             callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0044f8",
   "metadata": {},
   "source": [
    "- **Best val_loss So Far:** 0.24344857037067413:\n",
    "    - The best validation loss achieved so far across all trials is approximately 0.2434. This indicates the most optimal hyperparameter combination found by the tuner.\n",
    "- **Total elapsed time: 00h 15m 48s:**\n",
    "    - The total time taken to complete all the trials so far is 15 minutes and 48 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259efa5b",
   "metadata": {},
   "source": [
    "#### Retrieving the Best Hyperparameters\n",
    "\n",
    " - After the hyperparameter search is complete, the next step is to retrieve the best set of hyperparameters that yielded the lowest validation loss. This allows us to build the final model using these optimized settings, which should result in the best possible performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "029d8d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units': 28, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Retrieve the Best Hyperparameters\n",
    "best_hbp = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hbp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3909c71",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "  - {'units': 28, 'dropout_rate': 0.30000000000000004, 'learning_rate': 0.001}:\n",
    "  - **units: 28** - The best number of units (neurons) in the LSTM layer was found to be 28. This value dictates the complexity of the LSTM layer and influences how well the model can capture patterns in the time series data.\n",
    "  - **dropout_rate: 0.3** - The optimal dropout rate was determined to be 0.3. Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of the input units to zero during training. A dropout rate of 0.3 indicates that 30% of the units are dropped out.\n",
    "  - **learning_rate: 0.001** - The best learning rate for the optimizer was found to be 0.001. This rate controls how much to adjust the model's weights with respect to the loss gradient. A smaller learning rate typically results in more stable and gradual learning.\n",
    "  \n",
    " - Retrieving and applying the best hyperparameters is a crucial step in ensuring that the final model is both optimized and robust. With these values, the model is likely to achieve the best balance between bias and variance, making it more reliable when making predictions on unseen data. These optimized hyperparameters will be used to build the final LSTM model in the next steps, ensuring that it operates at its highest potential based on the training and validation data provided\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ad9d932d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras/rs_base_lstm\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 46 summary\n",
      "Hyperparameters:\n",
      "units: 28\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.24344857037067413\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.2531904876232147\n",
      "\n",
      "Trial 42 summary\n",
      "Hyperparameters:\n",
      "units: 8\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.2600080966949463\n",
      "\n",
      "Trial 37 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.271786093711853\n",
      "\n",
      "Trial 43 summary\n",
      "Hyperparameters:\n",
      "units: 24\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.28684625029563904\n",
      "\n",
      "Trial 33 summary\n",
      "Hyperparameters:\n",
      "units: 20\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.312380313873291\n",
      "\n",
      "Trial 24 summary\n",
      "Hyperparameters:\n",
      "units: 28\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.33491018414497375\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 8\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.6401737332344055\n",
      "\n",
      "Trial 30 summary\n",
      "Hyperparameters:\n",
      "units: 24\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6625583171844482\n",
      "\n",
      "Trial 23 summary\n",
      "Hyperparameters:\n",
      "units: 8\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.0001\n",
      "Score: 0.674884557723999\n"
     ]
    }
   ],
   "source": [
    "# Display tuning results summary\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084d3e3",
   "metadata": {},
   "source": [
    "#### Evaluating the Best Base Model\n",
    "   - Once the best hyperparameters are identified and the best model is trained, the next crucial step is to evaluate this model on the test data. The goal is to assess its performance using various metrics, including accuracy, precision, recall, and F1 score, which together provide a comprehensive understanding of the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e83d7856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9002 - loss: 0.2390 - precision: 0.8044 - recall: 0.9978  \n",
      "Accuracy: 0.8932\n",
      "Precision: 0.7962\n",
      "Recall: 0.9921\n",
      "F1 Score: 0.8834\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy, precision, recall = best_model.evaluate(test_generator)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8d4a1",
   "metadata": {},
   "source": [
    "**Output Interpretation:**\n",
    "\n",
    "- **Accuracy: 0.8932:** This indicates that approximately 89.32% of the predictions made by the model on the test data were correct.\n",
    "- **Precision: 0.7962:** This means that out of all the positive predictions made by the model, 79.62% were actually correct.\n",
    "- **Recall: 0.9921:** This high recall value shows that the model correctly identified 99.21% of all actual positive cases in the test data.\n",
    "- **F1 Score: 0.8834:** The F1 score, balancing precision and recall, reflects an overall strong performance of the model, especially in dealing with any class imbalances.\n",
    "\n",
    "**Impact:**\n",
    " - The combination of these metrics shows that the model performs well on the test data, especially in terms of recall, meaning it is highly effective at identifying positive cases. The precision and F1 score are also high, indicating a balanced and effective model. This evaluation confirms that the hyperparameter tuning and model selection process resulted in a model that is likely to perform robustly in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427696dc",
   "metadata": {},
   "source": [
    "#### Model Summary:\n",
    " - It provides an overview of the architecture of the LSTM model that was built and optimized during the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8dab920b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m5,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m29\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,965</span> (23.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,965\u001b[0m (23.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,965</span> (23.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,965\u001b[0m (23.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f35489",
   "metadata": {},
   "source": [
    "- **This Best Base LSTM Model consists of three key layers:**\n",
    "\n",
    "  - **LSTM Layer:**\n",
    "    - 28 units: Captures temporal dependencies in the data, crucial for predicting SPY ETF trends.\n",
    "    - 5,936 parameters: Represents the trainable weights and biases in the LSTM layer.\n",
    "  - **Dropout Layer:**\n",
    "    - Regularization: Prevents overfitting by randomly dropping units during training.\n",
    "    - No trainable parameters: It simply helps the model generalize better.\n",
    "  - **Dense Layer:**\n",
    "    - Single output: Produces the final prediction as a probability using a sigmoid activation function, ideal for binary classification.\n",
    "- Total Parameters: 5,965, indicating a lightweight yet effective model for trend prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a37fe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get all trials\n",
    "trials = tuner.oracle.get_best_trials(num_trials=50)\n",
    "\n",
    "# Extract accuracy scores\n",
    "accuracies = [trial.metrics.get_best_value('val_loss') for trial in trials]\n",
    "\n",
    "# Plot\n",
    "plt.plot(range(1, len(accuracies) + 1), accuracies, marker='o')\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.title('Validation Loss Over Trials')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2649f4d8",
   "metadata": {},
   "source": [
    "#### Validation Loss Over Trials\n",
    "- This graph displays the validation loss of the model across 50 trials during the hyperparameter tuning process. The primary observations are:\n",
    "\n",
    "   - Initial Decrease: The validation loss decreases significantly during the early trials, indicating that the model is improving as the tuning process selects better hyperparameters.\n",
    "   - Plateau: After approximately the 10th trial, the validation loss plateaus around 0.3. This suggests that the model has reached a point where further tuning provides minimal improvements, indicating convergence to an optimal set of hyperparameters.\n",
    "  - Final Increase: A slight increase in validation loss towards the end may indicate that some hyperparameter combinations in the later trials were less effective, reaffirming the stability of the earlier optimal parameters.\n",
    "- This pattern suggests that the tuning process successfully identified a robust set of hyperparameters that minimized validation loss effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc7355",
   "metadata": {},
   "source": [
    "### Generating Predictions of Best Base Model and Comparison with Actual Values\n",
    "  - In this step, we generate predictions using the best-performing base model and compare these predictions with the actual target values from the test data:\n",
    "\n",
    "**Generating Predictions:**\n",
    " - The model's predictions are generated on the test data.\n",
    " - The output of the model is in probabilities, which are then converted to binary values (0 or 1) using a threshold of 0.5.\n",
    "**Comparison with Actual Values:**\n",
    " - The actual values from the test data are extracted and aligned with the predictions.\n",
    " - A DataFrame (comparison_df) is created to compare the model's predictions with the actual values side by side.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c909fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "     Predicted  Actual\n",
      "0            0     0.0\n",
      "1            0     0.0\n",
      "2            0     0.0\n",
      "3            0     0.0\n",
      "4            1     1.0\n",
      "..         ...     ...\n",
      "304          0     0.0\n",
      "305          1     1.0\n",
      "306          1     0.0\n",
      "307          0     0.0\n",
      "308          0     0.0\n",
      "\n",
      "[309 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the test data\n",
    "predictions = best_model.predict(test_generator)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary 0 or 1\n",
    "\n",
    "# Actual values from the test data\n",
    "actual = y_test[-len(predictions):]  # Ensure the length matches the predictions\n",
    "\n",
    "# Combine predictions and actual values into a DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Predicted': predictions.flatten(),\n",
    "    'Actual': actual\n",
    "})\n",
    "\n",
    "# Display the first few rows of the comparison DataFrame\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2ad25a",
   "metadata": {},
   "source": [
    "- **Output Display:**\n",
    "  - The first few rows of the comparison DataFrame are displayed, showing how the model's predictions match the actual outcomes.\n",
    "  - The output demonstrates that the model has accurately predicted several instances, as shown by the alignment of predicted and actual values. This provides an initial view of the model's performance before detailed evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "229c7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model.save(\"best_base_lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dbd7fe",
   "metadata": {},
   "source": [
    "- the best model is saved for future use or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e7acb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard\n",
    "%tensorboard --logdir=./logs/lstm_model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40680d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1a974",
   "metadata": {},
   "source": [
    "### Model-2)  LSTM with 2 Layers\n",
    "\n",
    "**Architecture Overview:**\n",
    "\n",
    "  - The LSTM-2 Layer model introduces an additional layer of LSTM neurons compared to the base single-layer LSTM model. \n",
    "  - The architecture is designed to capture more complex patterns and dependencies in the sequential data by allowing information to flow through multiple layers before making a prediction.\n",
    "\n",
    "\n",
    "\n",
    "- **Differences from the Base Model (Single Layer):**\n",
    "\n",
    "   - **Deeper Network:**\n",
    "     - The introduction of a second LSTM layer increases the model's depth, enabling it to learn more abstract and high-level features from the data.\n",
    "     - In contrast to the single-layer LSTM, which only has one set of LSTM units processing the input data, the two-layer model processes the data twice through separate LSTM layers before making a prediction.\n",
    "  - **Return Sequences:**\n",
    "    - The first LSTM layer in this model has return_sequences=True, which means that the output of each time step is fed into the next LSTM layer. This setting is crucial for stacking multiple LSTM layers, as it ensures that the full sequence is passed through each layer.\n",
    "  - **Dropout Regularization:**\n",
    "    - Dropout layers are added after each LSTM layer to prevent overfitting by randomly setting a fraction of input units to 0 during training. This enhances the model's generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9bea730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build the Model with Hyperparameter Tuning\n",
    "def build_model(hp):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the number of units for the first LSTM layer\n",
    "    hp_units1 = hp.Int('units1', min_value=4, max_value=32, step=4)\n",
    "    \n",
    "    # Tune the dropout rate for the first LSTM layer\n",
    "    hp_dropout1 = hp.Float('dropout_rate1', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    \n",
    "    # Add the first LSTM layer\n",
    "    model.add(LSTM(units=hp_units1, input_shape=(lookback, X_train_scaled.shape[1]), \n",
    "                   activation='relu', return_sequences=True))\n",
    "    \n",
    "    # Add Dropout after the first LSTM layer\n",
    "    model.add(Dropout(hp_dropout1))\n",
    "    \n",
    "    # Tune the number of units for the second LSTM layer\n",
    "    hp_units2 = hp.Int('units2', min_value=4, max_value=32, step=4)\n",
    "    \n",
    "    # Tune the dropout rate for the second LSTM layer\n",
    "    hp_dropout2 = hp.Float('dropout_rate2', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    \n",
    "    # Add the second LSTM layer\n",
    "    model.add(LSTM(units=hp_units2, activation='relu', return_sequences=False))\n",
    "    \n",
    "    # Add Dropout after the second LSTM layer\n",
    "    model.add(Dropout(hp_dropout2))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]), \n",
    "                                 epsilon=1e-08, decay=0.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b16bc",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    " - **Layer 1 - First LSTM:**\n",
    "    - **units1:** This parameter defines the number of LSTM units (neurons) in the first layer. The hp.Int function is used to tune this value during hyperparameter optimization, with possible values ranging from 4 to 32 in steps of 4.\n",
    "   - **return_sequences=True:** This ensures that the output of each time step is passed as input to the next LSTM layer.\n",
    "- **Layer 2 - First Dropout:**\n",
    "  - **dropout_rate1:** A tunable dropout rate is applied after the first LSTM layer to prevent overfitting.\n",
    "- **Layer 3 - Second LSTM:**\n",
    "  - **units2:** Defines the number of units in the second LSTM layer, similar to the first, but with its own tunable parameters.\n",
    "  - **return_sequences=False:** This is set to False as it is the final LSTM layer, and we only need the output of the last time step.\n",
    "- **Layer 4 - Second Dropout:**\n",
    "  - **dropout_rate2:** Similar to the first dropout layer but applied after the second LSTM layer.\n",
    "  - **Output Layer:**\n",
    "    - A dense layer with a single output and a sigmoid activation function is used to predict the probability of the target class.\n",
    "\n",
    "- **Compilation:**\n",
    "  - The model is compiled with the Adam optimizer, binary cross-entropy loss, and accuracy, precision, and recall as the evaluation metrics.\n",
    "\n",
    "- This architecture is more sophisticated than the base model, potentially offering better performance on complex datasets due to its increased depth and ability to capture more nuanced relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39603828",
   "metadata": {},
   "source": [
    "#### RandomSearch Tuner for the LSTM 2-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a15db7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setup RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',  # Use loss as the primary metric\n",
    "    max_trials=50,  # Maximum number of trials\n",
    "    directory='./keras',\n",
    "    project_name='rs_2layer_lstm',  # Change this to distinguish between trials\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb225be",
   "metadata": {},
   "source": [
    "#### Callbacks for Early Stopping and TensorBoard for LSTM 2-layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac9a48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Setup Callbacks for Early Stopping and TensorBoard\n",
    "log_dir = \"./logs/2_layer_lstm\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "\n",
    "# Include the callbacks in the model training\n",
    "callbacks = [early_stopping, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f0883",
   "metadata": {},
   "source": [
    "#### Perform the Hyperparameter Search for LSTM 2-Layer Model\n",
    "  - In this step, the hyperparameter tuning process is executed using the tuner.search() function. The search is performed over 50 trials, evaluating the model on the validation data to find the best hyperparameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2f4e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 05s]\n",
      "val_loss: 0.6762955784797668\n",
      "\n",
      "Best val_loss So Far: 0.31076815724372864\n",
      "Total elapsed time: 00h 05m 47s\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform the Hyperparameter Search\n",
    "tuner.search(train_generator, epochs=100, validation_data=test_generator,\n",
    "             class_weight=class_weight_dict,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3abb46",
   "metadata": {},
   "source": [
    "**Results:**\n",
    " \n",
    " - The best validation loss (val_loss) achieved during the search process was 0.31076815724372864, demonstrating the model's ability to generalize well on unseen data.\n",
    "The total time taken for the entire hyperparameter search was just under 6 minutes, indicating an efficient tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2af05",
   "metadata": {},
   "source": [
    "#### Retrieve the Best Hyperparameters for Model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c2553f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units1': 20, 'dropout_rate1': 0.0, 'units2': 20, 'dropout_rate2': 0.2, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Retrieve the Best Hyperparameters\n",
    "best_hbp = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hbp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9627a",
   "metadata": {},
   "source": [
    "**Best Hyperparameters Retrieved:**\n",
    " - Units in First LSTM Layer (units1): 20\n",
    " - Dropout Rate After First LSTM Layer (dropout_rate1): 0.0 (no dropout applied)\n",
    " - Units in Second LSTM Layer (units2): 20\n",
    " - Dropout Rate After Second LSTM Layer (dropout_rate2): 0.2 (20% dropout applied)\n",
    " - Learning Rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "441e747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras/rs_2layer_lstm\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 32 summary\n",
      "Hyperparameters:\n",
      "units1: 20\n",
      "dropout_rate1: 0.0\n",
      "units2: 20\n",
      "dropout_rate2: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.31076815724372864\n",
      "\n",
      "Trial 21 summary\n",
      "Hyperparameters:\n",
      "units1: 32\n",
      "dropout_rate1: 0.0\n",
      "units2: 12\n",
      "dropout_rate2: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.3256916403770447\n",
      "\n",
      "Trial 10 summary\n",
      "Hyperparameters:\n",
      "units1: 20\n",
      "dropout_rate1: 0.4\n",
      "units2: 20\n",
      "dropout_rate2: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.32647982239723206\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "units1: 32\n",
      "dropout_rate1: 0.2\n",
      "units2: 24\n",
      "dropout_rate2: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.32763558626174927\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units1: 16\n",
      "dropout_rate1: 0.2\n",
      "units2: 24\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.3336203992366791\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units1: 4\n",
      "dropout_rate1: 0.2\n",
      "units2: 24\n",
      "dropout_rate2: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.5586530566215515\n",
      "\n",
      "Trial 22 summary\n",
      "Hyperparameters:\n",
      "units1: 4\n",
      "dropout_rate1: 0.2\n",
      "units2: 24\n",
      "dropout_rate2: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.6171936988830566\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "units1: 8\n",
      "dropout_rate1: 0.4\n",
      "units2: 32\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.6316127181053162\n",
      "\n",
      "Trial 20 summary\n",
      "Hyperparameters:\n",
      "units1: 16\n",
      "dropout_rate1: 0.0\n",
      "units2: 12\n",
      "dropout_rate2: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.6384034156799316\n",
      "\n",
      "Trial 43 summary\n",
      "Hyperparameters:\n",
      "units1: 20\n",
      "dropout_rate1: 0.0\n",
      "units2: 28\n",
      "dropout_rate2: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.6450580954551697\n"
     ]
    }
   ],
   "source": [
    "# Display tuning results summary\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66761aa",
   "metadata": {},
   "source": [
    "#### Evaluate the Best LSTM 2-Layer Model on Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1900322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8637 - loss: 0.3115 - precision: 0.7711 - recall: 0.9471  \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3115 - precision: 0.7711 - recall: 0.9471 \n",
      "Accuracy: 0.8608\n",
      "Precision: 0.7610\n",
      "Recall: 0.9603\n",
      "F1 Score: 0.8491\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the Best LSTM 2-Layer Model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(test_generator)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy, precision, recall = best_model.evaluate(test_generator)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc6e29",
   "metadata": {},
   "source": [
    "**Results on Test data:**\n",
    "   - **Accuracy:** The model achieved an accuracy of 0.8608 on the test data, meaning approximately 86% of predictions were correct.\n",
    "  - **Precision:** Precision is 0.7610, indicating that when the model predicted an uptrend (class 1), about 76% of those predictions were correct.\n",
    " - **Recall:** The recall is 0.9603, which shows that the model was able to identify 96% of all actual uptrends (class 1) correctly.\n",
    " - **F1 Score:** The F1 score, which is the harmonic mean of precision and recall, is 0.8491. This score represents a balance between precision and recall, showing that the model has a good balance of correctly predicting both classes with reasonable precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bc65e",
   "metadata": {},
   "source": [
    "#### Summary of the Best LSTM 2-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4950ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)         │         \u001b[38;5;34m3,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m20\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m3,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,901</span> (26.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,901\u001b[0m (26.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,901</span> (26.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,901\u001b[0m (26.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a43fd1",
   "metadata": {},
   "source": [
    "- Summary of the Best LSTM 2-Layer Model\n",
    "  - The model summary shows the architecture of the best 2-layer LSTM model obtained through hyperparameter tuning. Here’s a brief explanation of each layer:\n",
    "\n",
    "- First LSTM Layer:\n",
    "  - This layer has 20 units (neurons) as determined by the hyperparameter tuning.\n",
    "  - The input shape is (21, 20), indicating that the model uses 21 time steps (lookback period) with 20 features per step.\n",
    "  - The return_sequences=True parameter ensures that the output of this LSTM layer is passed as a sequence to the next LSTM layer.\n",
    "- First Dropout Layer:\n",
    "  - A dropout layer is added after the first LSTM layer to prevent overfitting by randomly setting a fraction of input units to 0 during training.\n",
    "  - In this case, the dropout rate is 0, indicating that no dropout is applied for this layer.\n",
    "- Second LSTM Layer:\n",
    "  - This layer also has 20 units. However, unlike the first LSTM layer, return_sequences=False, meaning it only outputs the final hidden state to the next layer.\n",
    "  - This layer further processes the sequence data, summarizing it to a single output.\n",
    "- Second Dropout Layer:\n",
    "  - Another dropout layer is added after the second LSTM layer with a dropout rate of 0.2, meaning 20% of the units are randomly dropped during training.\n",
    "- Dense Output Layer:\n",
    "  - The final layer is a Dense layer with a single unit, using the sigmoid activation function to output a probability between 0 and 1, representing the model's prediction for the target class.\n",
    "\n",
    "- Total Parameters:\n",
    "\n",
    "  - The model has 6,901 trainable parameters, which the model learns during training to make accurate predictions.\n",
    "- This architecture allows the model to capture complex temporal patterns and dependencies in the input data, contributing to its improved performance over a single-layer LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55ed48ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "    Predicted  Actual\n",
      "0           0     0.0\n",
      "1           0     0.0\n",
      "2           0     0.0\n",
      "3           0     0.0\n",
      "4           1     1.0\n",
      "5           0     0.0\n",
      "6           1     1.0\n",
      "7           0     0.0\n",
      "8           1     1.0\n",
      "9           1     1.0\n",
      "10          0     0.0\n",
      "11          1     1.0\n",
      "12          1     1.0\n",
      "13          1     0.0\n",
      "14          0     0.0\n",
      "15          1     1.0\n",
      "16          1     1.0\n",
      "17          1     1.0\n",
      "18          0     1.0\n",
      "19          0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the test data\n",
    "predictions = best_model.predict(test_generator)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary 0 or 1\n",
    "\n",
    "# Actual values from the test data\n",
    "actual = y_test[-len(predictions):]  # Ensure the length matches the predictions\n",
    "\n",
    "# Combine predictions and actual values into a DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Predicted': predictions.flatten(),\n",
    "    'Actual': actual\n",
    "})\n",
    "\n",
    "# Display the first few rows of the comparison DataFrame\n",
    "print(comparison_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "324a1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save the best model\n",
    "best_model.save(\"best_2_layer_lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef440c2",
   "metadata": {},
   "source": [
    "- Best LSTM 2 layer saved for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d916dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch TensorBoard\n",
    "%tensorboard --logdir=./logs/2_layer_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e69740",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beab46b",
   "metadata": {},
   "source": [
    "### Model-3) LSTM 5-Layers \n",
    "\n",
    "**Architecture**\n",
    "\n",
    " - The 5-layer LSTM model is a more complex architecture designed to capture deeper and more intricate patterns in time series data. Here's how it works:\n",
    "\n",
    "- **Layer Structure:** \n",
    "  - The model consists of five LSTM layers stacked sequentially. Each layer processes the time-series data step by step, allowing the model to capture both short-term and long-term dependencies.\n",
    "- **Data Flow:** \n",
    "  - The input data flows through each LSTM layer, with each layer's output serving as the input for the next layer.   - The return_sequences parameter is set to True for the first four LSTM layers, which means that each layer outputs a full sequence of data for the next layer to process. The fifth LSTM layer, which is the final one, outputs only the last time step, which is then fed into the dense output layer.\n",
    "- **Dropout:**\n",
    "  - Between each LSTM layer, a dropout layer is added to prevent overfitting by randomly setting a fraction of input units to zero at each update during training time. The dropout rate is a tunable hyperparameter.\n",
    "- **Output Layer:**\n",
    "  - The final dense layer uses a sigmoid activation function to output a single probability value, which represents the likelihood of the SPY ETF having an upward trend for the next day.\n",
    "- **Purpose:**\n",
    "   - This deeper network allows the model to learn more complex patterns in the data, which might not be captured by simpler models like a single-layer LSTM or a two-layer LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a0409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build the 5-Layer LSTM Model with Hyperparameter Tuning\n",
    "def build_model(hp):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM Layer\n",
    "    hp_units1 = hp.Int('units1', min_value=4, max_value=64, step=4)\n",
    "    hp_dropout1 = hp.Float('dropout_rate1', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(LSTM(units=hp_units1, input_shape=(lookback, X_train_scaled.shape[1]), activation='relu', return_sequences=True))\n",
    "    model.add(Dropout(hp_dropout1))\n",
    "    \n",
    "    # Second to Fifth LSTM Layers\n",
    "    for i in range(2, 6):\n",
    "        hp_units = hp.Int(f'units{i}', min_value=4, max_value=64, step=4)\n",
    "        hp_dropout = hp.Float(f'dropout_rate{i}', min_value=0.0, max_value=0.5, step=0.1)\n",
    "        model.add(LSTM(units=hp_units, activation='relu', return_sequences=True if i < 5 else False))\n",
    "        model.add(Dropout(hp_dropout))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the Model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]), epsilon=1e-08, decay=0.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13463d",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "  - **Sequential Model:**\n",
    "    - This line initializes a sequential model where layers are added in a linear stack.\n",
    " - **First LSTM Layer:**\n",
    "    - The number of units and dropout rate for the first LSTM layer are tuned using hyperparameters. This layer is responsible for capturing initial patterns in the time-series data.\n",
    "- **Second to Fifth LSTM Layers:**\n",
    "  - A loop is used to add the remaining four LSTM layers, each with tunable units and dropout rates. These layers help the model to learn deeper and more complex features.\n",
    "- **Output Layer:**\n",
    "  - The final dense layer produces the binary classification output, predicting whether the SPY ETF will trend upwards.\n",
    "- **Compilation:** \n",
    "  - The model is compiled using the Adam optimizer, with a binary cross-entropy loss function, and it tracks accuracy, precision, and recall as metrics. Hyperparameters for learning rate are also tuned during training.\n",
    "\n",
    "- This architecture allows the model to leverage the depth of the LSTM layers to better understand complex patterns in the time series data, potentially leading to more accurate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a73036",
   "metadata": {},
   "source": [
    "#### RandomSearch Tuner for LSTM 5 layers Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21e9ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setup RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',  # Use loss as the primary metric\n",
    "    max_trials=50,  # Maximum number of trials\n",
    "    directory='./keras',\n",
    "    project_name='rs_5layer_lstm',  #to distinguish between trials\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686b0d2",
   "metadata": {},
   "source": [
    "#### Callbacks for Early Stopping and Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52351616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Callbacks for Early Stopping and TensorBoard\n",
    "log_dir = \"./logs/5_layer_lstm\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "\n",
    "callbacks = [early_stopping, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c894af",
   "metadata": {},
   "source": [
    "#### Hyperparameter Search with RandomSearch Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c454dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 17s]\n",
      "val_loss: 0.6621342301368713\n",
      "\n",
      "Best val_loss So Far: 0.2610277831554413\n",
      "Total elapsed time: 00h 17m 02s\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Perform the Hyperparameter Search\n",
    "tuner.search(train_generator, epochs=100, validation_data=test_generator, class_weight=class_weight_dict, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b4f80",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "  - Best Validation Loss: The best val_loss achieved so far is 0.2610, indicating how well the model generalizes to the validation data.\n",
    " - Total Time: The total elapsed time for completing all 50 trials is approximately 17 minutes and 2 seconds, showcasing the efficiency of the hyperparameter tuning process.\n",
    "- This step is crucial in optimizing the model's performance by finding the best set of hyperparameters, which directly impacts the model's ability to predict the SPY ETF's trend with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c84092a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units1': 64, 'dropout_rate1': 0.30000000000000004, 'units2': 48, 'dropout_rate2': 0.0, 'units3': 32, 'dropout_rate3': 0.2, 'units4': 8, 'dropout_rate4': 0.0, 'units5': 48, 'dropout_rate5': 0.30000000000000004, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Retrieve the Best Hyperparameters\n",
    "best_hbp = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hbp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6137bf6d",
   "metadata": {},
   "source": [
    "- The hyperparameter tuning process identified the following optimal set of hyperparameters for the 5-layer LSTM model:\n",
    "\n",
    "- First LSTM Layer:\n",
    "  - Units: 64\n",
    "  - Dropout Rate: 0.3\n",
    "- Second LSTM Layer:\n",
    "  - Units: 48\n",
    "  - Dropout Rate: 0.0\n",
    "- Third LSTM Layer:\n",
    "  - Units: 32\n",
    "  - Dropout Rate: 0.2\n",
    "- Fourth LSTM Layer:\n",
    "  - Units: 8\n",
    "  - Dropout Rate: 0.0\n",
    "- Fifth LSTM Layer:\n",
    "  - Units: 48\n",
    "  - Dropout Rate: 0.3\n",
    "- Learning Rate: 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24b52a90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras/rs_5layer_lstm\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 29 summary\n",
      "Hyperparameters:\n",
      "units1: 64\n",
      "dropout_rate1: 0.30000000000000004\n",
      "units2: 48\n",
      "dropout_rate2: 0.0\n",
      "units3: 32\n",
      "dropout_rate3: 0.2\n",
      "units4: 8\n",
      "dropout_rate4: 0.0\n",
      "units5: 48\n",
      "dropout_rate5: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.2610277831554413\n",
      "\n",
      "Trial 38 summary\n",
      "Hyperparameters:\n",
      "units1: 52\n",
      "dropout_rate1: 0.4\n",
      "units2: 4\n",
      "dropout_rate2: 0.2\n",
      "units3: 16\n",
      "dropout_rate3: 0.2\n",
      "units4: 48\n",
      "dropout_rate4: 0.1\n",
      "units5: 16\n",
      "dropout_rate5: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.2615254819393158\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "units1: 12\n",
      "dropout_rate1: 0.1\n",
      "units2: 64\n",
      "dropout_rate2: 0.4\n",
      "units3: 4\n",
      "dropout_rate3: 0.4\n",
      "units4: 24\n",
      "dropout_rate4: 0.30000000000000004\n",
      "units5: 20\n",
      "dropout_rate5: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.34811753034591675\n",
      "\n",
      "Trial 12 summary\n",
      "Hyperparameters:\n",
      "units1: 64\n",
      "dropout_rate1: 0.0\n",
      "units2: 16\n",
      "dropout_rate2: 0.4\n",
      "units3: 24\n",
      "dropout_rate3: 0.1\n",
      "units4: 28\n",
      "dropout_rate4: 0.1\n",
      "units5: 64\n",
      "dropout_rate5: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 0.37016424536705017\n",
      "\n",
      "Trial 45 summary\n",
      "Hyperparameters:\n",
      "units1: 48\n",
      "dropout_rate1: 0.0\n",
      "units2: 40\n",
      "dropout_rate2: 0.1\n",
      "units3: 56\n",
      "dropout_rate3: 0.1\n",
      "units4: 32\n",
      "dropout_rate4: 0.30000000000000004\n",
      "units5: 48\n",
      "dropout_rate5: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "Score: 0.37389668822288513\n",
      "\n",
      "Trial 41 summary\n",
      "Hyperparameters:\n",
      "units1: 32\n",
      "dropout_rate1: 0.0\n",
      "units2: 32\n",
      "dropout_rate2: 0.2\n",
      "units3: 36\n",
      "dropout_rate3: 0.2\n",
      "units4: 28\n",
      "dropout_rate4: 0.1\n",
      "units5: 4\n",
      "dropout_rate5: 0.2\n",
      "learning_rate: 0.0001\n",
      "Score: 0.4038466811180115\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "units1: 48\n",
      "dropout_rate1: 0.2\n",
      "units2: 32\n",
      "dropout_rate2: 0.1\n",
      "units3: 44\n",
      "dropout_rate3: 0.2\n",
      "units4: 12\n",
      "dropout_rate4: 0.0\n",
      "units5: 24\n",
      "dropout_rate5: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "Score: 0.46905869245529175\n",
      "\n",
      "Trial 32 summary\n",
      "Hyperparameters:\n",
      "units1: 52\n",
      "dropout_rate1: 0.2\n",
      "units2: 36\n",
      "dropout_rate2: 0.30000000000000004\n",
      "units3: 52\n",
      "dropout_rate3: 0.2\n",
      "units4: 48\n",
      "dropout_rate4: 0.4\n",
      "units5: 12\n",
      "dropout_rate5: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5439107418060303\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units1: 28\n",
      "dropout_rate1: 0.1\n",
      "units2: 12\n",
      "dropout_rate2: 0.4\n",
      "units3: 20\n",
      "dropout_rate3: 0.4\n",
      "units4: 20\n",
      "dropout_rate4: 0.1\n",
      "units5: 20\n",
      "dropout_rate5: 0.1\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5603837370872498\n",
      "\n",
      "Trial 28 summary\n",
      "Hyperparameters:\n",
      "units1: 40\n",
      "dropout_rate1: 0.2\n",
      "units2: 52\n",
      "dropout_rate2: 0.0\n",
      "units3: 12\n",
      "dropout_rate3: 0.0\n",
      "units4: 28\n",
      "dropout_rate4: 0.2\n",
      "units5: 24\n",
      "dropout_rate5: 0.4\n",
      "learning_rate: 0.0001\n",
      "Score: 0.5993320345878601\n"
     ]
    }
   ],
   "source": [
    "# Display tuning results summary\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5f38b",
   "metadata": {},
   "source": [
    "#### Evaluate the Best 5-Layer LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51105e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.2609 - precision: 0.7526 - recall: 0.9978  \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.2609 - precision: 0.7526 - recall: 0.9978\n",
      "Accuracy: 0.8673\n",
      "Precision: 0.7576\n",
      "Recall: 0.9921\n",
      "F1 Score: 0.8591\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Best Model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(test_generator)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy, precision, recall = best_model.evaluate(test_generator)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411dfe2",
   "metadata": {},
   "source": [
    "**Evaluation of the Best 5-Layer LSTM Model**\n",
    "\n",
    " - **Accuracy: 0.8673**\n",
    "   - Accuracy indicates the proportion of correct predictions made by the model out of all predictions. With an accuracy of approximately 86.7%, the model correctly predicts the direction of the SPY ETF's trend most of the time. \n",
    " - **Precision: 0.7576**\n",
    "   - Precision measures the accuracy of the positive predictions made by the model. Specifically, it tells us the percentage of predictions that were actually positive (uptrend) out of all predictions that the model classified as positive. A precision of 75.8% indicates that when the model predicts an uptrend, it's correct about 75.8% of the time. While this is strong, there is some room for improvement to reduce false positives.\n",
    " - **Recall: 0.9921**\n",
    "   - Recall, also known as sensitivity or true positive rate, measures the model's ability to correctly identify all actual positives (uptrends). With a recall of 99.2%, the model is highly effective at capturing nearly all of the true uptrends in the data. This high recall is crucial for financial models where missing an uptrend could lead to lost opportunities.\n",
    "- **F1 Score: 0.8591**\n",
    "   - The F1 Score is the harmonic mean of precision and recall, providing a single metric that balances both. With an F1 score of 85.9%, the model achieves a good balance between precision and recall, making it reliable for predicting uptrends in the SPY ETF. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b44b3",
   "metadata": {},
   "source": [
    "#### Model Summary of Best 5-layer LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01c6ab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m22,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │        \u001b[38;5;34m21,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │         \u001b[38;5;34m1,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │        \u001b[38;5;34m10,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m49\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,153</span> (262.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,153\u001b[0m (262.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,153</span> (262.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m67,153\u001b[0m (262.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0179440",
   "metadata": {},
   "source": [
    "- The model summary for the best 5-layer LSTM model provides an overview of the architecture, detailing each layer's type, output shape, and the number of parameters. Here’s a breakdown:\n",
    "\n",
    "- **LSTM Layers:**\n",
    "  - **First LSTM Layer:** The first layer has 64 units, which captures the most immediate and foundational patterns in the data. It has 22,784 trainable parameters, which include weights, biases, and the connections between time steps.\n",
    "  - **Second to Fifth LSTM Layers:** Each subsequent LSTM layer (with 48, 32, 8, and 48 units, respectively) adds complexity to the model, allowing it to learn deeper and more intricate patterns. The number of parameters decreases with each layer, indicating a reduction in the number of units and connections.\n",
    "- **Dropout Layers:**\n",
    "  - Dropout layers are placed after each LSTM layer to help prevent overfitting. These layers randomly drop a fraction of the units during training, ensuring the model generalizes better to unseen data.\n",
    "- **Dense Layer:**\n",
    "  - The final dense layer, with a single unit and sigmoid activation, produces the binary output (predicting the uptrend or no uptrend for the SPY ETF). This layer synthesizes all the information processed by the preceding LSTM layers.\n",
    "- **Total Parameters:**\n",
    "  - The model has a total of 67,153 parameters, all of which are trainable. These parameters are adjusted during training to minimize the loss function, improving the model's predictive performance.\n",
    "\n",
    "- In summary, the 5-layer LSTM model is more complex than the previous models, with multiple LSTM layers allowing it to capture various levels of temporal patterns. This complexity helps in making more accurate predictions, as indicated by the performance metrics.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a14076",
   "metadata": {},
   "source": [
    "#### Generating Prediction of Best 5-layer Model and compare with Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23344665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "    Predicted  Actual\n",
      "0           1     0.0\n",
      "1           0     0.0\n",
      "2           0     0.0\n",
      "3           0     0.0\n",
      "4           1     1.0\n",
      "5           0     0.0\n",
      "6           1     1.0\n",
      "7           0     0.0\n",
      "8           1     1.0\n",
      "9           1     1.0\n",
      "10          0     0.0\n",
      "11          1     1.0\n",
      "12          1     1.0\n",
      "13          1     0.0\n",
      "14          0     0.0\n",
      "15          1     1.0\n",
      "16          1     1.0\n",
      "17          1     1.0\n",
      "18          1     1.0\n",
      "19          0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the test data\n",
    "predictions = best_model.predict(test_generator)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary 0 or 1\n",
    "\n",
    "# Actual values from the test data\n",
    "actual = y_test[-len(predictions):]  # Ensure the length matches the predictions\n",
    "\n",
    "# Combine predictions and actual values into a DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Predicted': predictions.flatten(),\n",
    "    'Actual': actual\n",
    "})\n",
    "\n",
    "# Display the first few rows of the comparison DataFrame\n",
    "print(comparison_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c181c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "739a0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model.save(\"best_5_layer_lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e432de",
   "metadata": {},
   "source": [
    "- Best 5 layer LSTM model was saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0d029dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launch TensorBoard\n",
    "%tensorboard --logdir=./logs/5_layer_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08603070",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b601fe",
   "metadata": {},
   "source": [
    "### Model-4) GRU Model \n",
    "\n",
    " - The Gated Recurrent Unit (GRU) is a type of recurrent neural network (RNN) that is often compared to the Long Short-Term Memory (LSTM) network. \n",
    " - GRUs are particularly known for their simplicity and effectiveness in capturing temporal dependencies in sequential data. \n",
    " - They have fewer parameters than LSTMs, which can make them faster to train while still retaining a strong capacity for learning long-term dependencies.\n",
    "\n",
    "**Architecture Overview:**\n",
    "\n",
    " - **Input:**\n",
    "   - The input to the GRU model is a sequence of data, specifically designed to handle time-series data like our SPY ETF dataset. \n",
    "   - The input shape for the GRU model is (lookback, number_of_features), where lookback represents the number of previous time steps (in our case, 21 days), and number_of_features corresponds to the number of features in the dataset.\n",
    "\n",
    " - **GRU Layers:**\n",
    "   - **Gated Mechanism:** The GRU architecture utilizes gating mechanisms (reset and update gates) that control the flow of information. \n",
    "     - This helps in deciding which information to retain from the previous time steps and which to discard. Unlike LSTM, GRU has a simpler structure with fewer gates, making it faster and more efficient.\n",
    "   - **Activation:** Typically, relu is used as the activation function in GRUs, which introduces non-linearity and allows the model to learn more complex patterns.\n",
    "- **Output Layer:**\n",
    "  - The final output layer is a dense layer with a single neuron and a sigmoid activation function, producing a binary classification (uptrend or no uptrend).\n",
    " \n",
    "- **Speciality of GRU Compared to LSTM:**\n",
    "\n",
    "  - **Efficiency:** GRUs generally have fewer parameters compared to LSTMs, which makes them faster to train and potentially less prone to overfitting on smaller datasets.\n",
    "  - **Simpler Architecture:** The GRU architecture is less complex than LSTM as it does not have separate forget, input, and output gates. Instead, it combines these into a single update gate, which reduces computational load.\n",
    "  - **Performance:** GRUs often perform as well as LSTMs on many tasks, especially when the sequence lengths are not too long. However, for very long sequences, LSTMs might have an advantage due to their more intricate gating mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5b620b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build the GRU Model with Hyperparameter Tuning\n",
    "def build_model(hp):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Tune the number of units for the first GRU layer\n",
    "    hp_units1 = hp.Int('units1', min_value=4, max_value=64, step=4)\n",
    "    # Tune the dropout rate for the first GRU layer\n",
    "    hp_dropout1 = hp.Float('dropout_rate1', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    \n",
    "    # Add the first GRU layer\n",
    "    model.add(GRU(units=hp_units1, input_shape=(lookback, X_train_scaled.shape[1]), \n",
    "                  activation='relu', return_sequences=True))\n",
    "    # Add Dropout after the first GRU layer\n",
    "    model.add(Dropout(hp_dropout1))\n",
    "    \n",
    "    # Add a second GRU layer\n",
    "    hp_units2 = hp.Int('units2', min_value=4, max_value=64, step=4)\n",
    "    hp_dropout2 = hp.Float('dropout_rate2', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(GRU(units=hp_units2, activation='relu', return_sequences=False))\n",
    "    model.add(Dropout(hp_dropout2))\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]), \n",
    "                                 epsilon=1e-08, decay=0.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d622db1f",
   "metadata": {},
   "source": [
    "**Explanation of the Code:**\n",
    "\n",
    " - **GRU Layers:**\n",
    "   - Two GRU layers are added, each with tunable units and dropout rates. The first GRU layer returns sequences, allowing the second GRU layer to process the entire sequence.\n",
    " - **Dropout Layers:**\n",
    "   - Dropout is applied after each GRU layer to prevent overfitting by randomly dropping units during training.\n",
    " - **Output Layer:** The dense layer with a sigmoid activation function provides a binary classification output.\n",
    "   - Hyperparameter Tuning: The hyperparameters like the number of units in each GRU layer, dropout rates, and learning rates are tuned using the Keras Tuner to find the best configuration for the model.\n",
    "- This GRU model is specifically designed to capture the sequential dependencies in the SPY ETF data, and with the proper tuning, it can be a powerful tool for time-series prediction.\n",
    " - The simplicity of the GRU architecture allows it to be more efficient in terms of computational resources compared to LSTM, while still maintaining strong performance in capturing temporal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2cf8b5",
   "metadata": {},
   "source": [
    "#### RandomSearch Tuner for GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8aaef03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setup RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',  # Use loss as the primary metric\n",
    "    max_trials=50,  # Maximum number of trials\n",
    "    directory='./keras',\n",
    "    project_name='random_search_gru',  # Change this to distinguish between trials\n",
    "    overwrite=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a536c7ce",
   "metadata": {},
   "source": [
    "#### Callbacks for GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "056c95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Setup Callbacks for Early Stopping and TensorBoard\n",
    "log_dir = \"./logs/gru_model\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "\n",
    "# Include the callbacks in the model training\n",
    "callbacks = [early_stopping, tensorboard_callback]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde11fa2",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Random Search for GRU Model\n",
    "- In this step, we perform the hyperparameter search for the GRU model using Keras Tuner's RandomSearch method. The goal is to identify the optimal combination of hyperparameters that minimize the validation loss on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bd01368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 31s]\n",
      "val_loss: 0.6874955296516418\n",
      "\n",
      "Best val_loss So Far: 0.20347130298614502\n",
      "Total elapsed time: 00h 25m 08s\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform the Hyperparameter Search\n",
    "tuner.search(train_generator, epochs=100, validation_data=test_generator,\n",
    "             class_weight=class_weight_dict,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505557d",
   "metadata": {},
   "source": [
    "#### Explanations: \n",
    "   - **Trial Process:**\n",
    "      - A total of 50 trials were conducted, with each trial testing a different combination of hyperparameters (such as the number of units in each GRU layer, dropout rates, and learning rates).\n",
    "      - Each trial involves training the GRU model on the training data (train_generator) and evaluating it on the validation data (test_generator).\n",
    "   - **Validation Loss:**\n",
    "     - The primary metric used to evaluate the performance of the model during tuning is val_loss, which represents the loss on the validation dataset.\n",
    "     - After 50 trials, the best validation loss achieved is 0.20347130298614502. This indicates that this specific combination of hyperparameters resulted in the most accurate predictions on the validation data.\n",
    "   - **Elapsed Time:**\n",
    "     - The entire tuning process took approximately 25 minutes and 8 seconds to complete all 50 trials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1b955",
   "metadata": {},
   "source": [
    "#### Retrieve the Best Hyperparameters for GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd6cea69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'units1': 24, 'dropout_rate1': 0.30000000000000004, 'units2': 36, 'dropout_rate2': 0.0, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Retrieve the Best Hyperparameters\n",
    "best_hbp = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hbp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a1ddd",
   "metadata": {},
   "source": [
    "- **Best Hyperparameters:**\n",
    "   - units1: 24\n",
    "   - dropout_rate1: 0.3\n",
    "   - units2: 36\n",
    "   - dropout_rate2: 0.0\n",
    "   - learning_rate: 0.001\n",
    "- **Explanation:**\n",
    "   - units1 and units2: These define the number of units (neurons) in the first and second GRU layers, respectively. The model performed best with 24 units in the first layer and 36 units in the second layer.\n",
    "  - dropout_rate1 and dropout_rate2: Dropout is a regularization technique to prevent overfitting by randomly setting a fraction of input units to 0 at each update during training. The first GRU layer has a dropout rate of 0.3 (meaning 30% of the units are dropped), while the second layer does not apply dropout (0.0).\n",
    "  - learning_rate: The learning rate controls the step size in updating the model weights during training. A learning rate of 0.001 was found to be the most effective in minimizing the validation loss during the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8005f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras/random_search_gru\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "units1: 24\n",
      "dropout_rate1: 0.30000000000000004\n",
      "units2: 36\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.20347130298614502\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units1: 44\n",
      "dropout_rate1: 0.2\n",
      "units2: 16\n",
      "dropout_rate2: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.23656423389911652\n",
      "\n",
      "Trial 42 summary\n",
      "Hyperparameters:\n",
      "units1: 64\n",
      "dropout_rate1: 0.1\n",
      "units2: 64\n",
      "dropout_rate2: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.2381349354982376\n",
      "\n",
      "Trial 16 summary\n",
      "Hyperparameters:\n",
      "units1: 36\n",
      "dropout_rate1: 0.1\n",
      "units2: 36\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.24368233978748322\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units1: 12\n",
      "dropout_rate1: 0.2\n",
      "units2: 60\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.01\n",
      "Score: 0.274105042219162\n",
      "\n",
      "Trial 12 summary\n",
      "Hyperparameters:\n",
      "units1: 44\n",
      "dropout_rate1: 0.1\n",
      "units2: 24\n",
      "dropout_rate2: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.2976452112197876\n",
      "\n",
      "Trial 24 summary\n",
      "Hyperparameters:\n",
      "units1: 24\n",
      "dropout_rate1: 0.2\n",
      "units2: 28\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.31646713614463806\n",
      "\n",
      "Trial 22 summary\n",
      "Hyperparameters:\n",
      "units1: 52\n",
      "dropout_rate1: 0.30000000000000004\n",
      "units2: 16\n",
      "dropout_rate2: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.3193293511867523\n",
      "\n",
      "Trial 43 summary\n",
      "Hyperparameters:\n",
      "units1: 60\n",
      "dropout_rate1: 0.1\n",
      "units2: 24\n",
      "dropout_rate2: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.3283694386482239\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units1: 40\n",
      "dropout_rate1: 0.2\n",
      "units2: 32\n",
      "dropout_rate2: 0.1\n",
      "learning_rate: 0.0001\n",
      "Score: 0.4650031626224518\n"
     ]
    }
   ],
   "source": [
    "# Display tuning results summary\n",
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de127dd4",
   "metadata": {},
   "source": [
    "#### Evaluate the Best GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d5d2e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.1890 - precision: 0.8713 - recall: 0.8552  \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.1890 - precision: 0.8713 - recall: 0.8552 \n",
      "Accuracy: 0.8900\n",
      "Precision: 0.8898\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.8607\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the Best GRU Model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(test_generator)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy, precision, recall = best_model.evaluate(test_generator)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe4750",
   "metadata": {},
   "source": [
    "**Output Metrics on Test Data:**\n",
    "\n",
    "- Accuracy: 0.8900\n",
    "- Precision: 0.8898\n",
    "- Recall: 0.8333\n",
    "- F1 Score: 0.8607\n",
    "\n",
    "- **Explanation:**\n",
    "  - Accuracy: The model correctly predicted the uptrend or downtrend 89.00% of the time. This indicates strong overall performance.\n",
    "  - Precision: Precision is the ratio of correctly predicted positive observations to the total predicted positives. A precision of 0.8898 means that about 89% of the times when the model predicted an uptrend, it was correct.\n",
    "  - Recall: Recall (or Sensitivity) is the ratio of correctly predicted positive observations to all observations in the actual class. A recall of 0.8333 means the model correctly identified about 83% of the actual uptrends.\n",
    "  - F1 Score: The F1 Score is the weighted average of Precision and Recall. The F1 Score of 0.8607 reflects the balance between precision and recall, indicating that the model performs well in identifying uptrends with a reasonable trade-off between false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3e5a0",
   "metadata": {},
   "source": [
    "#### Summary of the best GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9030e705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,696</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │         \u001b[38;5;34m3,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │         \u001b[38;5;34m6,696\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m37\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,333</span> (40.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,333\u001b[0m (40.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,333</span> (40.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,333\u001b[0m (40.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68d7e7",
   "metadata": {},
   "source": [
    "\n",
    "- **GRU Layers:**\n",
    "   - The first GRU layer has 24 units with a dropout rate of 0.3. This layer processes the input sequence and passes the information to the next GRU layer.\n",
    "  - The second GRU layer has 36 units with no dropout. This layer processes the output of the first GRU layer to further refine the temporal patterns identified in the input sequence.\n",
    "- **Dropout Layers:**\n",
    "  - Dropout layers are placed after each GRU layer to prevent overfitting by randomly dropping a fraction of the units during training. The first dropout layer has a rate of 0.3, which means 30% of the units are dropped during each update.\n",
    "- **Dense Layer:**\n",
    "  - The model ends with a dense layer containing a single unit with a sigmoid activation function. This layer outputs a probability score that determines the predicted class (uptrend or downtrend).\n",
    "- **Model Complexity:**\n",
    "   - The total number of trainable parameters in this model is 10,333. This relatively low number of parameters indicates that the model is not overly complex, which can help in reducing overfitting while still capturing the essential patterns in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1822e125",
   "metadata": {},
   "source": [
    "#### Generating Prediction of Best GRU model and comparing with actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b15fed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "    Predicted  Actual\n",
      "0           1     0.0\n",
      "1           0     0.0\n",
      "2           0     0.0\n",
      "3           0     0.0\n",
      "4           1     1.0\n",
      "5           0     0.0\n",
      "6           1     1.0\n",
      "7           0     0.0\n",
      "8           1     1.0\n",
      "9           1     1.0\n",
      "10          0     0.0\n",
      "11          0     1.0\n",
      "12          1     1.0\n",
      "13          0     0.0\n",
      "14          0     0.0\n",
      "15          1     1.0\n",
      "16          0     1.0\n",
      "17          1     1.0\n",
      "18          1     1.0\n",
      "19          0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the test data\n",
    "predictions = best_model.predict(test_generator)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary 0 or 1\n",
    "\n",
    "# Actual values from the test data\n",
    "actual = y_test[-len(predictions):]  # Ensure the length matches the predictions\n",
    "\n",
    "# Combine predictions and actual values into a DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Predicted': predictions.flatten(),\n",
    "    'Actual': actual\n",
    "})\n",
    "\n",
    "# Display the first few rows of the comparison DataFrame\n",
    "print(comparison_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d130a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best model\n",
    "best_model.save(\"best_gru_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66720a7",
   "metadata": {},
   "source": [
    "- Best GRU model saved for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d2f54eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launch TensorBoard\n",
    "%tensorboard --logdir=./logs/gru_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813cc07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0fa7d",
   "metadata": {},
   "source": [
    "### Model-5) LSTM + CNN Hybrid (Conv1D) Model\n",
    "\n",
    "**Architecture Explanation:**\n",
    "\n",
    "  - The LSTM + CNN Hybrid model is designed to leverage the strengths of both Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) networks. This hybrid model is particularly effective for time-series forecasting because it combines the ability of CNNs to capture local, spatial patterns with the power of LSTM networks to model temporal dependencies.\n",
    "  \n",
    "- **Transition to Functional API:**\n",
    "   - In this LSTM + CNN hybrid model, the Functional API is used instead of the Sequential API.\n",
    "   - The LSTM + CNN model is more complex than the previous models. The Conv1D layer processes the input data first, and its output is then passed to an LSTM layer. The Functional API is well-suited for handling this kind of data flow, where the output of one branch (the Conv1D layer) needs to be passed to another branch (the LSTM layer) before reaching the output layer.\n",
    "\n",
    "- **Components of the Architecture:**\n",
    "\n",
    "  - **Input Layer:**\n",
    "    - Shape: The input shape is (lookback, X_train_scaled.shape[1]). Here, lookback is the sequence length, representing the number of past time steps the model will look at, and X_train_scaled.shape[1] is the number of features in each time step.\n",
    "    - Purpose: This layer takes in sequences of data, each of which consists of multiple time steps and features, and passes it on to subsequent layers for processing.\n",
    "  - **CNN Layer (Conv1D + MaxPooling1D):**\n",
    "    - Conv1D Layer:\n",
    "      - Filters: Filters in a convolutional layer are essentially the feature detectors. The number of filters defines how many different patterns the layer will try to learn from the data.\n",
    "      - Kernel Size: The kernel size determines the width of the convolutional window. It specifies how many time steps will be considered simultaneously when the filter is sliding over the data.\n",
    "      - Activation Function: ReLU is used to introduce non-linearity, allowing the model to learn complex patterns.\n",
    "    - MaxPooling1D Layer:\n",
    "      - Pool Size: After convolution, max-pooling reduces the dimensionality of the output by selecting the maximum  value in a specific window, thereby focusing on the most significant features detected by the filters.\n",
    "      - Purpose: The CNN layer is used to extract high-level features from the input sequence. It looks for patterns within short subsequences of the input data, capturing local dependencies.\n",
    "\n",
    "  - **LSTM Layer:**\n",
    "    - Units: The number of LSTM units is tunable. These units represent the memory cells of the LSTM, which help in capturing and retaining information over time.\n",
    "    - Return Sequences: The return_sequences parameter is set to False, meaning the LSTM layer only returns the output for the last time step, which is then passed to the next layer.\n",
    "    - Activation Function: ReLU is again used to introduce non-linearity.\n",
    "    - Purpose: The LSTM layer processes the high-level features extracted by the CNN layer. It captures long-term dependencies in the data, enabling the model to understand how the sequence of events unfolds over time.\n",
    "  - **Dropout Layer:**\n",
    "     - Dropout Rate: Dropout is a regularization technique where a certain percentage of units are randomly dropped during training. This prevents the model from overfitting to the training data.\n",
    "     - Purpose: The dropout layer helps in generalizing the model by reducing overfitting, making it more robust to new, unseen data.\n",
    " - **Output Layer:**\n",
    "    - Dense Layer: The output layer is a fully connected layer with a single unit. It uses a sigmoid activation function to output a probability score between 0 and 1.\n",
    "    - Purpose: This layer generates the final prediction. Since the task is binary classification (predicting an uptrend or downtrend), the sigmoid function is ideal as it outputs a probability that the next time step will be an uptrend.\n",
    " - **Model Compilation:**\n",
    "    - Optimizer: The Adam optimizer is used for training, with a tunable learning rate.\n",
    "    - Loss Function: Binary cross-entropy is used as the loss function, suitable for binary classification tasks.\n",
    "- Metrics: The model’s performance is evaluated using accuracy, precision, and recall, which provide insights into how well the model is making predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ada5b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build the LSTM + CNN Model with Hyperparameter Tuning\n",
    "def build_model(hp):\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Input Layer\n",
    "    inputs = Input(shape=(lookback, X_train_scaled.shape[1]))\n",
    "    \n",
    "    # CNN Layer\n",
    "    hp_filters = hp.Int('filters', min_value=16, max_value=64, step=16)\n",
    "    hp_kernel_size = hp.Choice('kernel_size', values=[2, 3, 4])\n",
    "    hp_pool_size = hp.Choice('pool_size', values=[2, 3])\n",
    "    x = Conv1D(filters=hp_filters, kernel_size=hp_kernel_size, activation='relu')(inputs)\n",
    "    x = MaxPooling1D(pool_size=hp_pool_size)(x)\n",
    "    \n",
    "    # LSTM Layer\n",
    "    hp_units = hp.Int('units', min_value=4, max_value=32, step=4)\n",
    "    x = LSTM(units=hp_units, activation='relu', return_sequences=False)(x)\n",
    "    \n",
    "    # Dropout Layer\n",
    "    hp_dropout = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    x = Dropout(hp_dropout)(x)\n",
    "    \n",
    "    # Output Layer\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4]), \n",
    "                                 epsilon=1e-08, decay=0.0),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4f0f7",
   "metadata": {},
   "source": [
    "#### Setup RandomSearch Tuner for LSTM + CNN Hybrid Model\n",
    "   - In this step, we set up the RandomSearch tuner from the Keras Tuner library, which will be used to find the best hyperparameters for the LSTM + CNN hybrid model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1835724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Setup RandomSearch Tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',  # loss as the primary metric\n",
    "    max_trials=50,  # Maximum number of trials\n",
    "    directory='./keras',\n",
    "    project_name='rs_lstm_cnn', \n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b574a2",
   "metadata": {},
   "source": [
    "#### Callbacks for LSTM + CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4e6a4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Setup Callbacks for Early Stopping and TensorBoard\n",
    "log_dir = \"./logs/lstm_cnn\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d710b53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the callbacks in the model training\n",
    "callbacks = [early_stopping, tensorboard_callback]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10027f",
   "metadata": {},
   "source": [
    "#### Perform the Hyperparameter Search\n",
    "   - In this step, the hyperparameter search is conducted using the RandomSearch tuner, which iterates through different combinations of hyperparameters to find the most effective configuration for our LSTM + CNN hybrid model.    - This process is aimed at minimizing the validation loss (val_loss) to enhance the model's ability to generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a00c2dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 23s]\n",
      "val_loss: 0.6911958456039429\n",
      "\n",
      "Best val_loss So Far: 0.31274592876434326\n",
      "Total elapsed time: 00h 14m 56s\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform the Hyperparameter Search\n",
    "tuner.search(train_generator, epochs=100, validation_data=test_generator,\n",
    "             class_weight=class_weight_dict,\n",
    "             callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d11ad9",
   "metadata": {},
   "source": [
    "- **Output Interpretation:**\n",
    "\n",
    "  - Trial 50 Complete val_loss: 0.6911958456039429:\n",
    "     - This line indicates that the 50th trial has finished, and the validation loss for this specific trial is 0.6912.\n",
    "  - Best val_loss So Far: 0.31274592876434326:\n",
    "    - Among all the trials, the best validation loss achieved is 0.3127. This model configuration will be considered the best and will be used in subsequent steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12841bda",
   "metadata": {},
   "source": [
    "#### Retrieve the Best Hyperparameters\n",
    "   - In this step, we retrieve the best hyperparameters that were found during the hyperparameter search conducted in the previous step. The goal is to identify the optimal configuration of the model that achieved the lowest validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "235f0ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filters': 48, 'kernel_size': 4, 'pool_size': 2, 'units': 12, 'dropout_rate': 0.2, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Retrieve the Best Hyperparameters\n",
    "best_hbp = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hbp.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434b786",
   "metadata": {},
   "source": [
    "- filters: The best number of filters for the Conv1D layer was found to be 48. Filters in CNN layers are used to detect various features in the input data, such as patterns or trends in time series data.\n",
    "- kernel_size: The optimal kernel size for the Conv1D layer is 4. The kernel size defines the length of the filter, which determines how many time steps are considered together when detecting patterns.\n",
    "- pool_size: The best pool size for the MaxPooling1D layer is 2. Pooling helps in downsampling the output from the Conv1D layer, reducing the dimensionality and computation required in subsequent layers.\n",
    "- units: The number of units in the LSTM layer following the CNN layer was determined to be 12. These units represent the LSTM memory cells that capture temporal dependencies in the time series data.\n",
    "- dropout_rate: The dropout rate is set at 0.2. Dropout is a regularization technique that helps prevent overfitting by randomly dropping a fraction of units during training.\n",
    "- learning_rate: The learning rate for the optimizer was found to be 0.001. The learning rate controls how much the model's weights are adjusted in response to the gradient calculated during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "774f7ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./keras/rs_lstm_cnn\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 40 summary\n",
      "Hyperparameters:\n",
      "filters: 48\n",
      "kernel_size: 4\n",
      "pool_size: 2\n",
      "units: 12\n",
      "dropout_rate: 0.2\n",
      "learning_rate: 0.001\n",
      "Score: 0.31274592876434326\n",
      "\n",
      "Trial 39 summary\n",
      "Hyperparameters:\n",
      "filters: 32\n",
      "kernel_size: 3\n",
      "pool_size: 2\n",
      "units: 24\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.3178774416446686\n",
      "\n",
      "Trial 11 summary\n",
      "Hyperparameters:\n",
      "filters: 48\n",
      "kernel_size: 3\n",
      "pool_size: 2\n",
      "units: 28\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.319101482629776\n",
      "\n",
      "Trial 20 summary\n",
      "Hyperparameters:\n",
      "filters: 48\n",
      "kernel_size: 4\n",
      "pool_size: 2\n",
      "units: 24\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.001\n",
      "Score: 0.3396197557449341\n",
      "\n",
      "Trial 30 summary\n",
      "Hyperparameters:\n",
      "filters: 64\n",
      "kernel_size: 4\n",
      "pool_size: 2\n",
      "units: 24\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.0001\n",
      "Score: 0.34410375356674194\n",
      "\n",
      "Trial 36 summary\n",
      "Hyperparameters:\n",
      "filters: 32\n",
      "kernel_size: 2\n",
      "pool_size: 2\n",
      "units: 28\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.35838475823402405\n",
      "\n",
      "Trial 43 summary\n",
      "Hyperparameters:\n",
      "filters: 64\n",
      "kernel_size: 3\n",
      "pool_size: 3\n",
      "units: 24\n",
      "dropout_rate: 0.1\n",
      "learning_rate: 0.001\n",
      "Score: 0.3631739318370819\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "filters: 32\n",
      "kernel_size: 4\n",
      "pool_size: 3\n",
      "units: 32\n",
      "dropout_rate: 0.30000000000000004\n",
      "learning_rate: 0.001\n",
      "Score: 0.3758804500102997\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "filters: 48\n",
      "kernel_size: 2\n",
      "pool_size: 2\n",
      "units: 8\n",
      "dropout_rate: 0.4\n",
      "learning_rate: 0.001\n",
      "Score: 0.3839152157306671\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "filters: 16\n",
      "kernel_size: 4\n",
      "pool_size: 3\n",
      "units: 16\n",
      "dropout_rate: 0.0\n",
      "learning_rate: 0.0001\n",
      "Score: 0.38594990968704224\n"
     ]
    }
   ],
   "source": [
    "# Display tuning results summary\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551848f3",
   "metadata": {},
   "source": [
    "#### Evaluate the Best LSTM+CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bad9efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3277 - precision: 0.7586 - recall: 0.9043  \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8440 - loss: 0.3277 - precision: 0.7586 - recall: 0.9043 \n",
      "Accuracy: 0.8544\n",
      "Precision: 0.7682\n",
      "Recall: 0.9206\n",
      "F1 Score: 0.8375\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the Best LSTM+CNN Model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.evaluate(test_generator)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy, precision, recall = best_model.evaluate(test_generator)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bfa6fa",
   "metadata": {},
   "source": [
    "**Evaluation Metrics:**\n",
    "\n",
    " - The model's performance is evaluated using several key metrics:\n",
    "\n",
    "  - **Accuracy:** Measures the proportion of correct predictions (both uptrends and downtrends) made by the model out of the total predictions. An accuracy of 0.8544 indicates that approximately 85.44% of the predictions were correct.\n",
    "  - **Precision:** Focuses on the model’s ability to correctly identify positive instances (uptrends) among the instances it predicted as positive. A precision score of 0.7682 suggests that around 76.82% of the uptrends predicted by the model were actually uptrends.\n",
    "  - **Recall:** Also known as sensitivity, recall measures the model’s ability to identify all actual positive instances (uptrends). A recall score of 0.9206 indicates that the model successfully identified 92.06% of the actual uptrends in the test data.\n",
    "  - **F1 Score:** The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both. The F1 score of 0.8375 reflects the model's overall performance in terms of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f5eda",
   "metadata": {},
   "source": [
    "#### Summary of Best LSTM + CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26e41ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m24\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │         \u001b[38;5;34m4,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m48\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │         \u001b[38;5;34m2,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,597</span> (29.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,597\u001b[0m (29.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,597</span> (29.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,597\u001b[0m (29.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5b245",
   "metadata": {},
   "source": [
    "- Input Layer (InputLayer)\n",
    "  - Output Shape: (None, 21, 24)\n",
    "\n",
    "  - The input layer expects data with a shape of 21 time steps (lookback period) and 24 features. The None dimension represents the batch size, which can vary during training and inference.\n",
    "- Convolutional Layer (Conv1D)\n",
    "  - Output Shape: (None, 18, 48)\n",
    "  - Parameters: 4,656\n",
    "  \n",
    "  - The Conv1D layer applies 48 filters of size 4 (as determined by the hyperparameter tuning) across the input sequence, learning to recognize spatial hierarchies and patterns within the data. The convolution operation reduces the time dimension from 21 to 18.\n",
    "- Pooling Layer (MaxPooling1D)\n",
    "  - Output Shape: (None, 9, 48)\n",
    "\n",
    "  - The MaxPooling1D layer reduces the dimensionality of the data by taking the maximum value over a pool size of 2, further compressing the time dimension from 18 to 9. This helps reduce the model complexity and prevent overfitting.\n",
    "- LSTM Layer (LSTM)\n",
    "  - Output Shape: (None, 12)\n",
    "  - Parameters: 2,928\n",
    "\n",
    "  - The LSTM layer, with 12 units, processes the output of the convolutional layers, capturing the temporal dependencies in the sequence data. The output is a sequence of 12 units representing the learned temporal patterns.\n",
    "- Dropout Layer (Dropout)\n",
    "  - Output Shape: (None, 12)\n",
    "\n",
    "  - The Dropout layer randomly drops 20% of the units during training, as determined by the best hyperparameters. This helps prevent the model from overfitting by ensuring it does not rely too heavily on any single feature.\n",
    "- Dense Layer (Dense)\n",
    "  - Output Shape: (None, 1)\n",
    "  - Parameters: 13\n",
    "\n",
    "  - The Dense layer serves as the output layer with a single unit and a sigmoid activation function. It outputs a probability between 0 and 1, representing the model’s prediction of the SPY ETF's uptrend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6193e",
   "metadata": {},
   "source": [
    "#### Generate Predictions of best LSTM + CNN model and compare with actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83cc4b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "    Predicted  Actual\n",
      "0           0     0.0\n",
      "1           0     0.0\n",
      "2           0     0.0\n",
      "3           0     0.0\n",
      "4           1     1.0\n",
      "5           1     0.0\n",
      "6           1     1.0\n",
      "7           0     0.0\n",
      "8           1     1.0\n",
      "9           1     1.0\n",
      "10          0     0.0\n",
      "11          0     1.0\n",
      "12          1     1.0\n",
      "13          1     0.0\n",
      "14          0     0.0\n",
      "15          1     1.0\n",
      "16          1     1.0\n",
      "17          1     1.0\n",
      "18          1     1.0\n",
      "19          0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions using the test data\n",
    "predictions = best_model.predict(test_generator)\n",
    "predictions = (predictions > 0.5).astype(int)  # Convert probabilities to binary 0 or 1\n",
    "\n",
    "# Actual values from the test data\n",
    "actual = y_test[-len(predictions):]  # Ensure the length matches the predictions\n",
    "\n",
    "# Combine predictions and actual values into a DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Predicted': predictions.flatten(),\n",
    "    'Actual': actual\n",
    "})\n",
    "\n",
    "# Display the first few rows of the comparison DataFrame\n",
    "print(comparison_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09913b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the best model\n",
    "best_model.save(\"best_lstm_cnn_model.keras\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404c1fe",
   "metadata": {},
   "source": [
    "- Best LSTM+CNN model saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "19668c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Launch TensorBoard\n",
    "%tensorboard --logdir=./logs/lstm_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc3dc0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfd634",
   "metadata": {},
   "source": [
    "### Step-7) Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad47e0",
   "metadata": {},
   "source": [
    "### 7.1) Model Evaluation by Evaluation Metrics\n",
    "\n",
    "- **Loading and Evaluating the Saved Models**\n",
    "  - After saving the best models during the hyperparameter tuning process, we now proceed to load these models and evaluate their performance using various classification metrics. The purpose of this evaluation is to compare how each model performs on the test dataset.\n",
    "\n",
    "- **Functionality Overview:**\n",
    "\n",
    "  - Model Loading: We load the saved models using the load_model function from TensorFlow.\n",
    "  - Metrics Calculation: We calculate key performance metrics such as accuracy, F1 score, precision, recall, and additional metrics like True Positive Rate (TPR), True Negative Rate (TNR), False Positive Rate (FPR), and False Negative Rate (FNR).\n",
    "  - Adjusting Test Labels: The test labels (y_test) are adjusted to match the length of predictions (y_pred) generated by each model.\n",
    "  - Performance Storage: We store the calculated metrics in a dictionary and convert it into a DataFrame for easy comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b01d3",
   "metadata": {},
   "source": [
    "### Metrics Overview:\n",
    "\n",
    "### Accuracy:\n",
    "Accuracy is the ratio of correctly predicted observations to the total observations. It gives an overall view of how well the model is performing, but it might not be enough when dealing with imbalanced data.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "#### F1 Score:\n",
    "- The F1 score is the weighted average of Precision and Recall. It considers both false positives and false negatives, making it a more comprehensive metric, especially when dealing with imbalanced classes.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "#### Precision:\n",
    "- Precision is the ratio of correctly predicted positive observations to the total predicted positives. High precision relates to a low false positive rate.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "#### Recall (Sensitivity or True Positive Rate - TPR):\n",
    "- Recall is the ratio of correctly predicted positive observations to all observations in the actual class. High recall indicates that the model successfully captures most of the actual positives.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "#### True Positive Rate (TPR):\n",
    "- Also known as Recall, it measures the proportion of actual positives that are correctly identified by the model.\n",
    "\n",
    "#### True Negative Rate (TNR):\n",
    "- TNR is the ratio of correctly predicted negative observations to all observations in the actual negative class.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{TNR} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "#### False Positive Rate (FPR):\n",
    "- FPR is the ratio of incorrectly predicted positive observations to all actual negatives. A lower FPR is desirable.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}}\n",
    "$$\n",
    "\n",
    "#### False Negative Rate (FNR):\n",
    "- FNR is the ratio of incorrectly predicted negative observations to all actual positives. A lower FNR is desirable.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{FNR} = \\frac{\\text{FN}}{\\text{FN} + \\text{TP}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5eebcd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Loading the saved models\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate TPR, TNR, FPR, FNR\n",
    "def calculate_tpr_tnr_fpr_fnr(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate (Sensitivity, Recall)\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate (Specificity)\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "\n",
    "    return tpr, tnr, fpr, fnr\n",
    "\n",
    "# Load the best models\n",
    "best_base_lstm_model = load_model(\"best_base_lstm_model.keras\")\n",
    "best_2_layer_lstm_model = load_model(\"best_2_layer_lstm_model.keras\")\n",
    "best_5_layer_lstm_model = load_model(\"best_5_layer_lstm_model.keras\")\n",
    "best_gru_model = load_model(\"best_gru_model.keras\")\n",
    "best_lstm_cnn_model = load_model(\"best_lstm_cnn_model.keras\")\n",
    "\n",
    "# List of models and their names\n",
    "models = [best_base_lstm_model, best_2_layer_lstm_model, best_5_layer_lstm_model, best_gru_model, best_lstm_cnn_model]\n",
    "model_names = [\"Base LSTM (1-Layer)\", \"2-Layers LSTM\", \"5-Layers LSTM\", \"GRU\", \"LSTM + CNN (Conv1D)\"]\n",
    "\n",
    "# Dictionary to store the metrics\n",
    "model_performance = {\n",
    "    \"Model\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"F1 Score\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"TPR\": [],\n",
    "    \"TNR\": [],\n",
    "    \"FPR\": [],\n",
    "    \"FNR\": []\n",
    "}\n",
    "\n",
    "# Calculate metrics for each model\n",
    "for model_name, model in zip(model_names, models):\n",
    "    y_pred = (model.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Adjust y_test to match the length of y_pred\n",
    "    y_test_adjusted = y_test[-len(y_pred):]\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(y_test_adjusted, y_pred)\n",
    "    f1 = f1_score(y_test_adjusted, y_pred)\n",
    "    precision = precision_score(y_test_adjusted, y_pred)\n",
    "    recall = recall_score(y_test_adjusted, y_pred)\n",
    "    tpr, tnr, fpr, fnr = calculate_tpr_tnr_fpr_fnr(y_test_adjusted, y_pred)\n",
    "    \n",
    "    # Store the metrics\n",
    "    model_performance[\"Model\"].append(model_name)\n",
    "    model_performance[\"Accuracy\"].append(accuracy)\n",
    "    model_performance[\"F1 Score\"].append(f1)\n",
    "    model_performance[\"Precision\"].append(precision)\n",
    "    model_performance[\"Recall\"].append(recall)\n",
    "    model_performance[\"TPR\"].append(tpr)\n",
    "    model_performance[\"TNR\"].append(tnr)\n",
    "    model_performance[\"FPR\"].append(fpr)\n",
    "    model_performance[\"FNR\"].append(fnr)\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "performance_df = pd.DataFrame(model_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125453d1",
   "metadata": {},
   "source": [
    "**Function to Calculate TPR, TNR, FPR, FNR:**\n",
    "  - We used a helper function calculate_tpr_tnr_fpr_fnr to compute additional metrics based on the confusion matrix.\n",
    "- **Loading Models:**\n",
    "  - The models previously saved as .keras files are loaded into the environment. Each model corresponds to a different architecture: \n",
    "    - Base LSTM (1-Layer), 2-Layer LSTM, 5-Layer LSTM, GRU, and LSTM + CNN (Conv1D).\n",
    "- **Metrics Calculation:**\n",
    "   - For each model, predictions are generated using the test data.\n",
    "   - We calculated the accuracy, F1 score, precision, and recall using the sklearn.metrics functions.\n",
    "   - TPR, TNR, FPR, and FNR are computed using the previously defined function based on the confusion matrix.\n",
    "- The results are stored in a dictionary and then converted into a DataFrame for better visualization and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dee34d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base LSTM (1-Layer)</td>\n",
       "      <td>0.893204</td>\n",
       "      <td>0.883392</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.825137</td>\n",
       "      <td>0.174863</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-Layers LSTM</td>\n",
       "      <td>0.860841</td>\n",
       "      <td>0.849123</td>\n",
       "      <td>0.761006</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.792350</td>\n",
       "      <td>0.207650</td>\n",
       "      <td>0.039683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-Layers LSTM</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.781421</td>\n",
       "      <td>0.218579</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.889968</td>\n",
       "      <td>0.860656</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.928962</td>\n",
       "      <td>0.071038</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM + CNN (Conv1D)</td>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.837545</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.808743</td>\n",
       "      <td>0.191257</td>\n",
       "      <td>0.079365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  F1 Score  Precision    Recall       TPR  \\\n",
       "0  Base LSTM (1-Layer)  0.893204  0.883392   0.796178  0.992063  0.992063   \n",
       "1        2-Layers LSTM  0.860841  0.849123   0.761006  0.960317  0.960317   \n",
       "2        5-Layers LSTM  0.867314  0.859107   0.757576  0.992063  0.992063   \n",
       "3                  GRU  0.889968  0.860656   0.889831  0.833333  0.833333   \n",
       "4  LSTM + CNN (Conv1D)  0.854369  0.837545   0.768212  0.920635  0.920635   \n",
       "\n",
       "        TNR       FPR       FNR  \n",
       "0  0.825137  0.174863  0.007937  \n",
       "1  0.792350  0.207650  0.039683  \n",
       "2  0.781421  0.218579  0.007937  \n",
       "3  0.928962  0.071038  0.166667  \n",
       "4  0.808743  0.191257  0.079365  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b29918",
   "metadata": {},
   "source": [
    "**Detailed Analysis:**\n",
    "\n",
    " - **1) Base LSTM (1-Layer):**\n",
    "     - **Accuracy:** The highest accuracy among all models (0.8932).\n",
    "     - **F1 Score:** The highest F1 score (0.8834), indicating a strong balance between precision and recall.\n",
    "     - **Precision:** Fairly high precision (0.7962), meaning it’s good at minimizing false positives.\n",
    "     - **Recall/TPR:** The highest recall (0.9921), showing it’s excellent at capturing true positives.\n",
    "     - **TNR/FPR:** Moderate TNR and FPR, showing a balance between false alarms and missed detections.\n",
    " - **2) 2-Layers LSTM:**\n",
    "   - **Accuracy:** Lower than the Base LSTM (0.8608).\n",
    "   - **F1 Score:** Slightly lower (0.8491), indicating a bit of a trade-off in performance.\n",
    "   - **Precision and Recall:** Decent, but lower compared to the Base LSTM.\n",
    "- **3) 5-Layers LSTM:**\n",
    "   - **Accuracy and F1 Score:** Slightly better than the 2-Layers LSTM but still lower than the Base LSTM.\n",
    "   - **Recall:** On par with the Base LSTM, indicating good sensitivity.\n",
    "   - **TNR/FPR:** Lower than the Base LSTM, with a slightly higher rate of false positives.\n",
    "- **4) GRU:**\n",
    "    - **Accuracy:** Comparable to the Base LSTM (0.8900).\n",
    "    - **Precision:** The highest precision (0.8898), indicating it is very good at minimizing false positives.\n",
    "    - **Recall/TPR:** Lower recall compared to the Base LSTM (0.8333).\n",
    "    - **TNR/FPR:** The best TNR (0.9290), indicating a low rate of false positives.\n",
    "-  **5) LSTM + CNN (Conv1D):**\n",
    "   - **Accuracy and F1 Score:** The lowest among the models, but still reasonable.\n",
    "   - **Precision:** Good precision (0.7682) but lower than the Base LSTM and GRU.\n",
    "   - **Recall:** Lower recall (0.9206) compared to the Base LSTM.\n",
    "   - **TNR/FPR:** Moderate TNR and FPR, indicating some trade-off in performance.\n",
    "\n",
    "#### Conclusion: Choosing the Best Model\n",
    "\n",
    " - Based on the evaluation metrics, \n",
    "    - **the Base LSTM (1-Layer) model** stands out as the best overall model for this task. \n",
    "    - It achieves the highest accuracy (0.8932), the highest F1 score (0.8834), and excellent recall (0.9921), indicating that it effectively captures the uptrends in the SPY ETF while maintaining a good balance between false positives and false negatives.\n",
    "\n",
    "-  While the GRU model offers the highest precision, it does so at the cost of recall, which might lead to missing some potential uptrends. \n",
    "\n",
    "- The Base LSTM provides the best overall performance, making it the preferred choice for implementing the trading strategy in the subsequent backtesting phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cbde09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.to_csv(\"Deep_Learning_Models_Performance.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8670a4",
   "metadata": {},
   "source": [
    " - Saved the all models performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472cbc3",
   "metadata": {},
   "source": [
    "### Evaluating the Best Model with ROC Curve, Confusion Matrix, and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760cf9b0",
   "metadata": {},
   "source": [
    "#### Loading and Predicting with the Best Model (LSTM Single Layer)\n",
    "\n",
    " - In this step, we load the best LSTM model and use it to make predictions on the test data. After predictions are made, we will align the test data with the predictions to ensure consistency in the evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8090c6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "y_test_trimmed length: 309, y_pred_prob length: 309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model(\"best_base_lstm_model.keras\")\n",
    "\n",
    "# Align y_test to the length of predictions\n",
    "y_test_trimmed = y_test[lookback:]\n",
    "\n",
    "# Predicted probabilities and labels\n",
    "y_pred_prob = best_model.predict(test_generator).ravel()\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "# Ensure that y_test_trimmed and y_pred_prob have the same length\n",
    "print(f\"y_test_trimmed length: {len(y_test_trimmed)}, y_pred_prob length: {len(y_pred_prob)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d5688",
   "metadata": {},
   "source": [
    "#### Confusion Matrix of the Best Model (LSTM Signle Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "89bd00b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[151  32]\n",
      " [  1 125]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAIxCAYAAACo8+J5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbKElEQVR4nO3dd3yNd+P/8ffJkpAlVogdxAiCIJGWohS196bLaPWuttwdd6fqt63RW7mrw93W6t3aM/au4LY3sUcQIyEyZZ3fH37OLU0Ql3Au9Xo+Hh6Pnuv6nOu8z8mjjnc+1/W5LFar1SoAAAAAwH1xsHcAAAAAAHgcUaYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAACSpKSkJP3nP/9R37591aRJE4WFhalHjx6aOnWqUlNTH/rrR0dHa9CgQQoLC1OTJk106NChPD3+Dz/8oODgYJ06dSpPj3svn3zyiYKDgxUcHKzz58/fcdznn3+u4OBgtWnTxtDrZGZmKioqKldjg4OD9d577xl6HQDA/zjZOwAAwP7OnDmjt99+W2fPnlXz5s3VqlUrWa1WbdmyRePHj1dERITGjx+vfPnyPbQMY8eO1fbt2/Xyyy+raNGiKlOmTJ4ev0mTJipVqpQKFy6cp8e9H+vWrVPPnj2zbc/IyND69esNHzchIUGvvvqq6tatq9dff/2e40eMGKESJUoYfj0AwE2UKQB4wqWmpmrYsGGKjY3VlClTFBAQYNvXo0cPTZs2Td98843GjRund95556HlOH78uMqXL69BgwY9lONXrFhRFStWfCjHzg0/P787lqldu3YpNjZWBQsWNHTs69ev6+DBg6pbt26uxrdq1crQ6wAAsuI0PwB4ws2ePVsnTpzQm2++maVI3dKnTx+VL19eS5YsUWJi4kPLkZaWpvz58z+049tb48aNtWfPHl27di3bvjVr1qhChQry8/N79MEAAIZRpgDgCbd8+XIVKFBALVq0uOOYcePGadmyZSpQoIBt2/HjxzV8+HA1adJEDRo0UM+ePTV//vwsz1u0aJGCg4N1+PBhffLJJ2ratKnCwsI0ePBgHT58WJK0fft2BQcH68KFC9q/f7+Cg4P1ySef6Pz58woODtaECROyHPPGjRu2Mbdcv35dn376qZ5//nmFhoaqdevWGj16tOLj421jcrpmKi4uTqNGjVKrVq0UEhKidu3a6V//+pdSUlJsY27lWLRokX788Ue1bt1aDRo0UPfu3bVy5cpcf87PPPOMMjIy9Mcff2TZbrVatW7dOjVt2jTH5+3YsUNvvvmmnn32WdWvX1/PPfecPvzwQ0VHR9s+v7Zt20qSpkyZYrs269bnumjRIvXq1UsNGjTQm2++KSnrNVNz5sxRcHCwvvzyyyyv+9lnnyk4OPiBTj8EgL86TvMDgCeY1WrV4cOHFRQUJCenO38l/Pn6mkOHDmnAgAFycXFRt27d5OXlpTVr1mjkyJE6ffq03njjjSzjhw8frpIlS2rQoEG6fPmypk+frqFDh2rx4sUqV66cRowYoa+//lru7u4aMGCASpYseV/v45133tGRI0fUrVs3FS1aVJGRkZo1a5bOnj2r8ePH5/ic+Ph4vfTSSzp79qzat2+vihUrat++fZo8ebJ27dql77//Xs7OzrbxP/74oxwdHdWtWzc5ODjoP//5j95//32VK1dOFSpUuGfGKlWqqHjx4lq7dm2WRSb27dunS5cuqUmTJoqIiMjynK1bt+r1119XQECAXn75ZTk5OWn37t1atmyZLl68qB9//FHlypXTW2+9pa+//lpPP/20mjVrpoIFC9oWuxg1apSaNWum9u3bZynDt3Tq1Elr1qzR3Llz1bp1awUGBmrjxo1asGCB2rdvr0aNGuXqZwAATyLKFAA8wa5evaqMjAwVKlTovp43evRoZWZmasqUKbbi07VrVw0bNkzTpk1Ty5YtValSJdv4cuXKZSk1Tk5O+vHHH7V9+3aFhISoVatW+u677+Tt7W27nuduK9/dLjY2Vtu2bdMbb7yhPn362Lbny5dPu3btUkpKilxdXbM9b+rUqTp16pQ+++wztWzZUpLUuXNnVaxYUePGjdPs2bPVo0cP2/jU1FTNmTNH7u7ukqTKlStr4MCBWr58ea7KlHRzdmru3LlZMq1Zs0ZlypSRv79/tvG//vqrvL299eOPP9rGd+7cWcnJyVq/fr2uXbumQoUK6ZlnntHXX3+t8uXLZ7seyt/fXx9++KEsFssdc3344Yfq1q2b/u///k8TJ07UyJEj5efnp7feeitX7wsAnlSc5gcATzBHR0dJN1eTy62YmBjt3btXzZs3zzKD5ODgoBdffFGStHbt2izPadasWZbHt67NiomJMZT7du7u7sqfP79mz56tVatWKSEhQZI0dOhQTZkyJcciJd1cWc/Pzy/b6Y3du3dXgQIFsr2H0NBQW5Ey+h4aN26sGzduaPPmzbZta9euveMpfl9//bVmzJiR5T0kJCTYHt9+OuKdhIaG3rVISZKvr6/efPNNHTlyRP369dPVq1c1YsSIv/Q1bACQF5iZAoAnmJeXl1xcXBQbG5vr51y4cEGScly6vGzZslnG3PLnVepunT6XmZl5P3Fz5OLiovfff1+ff/653n33XTk6OqpGjRpq1KiR2rdvn6UA3e78+fOqU6dOtqLh5OSkkiVLPpT3EBQUJB8fH61bt06NGzfW4cOHde7cOTVp0iTH8Y6Ojrp06ZJ++uknHT9+XOfOndP58+dltVpz/dq5XSGwffv2Wr58ubZt26auXbuqZs2auX5fAPCkYmYKAJ5wNWvW1KFDh5SWlnbHMbNnz9Zbb72lo0eP2v4hn5NbM1y3X2sk3Zy1yis5zaK1aNFCS5Ys0SeffKImTZroxIkTGjdunLp3766rV6/meJx7vY+H8R4cHBzUsGFDbdy4Uenp6VqzZo38/PxUuXLlHMfPnz9fPXv21MaNG+Xr66tu3bpp0qRJ6tWr1329Zm5cu3ZNJ06ckCRt2rQpV7NeAPCko0wBwBOuSZMmSklJ0bJly3Lcn5mZqblz5yoiIkIeHh62xShuXxXvllvbihUr9sC5bpWA1NTULNv/fFpdYmKidu3aJavVqtatW+uLL77QihUrNHjwYEVHR2v58uU5Hr9EiRI6depUtlKVmpqqCxcuyNfX94HfQ06eeeYZxcXFadeuXVq7du0dZ6Vu3LihMWPGqGbNmpo1a5Y++ugj9ezZU0FBQXcsiA9i1KhRunbtmoYOHaqoqKhsqygCALKjTAHAE659+/YqVaqUvvnmG0VGRmbb/9133+nIkSN6/vnn5evrq0KFCql69epauXKloqKibOMyMzM1efJkScqTFeC8vb3l6OiYLdOfy9Hhw4f1yiuvaN68ebZtjo6Oqlq1qiTdcZXCZ555RufPn89WImfMmKHExEQ1bNjwgd9DTurXr68CBQpo+vTpOnny5B2vl7px44ZSUlJUqlSpLO8hKipKGzZskPS/WbpbxdPoaZNr167VihUr1Lt3b/Xu3VstWrTQzJkztXPnTkPHA4AnBddMAcATztnZWWPGjNFrr72m/v37q3nz5qpevboSExO1YcMG7dmzRzVq1NDbb79te86wYcM0cOBA9evXT127drUtjb5z50716tVLFStWfOBcrq6uaty4sVatWqUPP/xQderU0b59+/THH3/Iy8vLNq5WrVqqWbOmvv/+e0VHRysgIEBXrlzRrFmzVLhw4WyLX9zSr18/rVmzRp988on27NmjChUqaP/+/QoPD1f16tXVqVOnB34POXF2dlZYWJhWrFihYsWKqVq1ajmO8/T0VI0aNbR06VJ5enqqfPnyOnPmjObPn287JfPWTZRvFc+IiAiVKVPmjrNdObl27Zq+/PJL+fn56ZVXXpEkvfXWW9q0aZNGjBih33///Y6LeADAk46ZKQCA/P399euvv6pPnz6KjIzUhAkT9OOPPyo5OVlDhw7Vjz/+mOUeRdWqVdPkyZMVFBSk33//XRMmTFBKSoo+/vhj241h88J7772nNm3aaNOmTRozZowuXbqkH374QR4eHrYxDg4OGjt2rDp37qxNmzZp1KhRmjlzpurVq6effvopS/G6nYeHh37++Wd17NhR69ev19ixY7Vnzx699NJL2e4xlddulZ3GjRvfdaW9L7/8Uk2aNNHSpUs1duxYbdiwQR07dtS//vUvSTfvQyXdLJ6vvfaaYmJiNHr0aB05ciTXWUaNGqWYmBi99957ttLk4+Ojv/3tb5zuBwD3YLHe7QpcAAAAAECOmJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAJ3sHMBO3WkPsHQEAYGebF3xh7wgAABMIKu1xzzHMTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAMoUAAAAABhAmQIAAAAAAyhTAAAAAGAAZQoAAAAADKBMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAMoUAAAAABhAmQIAAAAAAyhTAAAAAGAAZQoAAAAADKBMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGmLlMZGRmKi4tTRkaGvaMAAAAAQBZO9g6QkzNnzmj+/Pk6cuSIMjIy9N5772nVqlUqXry4WrZsae94AAAAAGC+mamTJ09q1KhRunr1qpo0aSKr1SpJ8vT01IIFC7RhwwY7JwQAAAAAE85MzZ07V/7+/nrjjTdktVq1YsUKSVLnzp2Vmpqq9evXq2HDhnZOCQAAAOBJZ7qZqVOnTqlx48ZycHCQxWLJsi8oKEiXL1+2UzIAAAAA+B/TlSlnZ2clJyfnuC8+Pl7Ozs6POBEAAAAAZGe6MlWtWjUtXrw42wxUcnKyVq5cqSpVqtgpGQAAAAD8j+mumerYsaO++uorffrpp/Lz85MkzZw5UxcvXpTFYtHgwYPtnBAAAAAATFimChYsqA8//FArV65UZGSkihQporS0NIWEhOjZZ5+Vl5eXvSMCAAAAgPnK1OXLl1WkSBG1b9/e3lEAAAAA4I5MV6Y+/PBDlS9fXiEhIapbt67c3NzsHQkAAAAAsjHdAhT9+vWTq6urfv/9dw0fPlw//PCD9uzZo8zMTHtHAwAAAAAbi9Vqtdo7RE7i4+O1bds2bdu2TSdPnpS7u7vq1q2r+vXrq2zZsg/lNd1qDXkoxwUAPD42L/jC3hEAACYQVNrjnmNMW6Zud+XKFa1atUrr16+X1WrV999//1BehzIFAKBMAQCk3JUp010zdburV69q+/bt2r59u06fPi1vb2/Vr1/f3rEAAAAAwHxlKjExUTt27NC2bdt07NgxOTs7q1atWmrfvr0qV64si8Vi74gAAAAAYL4yNXz4cFmtVlWqVEl9+/ZV7dq1lS9fPnvHAgAAAIAsTFem2rZtq/r166tgwYL2jgIAAAAAd2SKMpWZmSkHh5urtDdv3ty27U5ujQUAAAAAezFFmXr11Vc1fPhw+fv769VXX73rWIvFou++++4RJQMAAACAnJmiTD3//PPy8fGx/TcAAAAAmJ0pylSbNm1y/O8/s1qtunr16qOIBAAAAAB3ZbqLjwYNGqTjx4/nuC8yMlKffvrpI04EAAAAANmZYmZq5syZSkxMtD0ODw+Xh0f2Ow5HRUXJ2dn5UUYDAAAAgByZokz5+fkpPDzc9jgqKkpOTlmjOTg4yM3NTT179nzU8QAAAAAgG1OUqbCwMIWFhUm6eZrfwIED5e/vb+dUAAAAAHBnpihTt/v+++/tHQEAAAAA7sl0ZUqSjh8/rsjISKWnp9u2ZWZmKjU1VUePHtU//vEPO6YDAAAAABOWqbVr12rGjBk57rNYLKpWrdojTgQAAAAA2ZmuTK1bt05Vq1bVSy+9pOXLlys5OVldunTRvn37NGXKFNWtW9feEQEAAADAfPeZunLliho1aqQCBQqobNmyOnr0qFxcXFSnTh01b95ca9eutXdEAAAAADBfmXJycpKLi4skqWjRorp06ZIyMjIkSf7+/rp48aI94wEAAACAJBOWqVKlSmn37t2SpGLFikmSTp48KUm6du2anVIBAAAAQFamu2bq2Wef1ffff6+kpCS99NJLCgoK0k8//aSgoCBt27ZNFStWtHdEAAAAADDfzFRQUJBee+01lSxZUpLUq1cvFStWTBs3blSJEiXUvXt3OycEAAAAAMlitVqt9g5hFm61htg7AgDAzjYv+MLeEQAAJhBU2uOeY0x3mt+RI0fuuM/BwUH58uVTkSJF5Orq+ghTAQAAAEBWpitTX3/99T3HODg4KCwsTD169JCDg+nOVAQAAADwBDBdmRoyZIh++OEH1a9fX/Xq1ZOnp6fi4+O1Y8cO/fHHH+rUqZMsFosWLFggHx8ftWzZ0t6RAQAAADyBTFemli1bpqefflpdu3a1bfP19VXFihXl4uKiXbt26e2331ZmZqbWr19PmQIAAABgF6Y7R+7UqVOqWrVqjvsqVapku+dUyZIlFRsb+yijAQAAAICN6cqUl5eXIiMjc9wXGRkpD4+bq2okJCTIzc3tUUYDAAAAABvTnebXqFEjzZ07V2lpaapdu7Y8PDx0/fp17dy5Uxs2bFCbNm0UGxurpUuXKiAgwN5xAQAAADyhTFemmjdvrtTUVC1fvlzr1q2zbXdzc1Pbtm3VsmVLRUREKCMjQx06dLBfUAAAAABPNNPetDc1NVXHjx9XQkKCChYsqJIlS9ruLZWZmflQlkTnpr0AAG7aCwCQcnfTXtNdM3WLxWKRk9PNibPixYsrOTnZto97SwEAAACwN9Od5idJ69ev14IFC5SUlCRJev/99zVv3jxJ0uDBg+Xi4mLPeAAAAABgvpmpzZs367ffflPt2rU1ZMj/TrsLDQ3V8ePHtWjRIjumAwAAAICbTDcztWLFCjVs2FA9e/ZUZmambXu9evV09epVbdiwQZ06dbJjQgAAAAAwYZm6dOnSHctS6dKlFRcX94gTAY+/YS8212s9nlG5Zu9n2/fRq8/rvVda5vg836eHKy4hOdt2L3c37Z73oT7/YYn+PXtjnucFADxch/fv1ozJ3+nk0cNyccmn2iFPq+dLQ+TpXdA25lrsFf3287favW2T4q/HqVDhYnqqaQt16vWynJyd7ZgeMA/TlSlPT0+dO3dOgYGB2fZduHBBnp6edkgFPL6ah1XVh4NaKTYuKcf91fxL6PT5GH3y7eJs+xJTbmTb5uLspN/GvCzfwvy/CACPo8gDezRi2ECVKFVW3foPVkLCdYXP/lWH9+3SFxOnyS1/AaXeSNGI4YN1Kfq8mrfprOJ+pXRo/27N/fUnnTlxVMNHfG3vtwGYgunKVN26dRUeHi5vb2/VqFHDtv3EiRNaunSpQkJC7JgOeLwM6tZQX73dUS7Od/5fvWqF4tp58Ix+X7LtnscrXbygpn35ourVKJeXMQEAj9D0H7+Rh5e3Roz7SfkLuEuSylesolEfvql1yxepZYfuWrZgps6dOam/j/hadUIbSpKatemswkV9teD3ydq/e7sCg4Lt+TYAUzBdmWrbtq3Onz+vX375xbZtzJgxSk1NVaVKldS2bVs7pgMeH+unvK16NcopfP0++Rbxkl9R72xj3FydVc6vsGYt33HP47VrUlM/j+yntPQMTZi+Rq/3bvIQUgMAHqb0tDQVcPdQ4+fa2oqUJFWrWUeSdOp4pCTpwO7t8vDythWpWxo801wLfp+syP27KVOATFimnJycNGTIEB06dEiHDx9WQkKC8ufPr0qVKikwMFAWi8XeEYHHgl8xb73y0TRNX/RfLZ/0Ro5jqpQvLkdHBx0+ES3pZrlKuZGunO7lXbVCcS3ZsE/vj5uvsn6FKVMA8BhycnbWu59/k237qeNHJEmFivhKkgYP/1jxcdeyjbsed1WS5ODo+PBCAo8R05WpW6pUqaIqVarYOwbw2KrS+hOlpWfcdUy1CiUkSU3qV9bIv7VTqeI+up6QrN+WbNP7/5yvpJRU29gxP6+0Ha+sX+GHFxwA8MjEXrmkyAN7Ne2Hf8qrYCE9+3xHSZJ3wULyLlgo2/il836XJFWpXuuR5gTMyhRlavPmzfc1PjQ09CElAf467lWkJKlaheKSpODAMhr5wxJdT0hRi6eqaWDXhqpczlctB06wzVLl5ngAgMdHRka6XuvVRpmZGXJwcNTgYR/Jp3CRO45fuWi2dm75Q1Vr1lHlwKBHFxQwMVOUqSlTptzXeMoUkDfW/DdSSSmpGvvLSiUm35yFmr96t2KuJeit/s3UrklNzV+9274hAQAPRUZ6ul79+ydysFi0ZukCfTvqY8VcvqgOPV/MNnbDynD99K9R8vYppNf+/qkd0gLmZIoy9dlnn911/5EjRzR79mwlJyerYcOGdx0LIPdWRBzUioiD2bb/MPMPvdW/mRrVrUSZAoC/KJd8rnq66c37DIY+01wfv/my5kz/t55t3VEent62ceFz/6Np3/9T7p5e+seX36pwUV87JQbMxxRlqkiRnKeU09LSNH/+fK1Zs0YFCxbUgAEDuI4KeAQuX42XJLnnz2fnJACAR8HBwUEhDZvqyMG9OnfmlO00vpmTv9ecX/+tgj6F9cGoiSpZprx9gwImY4oylZOTJ09q8uTJunjxosLCwtSlSxe5urraOxbwl7Lw29fk7OSglgMnZNkeULaYJOlk1BV7xAIAPCTR587q83eH6NnnO6hd9/5Z9iUn3by5u4vLzV+kzf31J8359d8qVqKkPvjyWxUt7veo4wKm52DvAH+WkZGhefPmafTo0bpx44aGDBmiPn36UKSAhyDmWoKeqRegsFr+tm0Wi0XvD2yl9PSMXN1/CgDw+Cha3E/JyYlavWSebqSk2LYnxF/XmqXzVahIMZX1r6S9O7Zo5pTvVay4nz79+t8UKeAOTDUzdebMGU2ePFnnz59X/fr11b17d7m5udk7FvCX9dGEhWoeVlVzvhmkib+v06WYeHV4tpYaBlfUx/9apKOnL9k7IgAgDzk4OOiVN97T1yPe0UdDX9Qzz7XVjRspWrV4jq5djdHfR/xTDo6O+nXSeFmtVtUOaaj9u7ZmO06psv4qWyHADu8AMBdTlKnMzEyFh4dr2bJlcnd316uvvqoaNWrYOxbwl3c2+qqavPC1Pn2tjQZ3b6R8zk46dCJaL34wRb+Fb7N3PADAQ1D/6aYa/ulYzfvtF/06abycnJ0VUK2mhn7whSpUDlRiQrztJr5L5/2W4zHadetHmQIkWay3biJjRyNHjlRUVJTy58+vFi1aqECBAncdHxYW9lByuNUa8lCOCwB4fGxe8IW9IwAATCCotMc9x5hiZioqKkqSlJSUpLlz595z/MMqUwAAAACQW6YoU59//rm9IwAAAADAfTFFmSpUqJC9IwAAAADAfTHd0ugAAAAA8DigTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAU6zmN3r06FyPtVgsGjZs2ENMAwAAAAD3Zooy5eDABBkAAACAx4spytTbb79t7wgAAAAAcF8euymhc+fO2TsCAAAAAJhjZup2CQkJmjdvno4cOaL09HRZrVZJktVqVWpqqpKTk/X999/bOSUAAACAJ53pZqZmzZqlTZs2ydfXV05OTnJ3d1f58uUlSSkpKerTp4+dEwIAAACACWemDhw4oNatW+v555/XqlWrFBkZqQEDBiglJUWjR4/mND8AAAAApmC6mamkpCTbTFSJEiV0+vRpSZKrq6ueffZZ7du3z57xAAAAAECSCcuUh4eHkpOTJUlFixbV9evXlZCQIEny9vbWtWvX7JgOAAAAAG4yXZmqXLmyli5dqkuXLqlw4cLy8PDQ5s2bJUl79+6Vu7u7nRMCAAAAgAnLVNu2bZWYmKjJkydLklq0aKE5c+bojTfe0Nq1a9WgQQP7BgQAAAAAmXABikKFCunTTz9VdHS0JKlp06by8PDQsWPHVK5cOYWGhto5IQAAAACYsExJkrOzs0qVKmV7XK9ePdWrV8+OiQAAAAAgK9OVqcWLF99zTOvWrR9BEgAAAAC4s8eqTOXLl0+enp6UKQAAAAB2Z7oyNXHixGzbkpOTFRkZqZkzZ6pv3752SAUAAAAAWZluNT8HB4dsfwoUKKDatWurZcuWmj17tr0jAgAAAID5ytTdFC1aVOfOnbN3DAAAAAB4fMpUWlqaNmzYIC8vL3tHAQAAAADzXTP17rvvZttmtVqVkJCgjIwMde3a1Q6pAAAAACAr05WpypUrZ9tmsVjk6uqqmjVr5rgfAAAAAB4105Wp/v3733V/RkaGHB0dH00YAAAAALgD010z9Y9//ENnzpzJcd+xY8c0fPjwR5wIAAAAALIzxczUsmXLlJqaKkmKiYnRmjVr5OPjk23ciRMnZLVaH3U8AAAAAMjGFGUqMzNTS5YssT3esmVLtjEWi0Vubm5q27bto4wGAAAAADkyRZlq1aqVWrVqJUkaNGiQhg0bpgoVKtg5FQAAAADcmemumfr8889Vrlw5Xbp0ybYtISFBR48etWMqAAAAAMjKdGUqX758Gjt2rMaPH2/bdvLkSY0dO1bjxo1TcnKyHdMBAAAAwE2mK1Nz5sxRTEyMunfvbttWrVo1vfHGG4qOjtaCBQvsmA4AAAAAbjJdmdq/f786duyowMBA2zYHBwdVqVJFbdu21e7du+0XDgAAAAD+P9OVqRs3bihfvnw57nN3d1dCQsIjTgQAAAAA2ZmuTJUuXVobN27McV9ERIRKlSr1iBMBAAAAQHamWBr9dq1atdKECRM0YsQI1apVS56enoqPj9fu3bsVFRWl119/3d4RAQAAAMB8Zapq1ap67bXXtGjRIoWHh9u2lypVSq+99prKly9vx3QAAAAAcJPpypQkBQYGKjAwUGlpaUpMTJSbm5uio6O1YcMGTZo0Kcuy6QAAAABgD6YsU7c7ePCg1q9fr9OnT0uS/P397ZwIAAAAAExapi5evKj169dry5YtSkpKko+Pj1q1aqXQ0FAVKVLE3vEAAAAAwDxlKjMzU7t379b69esVGRkpJycnBQYGavfu3XrppZeYkQIAAABgKqYoUwsXLlRERITi4uJUunRpdevWTfXr15eDg4OGDh1q73gAAAAAkI0pytSSJUvk5+enAQMGZJmBunHjhh1TAQAAAMCdmaJMhYWFaceOHRo7dqwqVKig0NBQ1alTx96xAAAAAOCOTFGm+vTpo27dumnHjh2KiIjQlClT9Pvvv6tGjRr2jgYAAAAAObJYrVarvUP82aVLlxQREaEtW7YoLi5OPj4+qlu3roKDg1WqVKmH9rputYY8tGMDAB4Pmxd8Ye8IAAATCCrtcc8xpixTt2RmZurAgQPauHGj9u/fr4yMDPn6+uqTTz55KK9HmQIAUKYAAFLuypQpTvO7EwcHB1WvXl3Vq1dXfHy8Nm/erE2bNtk7FgAAAACYu0zdzsPDQ82bN1fz5s3tHQUAAAAA5GDvAAAAAADwOKJMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMcMrNoLffftvQwceOHWvoeQAAAABgdrkqU+Hh4fd9YIvFQpkCAAAA8JeVqzJ1+PDhh50DAAAAAB4rD3zNVGZmpq5cuaLU1NS8yAMAAAAAjwXDZers2bP629/+pjp16ujpp5/Wjh07tGXLFnXt2lU7d+7My4wAAAAAYDqGytTZs2fVuXNnRUREqH79+rbtVqtVR44c0QsvvKC9e/fmWUgAAAAAMBtDZWrs2LFycnJSeHi4/u///k9Wq1WSFBoaqkWLFsnb21vffvttngYFAAAAADMxVKY2b96sHj16yNfXVxaLJcu+UqVKqVevXtq3b1+eBAQAAAAAMzJUplJSUlSoUKE77ndzc1NSUpLhUAAAAABgdobKlL+/vzZu3JjjPqvVquXLl6t8+fIPFAwAAAAAzMxQmerbt69Wr16tL774QkePHpUkJSYmau/evRoyZIh27NihHj165GlQAAAAADCTXN2098/at2+vqKgoTZw4UVOnTpUkvf7665Juzky98MIL6tKlS96lBAAAAACTMVSmJGnIkCFq166dVq5cqTNnzigzM1MlS5ZUkyZNVKFChbzMCAAAAACmY7hMSTdX7nvxxRfzKgsAAAAAPDYMl6nY2FhNmjRJ69at0/nz5+Xo6KgyZcqoWbNmeuGFF+Tm5paXOQEAAADAVAwtQHH27Fm1bdtWv/zyizIzM1W/fn3Vrl1b8fHxGj9+vLp27apr167lcVQAAAAAMA9DM1NjxoxRYmKifvjhBzVq1CjLvmXLlmn48OEaM2aMRo4cmSchAQAAAMBsDM1MRUREqF+/ftmKlCS1aNFCvXv31sqVKx84HAAAAACYlaEy5eDgIG9v7zvuL1OmjNLT041mAgAAAADTM1SmWrRooVmzZikpKSnbvrS0NM2fP19NmzZ94HAAAAAAYFa5umZqxowZWR6XL19eixYtUuvWrdWjRw+VK1dODg4OioqK0pw5c3T58mX17dv3oQQGAAAAADOwWK1W670GVa5cWRaLRbkY+r8DWyw6dOjQA4V71NxqDbF3BACAnW1e8IW9IwAATCCotMc9x+RqZmrq1KkPHAYAAAAA/kpyVabq1av3sHMAAAAAwGPF0H2mbjl06JASExOznP6Xnp6uxMREbd68WR9++OEDBwQAAAAAMzJUpo4dO6bBgwcrKirqjmMsFgtlCgAAAMBflqEy9c9//lMXLlxQnz595OTkpJ9//lnvvvuu4uLitGDBAsXGxmrevHl5nRUAAAAATMPQfaa2b9+uzp076/3339ff/vY3OTo6qnLlynrjjTc0Z84ceXl5afr06XmdFQAAAABMw1CZSkxMVLVq1SRJrq6uKlWqlA4cOCBJKliwoDp37qyNGzfmXUoAAAAAMBlDZcrb21sJCQm2x6VLl9bRo0dtj4sXL65Lly49eDoAAAAAMClDZapu3bqaNWuWYmJiJEkBAQHavHmzkpOTJUm7du2Sh8e9b3IFAAAAAI8rQ2Vq4MCBOn/+vJo0aaKrV6+qS5cuiomJUbt27dS3b1/NnTtXjRs3zuusAAAAAGAahspU5cqVNXv2bHXq1EkFCxZU6dKlNXHiRGVkZOjgwYNq1aqVhg8fntdZAQAAAMA0LNbb77j7hHOrNcTeEQAAdrZ5wRf2jgAAMIGg0ve+bClX95lKTU01FMDFxcXQ8wAAAADA7HJVpmrUqCGLxXJfB7ZYLDp48KChUAAAAABgdrkqU+3bt7/vMgUAAAAAf2W5KlNffvnlw84BAAAAAI8VFqC4TUq6vRMAAOzN78Xf7B0BAGACMVN73HOMoaXRAQAAAOBJR5kCAAAAAAMoUwAAAABgAGUKAAAAAAzI1Wp+d5Kenq79+/fr/PnzqlevnlxdXZWRkSEvL6+8ygcAAAAApmR4ZmrFihVq3LixevToobfffltHjx7Vjh071KhRI/388895mREAAAAATMdQmdq8ebOGDh0qX19fvfnmm7q1unrx4sVVtmxZjR49WosXL87ToAAAAABgJobK1MSJExUQEKD//Oc/6tKli217pUqVNHPmTAUGBmrKlCl5FhIAAAAAzMZQmdq/f7/atWsnZ2fnbPtcXFzUvn17nThx4oHDAQAAAIBZGSpTDg53f1pCQoIsFouhQAAAAADwODBUpoKCgjR//nxlZmZm25eQkKCZM2eqZs2aDxwOAAAAAMzKUJl6/fXXdfz4cXXr1k0zZsyQxWLR9u3bNWnSJLVp00YXL17U4MGD8zorAAAAAJiGxXprKb77FBERoY8//lhRUVFZthctWlQfffSRnn322TwJ+CilpNs7AQDA3vxe/M3eEQAAJhAztcc9xxi+aW9YWJhWrlypgwcP6vTp07JarfLz81NgYKCcnB7oXsAAAAAAYHoP1HosFouqVaumatWq5VUeAAAAAHgsGCpT77333j3HWCwW/d///Z+RwwMAAACA6RkqU/Pmzbvrfm9vb3l5eRkKBAAAAACPA0Nlau/evdm2paen68qVK1q8eLH+85//6LvvvnvgcAAAAABgVoaWRndxccn2J3/+/CpdurReffVVPfPMM/ryyy/zOisAAAAAmIahMnUvNWvW1LZt2x7GoQEAAADAFB5Kmdq2bZvy5cv3MA4NAAAAAKZg6Jqpr7/+OsftqampOnjwoLZt26aOHTs+UDAAAAAAMDNDZerHH3+88wGdnPTcc8/pnXfeMRwKAAAAAMzOUJlavXp1jtsdHR3l7e0tV1fXBwoFAAAAAGZnqEyNHDlSrVq1Ups2bfI6DwAAAAA8FgwtQBEREaGEhIS8zgIAAAAAjw1DZapChQo6cOBAXmcBAAAAgMeGodP8+vTpo88++0zHjh3TU089JR8fHzk6OmYb161btwcOCAAAAABmZLFardb7fVLlypXvfWCLRYcOHTIUyl5S0u2dAABgb34v/mbvCAAAE4iZ2uOeYwzNTE2dOtXI0wAAAADgLyNXZapv374aPHiwQkNDJUn16tV7qKEAAAAAwOxytQDF1q1bdeXKlYedBQAAAAAeG4ZW8wMAAACAJx1lCgAAAAAMyPUCFNu3b1dGRsZ9Hbx9+/b3mwcAAAAAHgu5Whq9cuXKslgsuT6o1WplaXQAwGOJpdEBAFIeL43etWtXBQUFPUgeAAAAAPjLyHWZCg4OVps2bR5mFgAAAAB4bLAABQAAAAAYQJkCAAAAAANyVaY6dOig0qVLP+wsAAAAAPDYyNU1U1988cXDzgEAAAAAjxVO8wMAAAAAAyhTAAAAAGAAZQoAAAAADKBMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMcLJ3gDu5evWqIiMjde3aNYWGhiouLk5+fn5ydHS0dzQAAAAAMGeZmjt3rlatWqXMzExJUtWqVTVnzhwlJCRo6NCh8vDwsHNCAAAAAE86053mt3LlSq1cuVJt2rTRxx9/bNveqlUrxcXFaeHChXZMBwAAAAA3ma5MrV+/Xi1atFDLli1VrFgx2/aAgAC1adNG+/bts2M6AAAAALjJdGXq6tWr8vf3z3Ff0aJFFR8f/4gTAQAAAEB2pitTPj4+OnbsWI77Tp48qUKFCj3iRAAAAACQnekWoHjqqae0YMECubi4qGbNmpKk5ORkbdu2TcuXL1fLli3tnBAAAAAAJIvVarXaO8TtrFarfvvtN23YsCHbvpCQEPXr108Wi+WhvHZK+kM5LADgMeL34m/2jgAAMIGYqT3uOcZ0M1MWi0U9e/ZU06ZNFRkZqYSEBOXPn1+VKlVSiRIl7B0PAAAAACSZsEwtXLhQISEhKlasWJbV/AAAAADATExXplavXq0lS5aobNmyCg0NVXBwsAoUKGDvWAAAAACQhemumUpNTdWePXu0bds2HThwQJIUGBio0NBQVa9eXY6Ojg/ttblmCgDANVMAACl310yZrkzdLjExUTt27NC2bdt07Ngx5c+fX8HBwerR495vzAjKFACAMgUAkHJXpkx3n6nbFShQQA0bNlSPHj3UsGFDJSUlaf369faOBQAAAADmu2bqlitXrmjr1q3atm2bLly4IB8fHz333HMKDQ21dzQAAAAAMF+ZWrNmjbZu3apTp04pX758qlWrlrp3766AgAB7RwMAAAAAG9OVqVmzZikgIED9+/dX7dq15eLiYu9IAAAAAJCN6crUF198IW9vb3vHAAAAAIC7MkWZioiIUI0aNeTh4WFbDv1uwsLCHkEqAAAAALgzU5SpadOmafjw4fLw8NC0adPuOZ4yBQAAAMDeTHGfqZiYGHl5ecnJyUkxMTH3HF+oUKGHkoP7TAEAuM8UAEB6jO4zVahQITk53ZwkO3LkiPLly6dChQpl++Pg4KDt27fbOS0AAAAAmKRMZWZm2v5MmTJF0dHRWbbd+hMZGalFixbZOy4AAAAAmOOaqTFjxujEiRNZHt9JmTJlHkUkAAAAALgrU5SpPn362E7fCw8PV4MGDVSwYMEsYxwcHJQ/f37VrVvXHhEBAAAAIAtTlKnixYurTZs2km4uRtGyZUsVKVLEzqkAAAAA4M5MUaYyMzPl4HDz8q2+ffvatt3JrbEAAAAAYC+mKFOvvvqqhg8fLn9/f7366qt3HWuxWPTdd989omQAAAAAkDNTlKnnn39ePj4+tv8GAAAAALMzxU17zYKb9gIAuGkvAEDK3U17TTEz9WcxMTFKTU1V8eLFlZKSovnz5ysmJkZ169ZVvXr17B0PAAAAAMxx097bHTp0SB999JEiIiIkSb/++qvWr1+vK1eu6Oeff9bmzZvtnBAAAAAATFimFi9erAoVKqhFixZKSUnRrl279Nxzz+njjz9W06ZNtXr1antHBAAAAADzlamzZ8+qWbNmcnd3V2RkpNLT0xUcHCxJCgwMVHR0tJ0TAgAAAIAJy5Sjo6Ptvw8ePCgPDw+VLFlSkpSUlCRXV1d7RQMAAAAAG9MtQFG2bFn98ccfyp8/v7Zt26batWtLkq5fv67ly5erbNmy9g0IAAAAADLhzFTHjh11/PhxjRo1Sk5OTmrRooUkacSIEYqJiVG7du3snBAAAAAATHqfqZSUFF24cEF+fn5ycXGRJO3cuVP+/v7y8vJ6eK/LfaYA4InHfaYAANJjfJ8pV1dXFSlSRIcPH1ZSUpLc3d1VuXJl5c+f397RAAAAAECSSctUeHi4li5dqvT0/00VOTo66rnnnlPbtm3tmAwAAAAAbjJdmdq4caMWLVqk0NBQhYaGytPTU3FxcdqyZYuWLFmiQoUKKSwszN4xAQAAADzhTFemVq9eraeeekq9e/e2bfP19VVAQICcnJy0du1ayhQAAAAAuzPdan6XL19WUFBQjvtq1qzJTXsBAAAAmILpypS3t7euXLmS477Lly/Lzc3tEScCAAAAgOxMV6Zq1qypxYsX69ixY1m2Hzt2TOHh4apZs6adkgEAAADA/5jumqnWrVvr4MGDGjNmjLy9veXl5aW4uDhdu3ZNxYsXV4cOHewdEfjL+mnSD/p12lSt2RBh7ygAgIdgaOuqGtC8kqr+bX62fUW9XPVBl5pqWqO4fNxddD42WbM3n9KY+QeUlpFpG9ewajHNe7dJjsfvM26Dluw897DiA6ZjujLl5uam999/X5s2bdKRI0eUmJiowoULq1KlSgoNDbXdxBdA3tr4x3pN/NeEh3pjbACA/TStUVzvdAzU1YTUbPtcnR01/90mKl2kgH5efUwnouMVElBEw9oFqlopb/Ue94dtbOWSN78nhv68VSmpGVmOs/tk7MN9E4DJmK5MSZKzs7MaNWqkRo0a2TsK8JdntVr1+39+1ZhRXyo9Pc3ecQAAD8HLz1bUZz1rycXJMef9zSoqwM9LPb9er+W7z0uSJq89pnMxSRrapqqeqlJUGw9dkiRVKemlmPgbmrbu+CPLD5iVacrUH3/8odWrVysmJkZFixZV48aN9dRTT9k7FvCX16dnN+3bu0cNGzXWlSuXdDH6or0jAQDy0PKPmim4QmEt23VOvt6uKl4wf7YxT1cppivXU2xF6pa5W05raJuqql+piK1MVS3prSPn4x5JdsDsTLEARUREhH799VdlZmaqRo0aslgsmj59uhYvXmzvaMBf3sWL0Rox8gtNmPi98ucvYO84AIA8VsInv4b8uEW9/rlBCSnpOY4ZMum/avvF6mzbC3vmkyRlZFht2wL8vBR57rokycXJQU6OloeQGng8mGJmasOGDapVq5YGDBggi+Xm/5AzZ87U6tWr1bp1azunA/7alixbJWeuRQSAv6zaby/KsoBETi5fT9Hl6ynZtg9oHiBJ2hR5c1aqdOEC8nBzVgkfN63+9DlVL+OtzExp7f4LenfaDp2+nJj3bwAwMVPMTEVHRyssLMxWpCSpcePGSk5OvuM9pwDkDYoUAPy13atI3Un/xhXUopaf/jh4UVuP3vz3WJX/v/hEcIXCmv/fM+r7zUZ9veiAnqpSTEs+bKZiXq55lht4HJhiZurGjRtydc36P1/BggUlScnJyfaIBAAA8MTq2qCsRvWro+hryXpt0hbb9tOXEzVq3j4t2HpWh8/dvG5q2a5z2nE8RjOHPaM321bTu9N22Cs28MiZokxJyjIrJUkODjcnzaxWa07DAQAA8BAMfC5AI3vUUmzCDXUetVbnYpJs+w6fi9PhedkXn1i994LOXE7Q01WKPcqogN2ZpkwBAADAvt7tWF3D2wcq+mqSOn61VpHnr+f6uVeu31ARTvPDE8Y0ZWrfvn2Kjo62Pb41I7Vnzx6dPXs2y9iwsLBHmg0AAOCv7q02VTW8faBOXIxXp6/W6syV7ItJvNepuro2KKumHy9X7G03/3V0sKhcMXftP3PtESYG7M80ZWrZsmU5bg8PD8+2jTIFAACQd56p5qv3OtXQyYvxaj1ylS7GZV/ZT5KiYpJUuoi7XmhSUWMXHrBtH/RcgAq659PszaceUWLAHExRpj7//HN7RwAAAHhifdw9SA4OFi3ffV4Nq/lm238o6pr2n7mm/2w4oV4Ny+udjoEqVbiAdp+MVd2KhdX9qXJavfeCft1wwg7pAfsxRZkqVKiQvSMAAAA8kTzzO6tGmZurKA96LiDHMd8sPqj9Z64pI9OqrmPW6f1ONdS6Tkl1e6qszsUkadS8fRq3+KBYNwxPGouV5fJs7nBTcADAE8Tvxd/sHQEAYAIxU3vcc4wpbtoLAAAAAI8byhQAAAAAGECZAgAAAAADKFMAAAAAYIApVvMbPXp0rsdaLBYNGzbsIaYBAAAAgHszRZlycGCCDAAAAMDjxRRl6u2337Z3BAAAAAC4L4/dlNC5c+fsHQEAAAAAzDEzdbuEhATNmzdPR44cUXp6um7dU9hqtSo1NVXJycn6/vvv7ZwSAAAAwJPOdDNTs2bN0qZNm+Tr6ysnJye5u7urfPnykqSUlBT16dPHzgkBAAAAwIQzUwcOHFDr1q31/PPPa9WqVYqMjNSAAQOUkpKi0aNHc5ofAAAAAFMw3cxUUlKSbSaqRIkSOn36tCTJ1dVVzz77rPbt22fPeAAAAAAgyYRlysPDQ8nJyZKkokWL6vr160pISJAkeXt769q1a3ZMBwAAAAA3ma5MVa5cWUuXLtWlS5dUuHBheXh4aPPmzZKkvXv3yt3d3c4JAQAAAMCEZapt27ZKTEzU5MmTJUktWrTQnDlz9MYbb2jt2rVq0KCBfQMCAAAAgEy4AEWhQoX06aefKjo6WpLUtGlTeXh46NixYypXrpxCQ0PtnBAAAAAATFimJMnZ2VmlSpWyPa5Xr57q1atnx0QAAAAAkJXpytTixYvvOaZ169aPIAkAAAAA3NljVaby5csnT09PyhQAAAAAuzNdmZo4cWK2bcnJyYqMjNTMmTPVt29fO6QCAAAAgKxMt5qfg4NDtj8FChRQ7dq11bJlS82ePdveEQEAAADAfGXqbooWLapz587ZOwYAAAAAPD5lKi0tTRs2bJCXl5e9owAAAACA+a6Zevfdd7Nts1qtSkhIUEZGhrp27WqHVAAAAACQlenKVOXKlbNts1gscnV1Vc2aNXPcDwAAAACPmunKVP/+/e+6PyMjQ46Ojo8mDAAAAADcgemumfrHP/6hM2fO5Ljv2LFjGj58+CNOBAAAAADZmWJmatmyZUpNTZUkxcTEaM2aNfLx8ck27sSJE7JarY86HgAAAABkY4oylZmZqSVLltgeb9myJdsYi8UiNzc3tW3b9lFGAwAAAIAcWawmm+oZNGiQhg0bpgoVKjzy105Jf+QvCQAwGb8Xf7N3BACACcRM7XHPMaa7Zurzzz9XuXLldOnSJdu2hIQEHT161I6pAAAAACAr05WpfPnyaezYsRo/frxt28mTJzV27FiNGzdOycnJdkwHAAAAADeZrkzNmTNHMTEx6t69u21btWrV9MYbbyg6OloLFiywYzoAAAAAuMl0ZWr//v3q2LGjAgMDbdscHBxUpUoVtW3bVrt377ZfOAAAAAD4/0xXpm7cuKF8+fLluM/d3V0JCQmPOBEAAAAAZGe6MlW6dGlt3Lgxx30REREqVarUI04EAAAAANmZ4j5Tt2vVqpUmTJigESNGqFatWvL09FR8fLx2796tqKgovf766/aOCAAAAADmu8+UdPO6qUWLFun06dO2baVKlVLbtm1VoUIFubm5PZTX5T5TAADuMwUAkHJ3nynTzUxJUmBgoAIDA5WWlqbExES5ubkpOjpaGzZs0KRJk7Ismw4AAAAA9mDKMnW7gwcPav369bZZKn9/fzsnAgAAAACTlqmLFy9q/fr12rJli5KSkuTj46NWrVopNDRURYoUsXc8AAAAADBPmcrMzNTu3bu1fv16RUZGysnJSYGBgdq9e7deeuklZqQAAAAAmIopytTChQsVERGhuLg4lS5dWt26dVP9+vXl4OCgoUOH2jseAAAAAGRjijK1ZMkS+fn5acCAAVlmoG7cuGHHVAAAAABwZ6YoU2FhYdqxY4fGjh2rChUqKDQ0VHXq1LF3LAAAAAC4I1OUqT59+qhbt27asWOHIiIiNGXKFP3++++qUaOGvaMBAAAAQI5MedPeS5cuKSIiQlu2bFFcXJx8fHxUt25dBQcHq1SpUg/tdblpLwCAm/YCAKTc3bTXlGXqlszMTB04cEAbN27U/v37lZGRIV9fX33yyScP5fUoUwAAyhQAQMpdmTLFaX534uDgoOrVq6t69eqKj4/X5s2btWnTJnvHAgAAAABzz0w9asxMAQCYmQIASLmbmXJ4BDkAAAAA4C+HMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAMoUAAAAABhAmQIAAAAAAyhTAAAAAGAAZQoAAAAADKBMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAMoUAAAAABhAmQIAAAAAAyhTAAAAAGAAZQoAAAAADKBMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAIvVarXaOwQAAAAAPG6YmQIAAAAAAyhTAAAAAGAAZQoAAAAADKBMAQAAAIABlCkAAAAAMIAyBQAAAAAGUKYAAAAAwADKFAAAAAAYQJkCAAAAAAMoUwAAAABgAGUKAAAAAAygTAEAAACAAZQpAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAh5TVqvV3hFMhc8DAG56Ev8+fBLfM8zByd4BAHsYO3asjhw5kmWbk5OTvLy8FBgYqHbt2qlAgQIP5bWvXLmif/zjH+rTp4+eeuopRUZG6uuvv9bQoUNVpUqVXB1j48aNOnfunLp16/bAeRYtWqTFixdr4sSJcnR0zHHM+++/r4SEBH300UcqXLhwtv3vvPOOqlSpov79+z9wHiOOHTum8PBwvfHGG5Jk6DMFAInvh9vl9vshJiYmyzYnJycVKlRIQUFBatOmjZydnR84yy1//kySkpI0c+ZMhYSEqHLlyrZM/v7+eumll/LsdYE7oUzhieXn56eePXvaHqenp+vMmTNasGCBzp49q7///e+yWCwPPUfp0qU1fPhw+fn55fo5S5Yskb+//0NMld2NGzc0ZcoUvfXWW4/kc7kfGzdu1Pnz522PjXymAHAL3w/3p2rVqnr++edtj9PS0hQZGally5YpNjZWL7/8cp691p8/k7Nnz2rz5s2qX7++bcyAAQPk5uaWZ68J3A1lCk8sV1dXVahQIcu2ypUrKy0tTQsXLtTJkydVvnz5h57Dzc0tWw4zyp8/v44cOaI1a9aoadOm9o5zV4/LZwrAnPh+uD/u7u7ZclapUkXXr1/Xpk2b1KVLF3l5eeXJa+XmMylbtmyevBaQG5Qp4E/KlCkjSYqJiVH58uU1duxY+fj4KCMjQ3v37lWJEiX07rvvKi0tTYsWLdLWrVsVHx+vIkWK6LnnnlNoaGiW40VERGjFihWKiYmRn5+fWrdunWV/TqdxnDp1SgsXLtTx48fl6OioSpUqqVOnTipSpIgGDhxoy7d161b98MMPkqTz589r7ty5Onr0qKxWqypVqqTOnTvL19fX9lrJycmaPXu2du/erfT0dNWvXz/Xv70LDAxUfHy85s2bp8DAQBUrVuyu4yMiIrRq1SpdunRJ7u7uCgkJUZs2beTk9L+/dvbt26eFCxfqwoUL8vHxUbt27TRv3jzVr19fbdq0kSRFRUVp0aJFOnbsmJKSkuTp6amgoCB16tRJLi4uWU7JGThwoN566y1Jsn2mLi4uGjVqlAYPHqygoCDba8fGxur9999X79699dRTT+X65wngycX3w/1/XhEREYqNjZWXl5cyMzP1xx9/aP369bbvhuDgYLVt21YuLi6SpISEBM2aNUsHDx5UUlKSihQpooYNG6pJkybZPpOrV69qypQpkqRx48YpNDRU/fv3z3Ka30cffSRfX1+9+uqrWbJ9/fXXSk9P19///ndJ0p49e7RkyRKdO3dOrq6uqlWrljp27MgMF+6JBSiAP4mOjpYkFS1a1LZt27ZtSktL06BBg9SyZUtJ0g8//KC1a9eqUaNGGjRokCpWrKjJkydr3bp1tudt2LBBU6dOVYUKFTRw4EAFBgZq0qRJd339qKgojR49WomJierTp4969+6t6OhojRs3TqmpqRo+fLg8PT1VtWpVDR8+XJJ06dIljRo1SlevXlXv3r3Vp08fXbt2TaNGjVJsbKykmxfnTpgwQTt37lTr1q31wgsv6PLly1q1alWuP5u+ffvKyclJkydPVmZm5h3HLV++XFOnTpW/v78GDRqkJk2aaPXq1fr5559tYyIjIzVx4kR5e3vrlVdeUcOGDTV16lRdvXrVNiYuLk6jR49WcnKy+vTpoyFDhqh27dpat26dVq5cKUnq3r27AgMD5eHhoeHDh6t06dJZsvj7+6to0aLaunVrlu1bt26Vk5OT6tSpIyl3P08ATza+H4x9XkWKFJEkTZ8+Xb///ruqVaumQYMGqWHDhlq3bp2+/fZb2wIS//73v3X69Gl17dpVQ4YMUUBAgGbMmKH//ve/2Y4fGBhouzasS5cuts//diEhITpw4ICSkpJs265du6YjR44oJCREkrR9+3Z999138vHx0SuvvKI2bdpox44dGj9+vDIyMh7oM8BfHzNTeKLd/pdkYmKijh49ajvf/PZ/lFutVvXv39/2G6pDhw5p37596t+/v+03jdWrV1dmZqYWLFigBg0ayNnZWYsXL1bNmjXVp08f2xgHBwctXLjwjpmWLFkiNzc3vfnmm3J1dZUk+fr6avz48Tp58qQCAgLk7Oyc5bSKRYsWycHBQW+99ZbtwujAwEB98MEHWrJkiXr37q2DBw/q+PHjGjRokGrVqiVJqlGjhj755BNdvHgxV5+Xj4+PunTpoqlTp2rlypV67rnnso1JTk7W4sWL1aBBA/Xu3dv2vgsWLKiffvpJx48fl7+/vxYuXChfX18NHjxYDg43f6/j6empn376yXasqKgolShRQoMGDVL+/PklSdWqVdPhw4d15MgRPf/88/Lz85OHh4ccHR3veOpHSEiIli5dqpSUFNtnunXrVtWoUUNubm65+nne+q0pgCcD3w/39/1w++cVHx+v/fv3a8OGDapbt67c3d11/vx5RUREqE2bNrYZuMDAQBUsWFCTJ0/W3r17VbNmTR07dkytWrVS3bp1Jd08XTB//vw5zhB5enrarp3y8/PL8YyJkJAQLVy4ULt27VJYWJikmwXY0dFRwcHBslqtmj17tipVqmSb2bt1vNGjR2vHjh2qV69erj4DPJkoU3hiHT9+PNu0v8ViUZUqVdSnT58sFxcXKlQoy1/khw8fliTVrFkzyxdIrVq1tHHjRp06dUqenp6Ki4vLcmqZJNWrV++uX5ZHjx5VtWrVbF+UklSiRAl9+eWXd3zO4cOHFRAQIFdXV1seFxcXValSRQcPHpQkHTlyRA4ODqpRo4bteQ4ODgoODlZ4ePgdj/1nYWFh2rVrlxYuXKjq1aurRIkSWfafOHFCqampCgoKyvLZ1KhRQxaLRQcPHlTp0qV14sQJtWrVylakJKlOnTr65ZdfbI+rVaumatWqKTMzUxcvXtSlS5d09uxZJSQk2MpVbtSvX1+LFi3S7t27FRISonPnzuncuXPq0KGD7fOT7v7zrFSpUq5fD8Djje+H+/t+2Lp1a7bZf0dHR9WuXdu2kMfRo0dt7/HP73nq1KmKjIxUzZo1VaVKFS1atEjnzp1TtWrVVLVqVbVr1+6eGe7Ex8dHFStW1NatW21l6tYv0/Lnz6/o6GhdvXpVzZs3z/LzKleunLy8vHTw4EHKFO6KMoUnVsmSJW2/EbRYLHJ2dpaPj0+WL6lbPD09szxOSEiQJL355ps5HvvatWu2ZWQ9PDyy7PP29r5rroSEhGzPuZeEhATt3Lkz25e/JFuOWwXkz8vbGrkouHfv3vr00081efJkvfPOO9mySNLEiRNzfO61a9eUlJSkzMxMubu7Z8t6+7bMzEwtXLhQa9euVUpKigoWLKhy5crJ2dn5vu4pUrhwYVWsWFHbtm1TSEiItm7dKg8PD1WtWjVL5rv9PAE8Ofh+uCm33w+BgYG261wtFotcXFxUuHDhLEuiJyYmSsr+ed36ez85OVmS9NJLL2nFihXavn27tm/fLovFIn9/f/Xs2dPwCq2hoaGaOnWq4uLilJycrDNnzthmx279vGbMmKEZM2Zkey5//+NeKFN4YuXLl8/wij9ubm5ydnbWsGHDctxfuHBh2xdHXFxcln23/uK+k/z58+c45sCBAypevLh8fHxyfE5AQICaN29+x+N6eHgoMTFRGRkZWb4w75UnJ97e3urWrZt++eUXLVu2LFsWSXrhhReyXNx8i7u7uzw8POTk5KT4+Pgs+zIzM7PkWbZsmZYvX66+ffsqKCjI9tvfL7744r4zh4SEaPr06UpMTNS2bdtUt25d2+eQm58ngCcH3w+5y3P7a9zr87p1iuH169ezlNKMjAwlJCTYfpHm6uqqtm3bqm3btoqNjdWePXsUHh6uf//73/r4449zlefPateurd9++007d+5UfHy8PDw8FBgYaMsuSR06dLDdp+p2ORVo4HYsQAEYEBAQoLS0NGVkZKhs2bK2P5cuXdKCBQuUmpqqYsWKqVChQtq+fXuW5+7evfuux65QoYIOHDig1NRU27ZLly5p/PjxioyMlKRs9zepVKmSzp8/r1KlSmXJs3btWtupF1WqVJHVas2WZ8+ePYY+g5CQEAUFBSk8PNz2DwPp5qkRTk5Oio2NzZLFzc1Ns2fP1oULF+Tg4CB/f3/t2rUrywzT7t27syxscfz4cfn6+io0NNRWpK5evapz585led7tpwreSZ06deTo6KhFixYpJiYmy6paufl5AkBu8P2Qs4oVK0pSjosBZWZmqkKFCoqJidG7775ry+Hj46PGjRurTp062W4MfEtu/v53dXVVUFCQdu/erZ07dyo4ONhWGn19feXp6anLly9n+XwKFy6suXPn6sSJEw/ytvEEYGYKMKBatWqqVKmSvvvuO7Vs2VIlSpTQmTNntHjxYvn7+9t+O9ipUydNmjRJ//73v1W/fn2dP39ey5cvv+uxn3/+eX311Vf65ptv1LRpU2VmZmrx4sUqXry4ateuLenmb9KioqJ06NAhBQQEqHXr1vrqq680btw4PfPMM8qXL58iIiK0c+dOvfDCC5JufsFXr15dv/76q65fvy5fX19t2rRJFy5cMPw59OrVS5988kmWMuXu7q7nnntOixcvVnJysipXrqzr169r8eLFSktLsy0t3KZNG40dO1bfffedwsLCFBsbq8WLF0v63z8GypYtqwMHDig8PFzly5fX5cuXtWzZMqWnp2f5x4Sbm5sSEhK0d+/eO9775daX6fr161WiRIksF5Dn9ucJAPfC90POSpQoodDQUIWHhys1NVWVKlVSVFSUwsPDVbFiRdsCHAULFtTvv/+uxMREFS1aVBcuXNDmzZsVHByc43FvzSzt379fXl5e2a7jvSU0NFQTJkxQZmam+vfvb9vu4OCg9u3ba9q0aZKkoKAg3bhxQ8uWLdPly5fVo0ePPPsM8NdEmQIMcHBw0Ouvv66FCxdq5cqVio+Pl5eXlxo1apTlPiF16tSRxWJReHi4vv/+exUtWlQvvviiJkyYcMdjly5dWsOGDdO8efP0yy+/KF++fKpSpYo6deqkfPnySZJatmypX3/9Vd99950++ugj+fn5afjw4VqwYIGmTp0qq9Wq4sWLa8CAAbalv6Wb92GaN2+eVqxYoZSUFFWvXl2tWrXS/PnzDX0Onp6e6tmzZ7blfNu2bStvb2+tXbtWa9askZubmwICAtS+fXvb+fIVK1bUoEGDtHDhQv34448qVKiQevbsqR9//NH2Plu0aKGEhAStW7dOS5culY+Pj0JCQuTo6Kjw8HDbqSENGzbUvn379MMPP6hfv353PM8/NDTUdt3U7XL78wSAe+H74c769u2rokWL2u5D6O3trcaNG6t169a2GabBgwdr/vz5WrJkiRISEuTl5WUbk5PixYsrJCRE69atU3R0tF5//fUcx1WuXFmenp5yc3PLdkpiWFiY3NzctHz5cm3ZskX58uVTuXLl1LdvXxUvXjzP3j/+mizW+7mKGwDyyM6dO+Xj45PlS+3cuXMaMWKEXnvttSyrSgEAAJgRM1MA7CIyMlJbt25Vhw4dVKxYMV29elXLli1T8eLFVaVKFXvHAwAAuCdmpgDYRVpamhYsWKCdO3cqLi5O+fPnV/Xq1dWhQ4f7XvoXAADAHihTAAAAAGAAS6MDAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAMoUAAAAABhAmQIA3NW7776rgICALH+qVKmi2rVrq2PHjpo6daoyMzMfeo4NGzYoICBAc+fOtW0LCAjQm2++ed/HSkhI0OXLl/Ms22+//aaAgAD997//veOYqKgoBQQEaMyYMfd9/D59+igsLOxBImYxYcIEBQQE6Pjx43l2TAB4EnHTXgBArrz33nsqWLCgJMlqtSopKUmrVq3S559/rqioKL3//vuPPNOoUaPk5+d3X8/Zv3+/Bg8erM8//1xFihR5SMkAAE8CyhQAIFeeffZZlSxZMsu2bt26qVu3bpo+fbpefvllFS1a9JFmateu3X0/58iRI7p06dJDSAMAeNJwmh8AwDBHR0e1atVKGRkZ2rNnj73jAADwSFGmAAAPxMHh5ldJWlqapJvXWDVr1kyzZs1S/fr1VadOHS1cuFCSdP36dY0cOVKNGjVSYGCgmjVrpm+//db23FuuXr2qDz74QA0aNFCtWrX09ttvKzExMdtr53TN1ObNm9W/f3/VqVNH9evX16BBgxQZGSnp5rVC7733niTplVdeUZMmTWzPu3jxot577z01aNBAgYGBat26tX799ddsrxkVFaWhQ4eqfv36Cg4O1meffab09HRDn116erp++ukndejQQbVq1VKNGjXUqlUrTZo0Kcfr0P744w+1adNGgYGBatmypaZPn55tTG7fBwDgwXGaHwDggWzZskWSVK1aNdu2S5cuacyYMRo0aJDi4uJUp04dJSUlqVevXoqKilKPHj1UqlQp7dq1S+PHj9eBAwf07bffymKxKDU1VX379tWJEyfUq1cvlSpVSosXL9aHH354zyzLli3Tm2++qbJly2rQoEFydHTU1KlT1adPH82ZM0fNmjXT5cuXNWPGDL300kuqXbu2pJsFpHPnzkpPT1ePHj1UqFAhbdy4USNGjNDJkyf1wQcfSJJiY2PVvXt3JSYmql+/fvLy8tLs2bO1YMECQ5/dBx98oPnz56tr167q0aOH4uPjNW/ePI0ZM0Y+Pj7q1KmTbWxcXJxeffVVdejQQd26ddOyZcv02Wef6dq1axoyZMh9vQ8AQN6gTAEAcuX69euKjY2VJGVmZio6Olpz587V2rVr1axZM5UpU8Y2NiUlRe+884569uxp2zZhwgQdP35cv//+u2rUqCFJ6tGjh6pWraovvvhCa9euVZMmTTR79mwdOXJEI0eOVJcuXSRJ3bt3V//+/bV9+/Y75svMzNTIkSNVvHhxzZkzR/nz55ckNWrUSK1bt9b06dP13nvvKSgoSDNmzFBISIgaNmwoSfrnP/+ppKQkLViwwHZdWK9evTRy5EhNmzZNnTt3VuXKlfXTTz/p8uXLmjx5skJDQyVJXbp0UadOnRQfH39fn+eVK1e0YMEC9e7dO0vJ6dixoxo0aKCVK1dmKVNpaWl699139cILL9g+u169eun7779Xz5495ePjk+v3AQDIG5zmBwDIlQ4dOig0NFShoaEKCwtTp06dNGPGDLVt21ZffvlltvFPP/10lscrVqxQ+fLlVbJkScXGxtr+NG3aVBaLRWvXrpUkrV+/Xvnz51eHDh1sz3V2dlavXr3umm///v26fPmyunbtaitSkuTv7685c+Zo0KBBOT4vMzNTq1atUq1atZQ/f/4s2Vq0aCFJWrdunS1b+fLlbUVKktzd3dW5c+e7ZstJ4cKFtX37dr311ltZtsfHx6tAgQJKSkrKsr1AgQJZPgNHR0f16tVLaWlp2rRp0329DwBA3mBmCgCQK6NHj1bhwoUlSRaLRR4eHipfvnyW4nK7QoUKZXl8+vRp3bhxI0sRud358+cl3bwmqUSJEnJyyvoV5e/vf9d8586dkySVLl06276qVave8XmxsbGKj4/XH3/8kats9erVy7b/XtnuJF++fFq6dKn++OMPnTp1SqdPn9a1a9ck3Vx+/nYlS5aUi4tLlm23ZgPPnTt3X+8DAJA3KFMAgFypXbt2tqXR78bR0THL48zMTNWsWVNDhw7Ncbynp6ftv/9cJO607c/Hl24WlPtx63lNmjRRnz59chxza8l3i8WSYw4jNy1OTU3VK6+8ov/+97+2hTp69uypOnXqqGvXrtnG31roI6fXdXJyuq/3AQDIG5QpAMAj4efnp+vXr6tBgwZZtt+4cUOrV6+Wr6+vJKlUqVLasmWLUlNTs8zEnDlz5q7HL1GihKSbM2B/9tVXX8nDw0Ovvvpqtn0+Pj5yc3NTampqtmyxsbHatm2bbQaoZMmSOnnyZLZjnD179q7ZcrJkyRJt2bJFH330UZbT91JTU3O8/urChQvKyMjIUlJvZSlTpsx9vQ8AQN7gmikAwCPRtGlTnTx5UsuXL8+yferUqXrzzTe1efNmSVLz5s2VnJysadOm2cZkZmbmuAz47QIDA1WkSBHNnTtXycnJtu2nTp3StGnTFBMTI+l/Mzy3ZpicnJzUqFEjbdq0SXv37s1yzPHjx+tvf/ubjh07Zst29uxZLVu2zDYmNTVVM2bMuK/PQpLtdL4KFSpk2T59+nSlpaVlW2792rVr2V536tSpcnd3V0hIyH29DwBA3mBmCgDwSAwcOFArV67UW2+9pS5duqhKlSo6cOCAZs2apcDAQHXs2FGS1K5dO82ZM0ejR4/W6dOnFRAQoBUrVujIkSN3Pb6zs7Pef/99vfXWW+ratas6duyo9PR0TZ8+Xd7e3ho4cKAk2a77mjFjhq5fv642bdpo2LBh+u9//6t+/fqpR48eKlOmjLZs2aIlS5bomWeesS2m8eKLL2rx4sUaNmyY9uzZo+LFi2v+/Pm2YnQ/wsLCbJl79+4tV1dXbdq0SStWrFC+fPmy3VfLy8tLH3zwgSIjI1W0aFEtXLhQBw8e1MiRI+Xu7i5JuX4fAIC8QZkCADwSXl5emjFjhsaPH681a9Zo9uzZKlasmPr27avBgwfLzc1N0s1rrSZNmqRvvvlG4eHhWrBggerXr6+vvvpKAwYMuOtrtGrVSh4eHpo4caLGjRunAgUKqF69enr77bdt1wuFhISodevWWrVqlbZv367mzZurVKlSmjVrlsaPH6/58+crPj5eJUqU0Ouvv66XX37ZNptVoEAB/fbbbxo9erTmzZunGzduqEmTJurXr5/+/ve/39fnUbFiRf3rX//S+PHj9c0338jNzU3lypXTt99+q82bN+u3337T5cuXVaRIEUlS2bJl9dJLL+mf//ynoqKiVL58eX3zzTe2lfok5fp9AADyhsV6ryt6AQAAAADZ8CsqAAAAADCAMgUAAAAABlCmAAAAAMAAyhQAAAAAGECZAgAAAAADKFMAAAAAYABlCgAAAAAMoEwBAAAAgAGUKQAAAAAwgDIFAAAAAAZQpgAAAADAAMoUAAAAABhAmQIAAAAAA/4fMKqo2csqG3kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_trimmed, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Display Confusion Matrix as a nicely formatted table\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "            xticklabels=['Predicted Negative', 'Predicted Positive'], \n",
    "            yticklabels=['Actual Negative', 'Actual Positive'])\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad54d1b",
   "metadata": {},
   "source": [
    "**Breakdown of the Confusion Matrix:**\n",
    "\n",
    "  - **TN (151):**\n",
    "    - This value represents the number of instances where the actual label was negative (i.e., the SPY ETF did not experience an uptrend), and the model correctly predicted it as negative. In this case, 151 out of all test  instances were correctly identified as negatives.\n",
    " - **FP (32):**\n",
    "   - This value represents the number of instances where the actual label was negative, but the model incorrectly predicted it as positive. These are the false positives. In this case, the model incorrectly predicted an uptrend in 32 instances where there was none.\n",
    " - **FN (1):**\n",
    "   - This value represents the number of instances where the actual label was positive (i.e., the SPY ETF experienced an uptrend), but the model incorrectly predicted it as negative. This is a false negative. Here, the model failed to identify 1 actual uptrend.\n",
    "- **TP (125):**\n",
    "  - This value represents the number of instances where the actual label was positive, and the model correctly predicted it as positive. The model correctly identified 125 uptrends.\n",
    "\n",
    "**Interpretation of the Results:**\n",
    "\n",
    "  - **High True Positives (TP = 125):**\n",
    "    - The model is highly effective at identifying uptrends, correctly predicting 125 out of the 126 actual uptrends (TP + FN). This indicates that the model is very sensitive (high recall) and is adept at capturing most of the actual positive signals.\n",
    "  - **Low False Negatives (FN = 1):**\n",
    "    - The model has a very low number of false negatives, meaning it rarely misses an uptrend when one actually occurs. This low number is crucial for the trading strategy as it minimizes missed opportunities.\n",
    " - **Moderate False Positives (FP = 32):**\n",
    "   - There is a moderate number of false positives, where the model incorrectly predicted an uptrend when there wasn't one. In the context of trading, this could lead to entering positions that may not be profitable, which could affect overall portfolio performance.\n",
    "- **High True Negatives (TN = 151):**\n",
    "  - The model also performs well in identifying periods where there is no uptrend, with 151 correct predictions out of 183 (TN + FP) actual negative instances. This helps avoid unnecessary trades, reducing the potential for losses from entering positions at the wrong time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2013b81",
   "metadata": {},
   "source": [
    "#### Classification Report of the Best Model (LSTM Single Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e80004cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.83      0.90       183\n",
      "         1.0       0.80      0.99      0.88       126\n",
      "\n",
      "    accuracy                           0.89       309\n",
      "   macro avg       0.89      0.91      0.89       309\n",
      "weighted avg       0.91      0.89      0.89       309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "report = classification_report(y_test_trimmed, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f03ec",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    " - **Class  (No Uptrend):**\n",
    "     - The model exhibits very high precision, indicating a strong ability to avoid false positives when predicting no uptrend. However, with a recall of 0.83, it may occasionally miss true \"No Uptrend\" signals.\n",
    " - **Class 1 (Uptrend):**\n",
    "   - The model has a very high recall of 0.99, meaning it rarely misses an actual uptrend, which is essential for trading strategies that rely on capturing upward movements. The precision is lower at 0.80, suggesting that some predicted uptrends might be false alarms.\n",
    " - **Balanced Performance:**\n",
    "   - The high recall for Class 1.0 (uptrend) ensures that the model captures almost all opportunities, which is critical in financial trading. The slightly lower precision indicates that some caution is needed, as not all predicted uptrends will materialize.\n",
    "\n",
    "- Overall, this classification report highlights that the model is particularly effective at identifying true uptrends, with a very high recall rate, making it well-suited for trading strategies where capturing upward movements is more critical than avoiding false positives. The slight trade-off in precision for uptrends is balanced by the high recall, ensuring that most opportunities are not missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27949b29",
   "metadata": {},
   "source": [
    "#### Balanced Accurcay of the Best Model (LSTM Single Layer)\n",
    "\n",
    "\n",
    "**Balanced Accuracy** is a metric that provides a more nuanced view of a model's performance, especially when dealing with imbalanced datasets. It is the average of the true positive rate (TPR) and true negative rate (TNR), offering a balance between sensitivity and specificity.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "\\text{Balanced Accuracy} = \\frac{\\text{TPR} + \\text{TNR}}{2}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- **TPR (True Positive Rate)**: Also known as recall, it measures the proportion of actual positives that are correctly identified by the model.\n",
    "- **TNR (True Negative Rate)**: It measures the proportion of actual negatives that are correctly identified by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "55f1656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.9086\n"
     ]
    }
   ],
   "source": [
    "# Balanced Accuracy\n",
    "balanced_acc = balanced_accuracy_score(y_test_trimmed, y_pred)\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6e2aa",
   "metadata": {},
   "source": [
    "**Interpretation of Balanced Accuracy: 0.9086**\n",
    "\n",
    "  - **Value Interpretation:**\n",
    "    - A balanced accuracy of 0.9086 indicates that, on average, the model correctly identifies approximately 90.86% of both the positive and negative classes. \n",
    "    - This is a strong indicator of the model’s ability to handle both classes well, particularly in a situation where the dataset may be imbalanced.\n",
    "    \n",
    "    \n",
    "- Overall, a balanced accuracy of 0.9086 suggests that the model performs very well across both positive and negative classes, making it reliable for use in the trading strategy where both capturing uptrends and avoiding false signals are critical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f140b",
   "metadata": {},
   "source": [
    "#### ROC-AUC Analysis\n",
    "  - The Receiver Operating Characteristic (ROC) curve is a graphical representation that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. \n",
    "  - The Area Under the ROC Curve (AUC) is a single scalar value that summarizes the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f8c8df07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9606\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# AUC\n",
    "auc = roc_auc_score(y_test_trimmed, y_pred_prob)\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test_trimmed, y_pred_prob)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207146e",
   "metadata": {},
   "source": [
    "**Interpretation of the ROC-AUC in the Graph:**\n",
    "\n",
    "  - **AUC = 0.9606:** This indicates that the model has a strong ability to distinguish between the positive and negative classes, with an AUC value close to 1. The model can correctly classify positive cases 96.06% of the time, which is a very good performance.\n",
    "  - The ROC curve in the image shows that the model performs significantly better than random guessing (represented by the diagonal dashed line), as the curve is much closer to the top left corner, indicating high sensitivity and low FPR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c83f74",
   "metadata": {},
   "source": [
    "###  Saving y_pred (model's predictions) on the test data as Signal to use in Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1d44d4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>yield_spread</th>\n",
       "      <th>VXX_daily_return</th>\n",
       "      <th>UUP_daily_return</th>\n",
       "      <th>volume_tech</th>\n",
       "      <th>ADOSC_3_10</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>AOBV_SR_2</th>\n",
       "      <th>...</th>\n",
       "      <th>PIVOTS_TRAD_D_P</th>\n",
       "      <th>PIVOTS_TRAD_D_R3</th>\n",
       "      <th>PSL_12</th>\n",
       "      <th>PVOL</th>\n",
       "      <th>PVT</th>\n",
       "      <th>SLOPE_1</th>\n",
       "      <th>SMCtp_14_50_20_5</th>\n",
       "      <th>STDEV_30</th>\n",
       "      <th>Target</th>\n",
       "      <th>Signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.009178</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>65200243.0</td>\n",
       "      <td>9.755913e+07</td>\n",
       "      <td>13.795051</td>\n",
       "      <td>-1.829899e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>409.276667</td>\n",
       "      <td>418.636667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2.657562e+10</td>\n",
       "      <td>-1.296695e+10</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>-1.112537</td>\n",
       "      <td>6.497442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2023-04-06</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.017623</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>63743345.0</td>\n",
       "      <td>1.018255e+08</td>\n",
       "      <td>14.138402</td>\n",
       "      <td>4.544436e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>407.393333</td>\n",
       "      <td>413.033333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2.608314e+10</td>\n",
       "      <td>-1.294209e+10</td>\n",
       "      <td>1.59</td>\n",
       "      <td>-9.946714</td>\n",
       "      <td>6.806184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.009660</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>63681042.0</td>\n",
       "      <td>1.137047e+08</td>\n",
       "      <td>14.491270</td>\n",
       "      <td>1.091254e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>408.116000</td>\n",
       "      <td>415.720000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.608439e+10</td>\n",
       "      <td>-1.293555e+10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-16.918295</td>\n",
       "      <td>7.118465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2023-04-11</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.009754</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>59297945.0</td>\n",
       "      <td>1.027176e+08</td>\n",
       "      <td>15.066452</td>\n",
       "      <td>1.684233e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>408.423333</td>\n",
       "      <td>415.863333</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.429555e+10</td>\n",
       "      <td>-1.293396e+10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-24.431616</td>\n",
       "      <td>7.406816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>-0.004076</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>-0.005396</td>\n",
       "      <td>86420379.0</td>\n",
       "      <td>6.847982e+07</td>\n",
       "      <td>15.217157</td>\n",
       "      <td>8.200296e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>409.940000</td>\n",
       "      <td>414.460000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>3.526384e+10</td>\n",
       "      <td>-1.296918e+10</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-27.228810</td>\n",
       "      <td>7.578515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>2024-06-24</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.007972</td>\n",
       "      <td>-0.003436</td>\n",
       "      <td>45528654.0</td>\n",
       "      <td>3.742017e+07</td>\n",
       "      <td>26.137312</td>\n",
       "      <td>1.641817e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>544.393333</td>\n",
       "      <td>549.653333</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>2.471022e+10</td>\n",
       "      <td>-1.149704e+10</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>-7.034976</td>\n",
       "      <td>7.967939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>0.003851</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>38273346.0</td>\n",
       "      <td>3.392215e+07</td>\n",
       "      <td>26.493766</td>\n",
       "      <td>1.680090e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>544.103333</td>\n",
       "      <td>552.763333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2.085247e+10</td>\n",
       "      <td>-1.148231e+10</td>\n",
       "      <td>2.09</td>\n",
       "      <td>-10.189487</td>\n",
       "      <td>7.897289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.010909</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>38550637.0</td>\n",
       "      <td>3.609444e+07</td>\n",
       "      <td>27.023626</td>\n",
       "      <td>1.718641e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>544.156667</td>\n",
       "      <td>549.676667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.102976e+10</td>\n",
       "      <td>-1.147750e+10</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-20.033204</td>\n",
       "      <td>7.778476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.006434</td>\n",
       "      <td>-0.001371</td>\n",
       "      <td>35041480.0</td>\n",
       "      <td>3.925285e+07</td>\n",
       "      <td>27.653751</td>\n",
       "      <td>1.753682e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>544.926667</td>\n",
       "      <td>551.346667</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.914561e+10</td>\n",
       "      <td>-1.147197e+10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-25.013835</td>\n",
       "      <td>7.748247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>2024-06-28</td>\n",
       "      <td>-0.003935</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76144535.0</td>\n",
       "      <td>2.114413e+07</td>\n",
       "      <td>28.820181</td>\n",
       "      <td>1.677537e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>545.980000</td>\n",
       "      <td>550.680000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>4.143938e+10</td>\n",
       "      <td>-1.150193e+10</td>\n",
       "      <td>-2.15</td>\n",
       "      <td>-39.769611</td>\n",
       "      <td>7.824571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  daily_return  yield_spread  VXX_daily_return  \\\n",
       "1437 2023-04-05     -0.002618         -0.49         -0.009178   \n",
       "1438 2023-04-06      0.003901         -0.52         -0.017623   \n",
       "1439 2023-04-10      0.001026         -0.59         -0.009660   \n",
       "1440 2023-04-11      0.000269         -0.60         -0.009754   \n",
       "1441 2023-04-12     -0.004076         -0.54          0.006098   \n",
       "...         ...           ...           ...               ...   \n",
       "1741 2024-06-24     -0.003251         -0.46         -0.007972   \n",
       "1742 2024-06-25      0.003851         -0.42         -0.017857   \n",
       "1743 2024-06-26      0.001248         -0.39         -0.010909   \n",
       "1744 2024-06-27      0.001577         -0.41         -0.006434   \n",
       "1745 2024-06-28     -0.003935         -0.35          0.010176   \n",
       "\n",
       "      UUP_daily_return  volume_tech    ADOSC_3_10     ADX_14           OBV  \\\n",
       "1437          0.002894   65200243.0  9.755913e+07  13.795051 -1.829899e+07   \n",
       "1438          0.000722   63743345.0  1.018255e+08  14.138402  4.544436e+07   \n",
       "1439          0.005768   63681042.0  1.137047e+08  14.491270  1.091254e+08   \n",
       "1440         -0.003584   59297945.0  1.027176e+08  15.066452  1.684233e+08   \n",
       "1441         -0.005396   86420379.0  6.847982e+07  15.217157  8.200296e+07   \n",
       "...                ...          ...           ...        ...           ...   \n",
       "1741         -0.003436   45528654.0  3.742017e+07  26.137312  1.641817e+09   \n",
       "1742          0.001034   38273346.0  3.392215e+07  26.493766  1.680090e+09   \n",
       "1743          0.004823   38550637.0  3.609444e+07  27.023626  1.718641e+09   \n",
       "1744         -0.001371   35041480.0  3.925285e+07  27.653751  1.753682e+09   \n",
       "1745          0.000000   76144535.0  2.114413e+07  28.820181  1.677537e+09   \n",
       "\n",
       "      AOBV_SR_2  ...  PIVOTS_TRAD_D_P  PIVOTS_TRAD_D_R3     PSL_12  \\\n",
       "1437        0.0  ...       409.276667        418.636667  66.666667   \n",
       "1438        0.0  ...       407.393333        413.033333  66.666667   \n",
       "1439        0.0  ...       408.116000        415.720000  75.000000   \n",
       "1440        0.0  ...       408.423333        415.863333  75.000000   \n",
       "1441        0.0  ...       409.940000        414.460000  66.666667   \n",
       "...         ...  ...              ...               ...        ...   \n",
       "1741        1.0  ...       544.393333        549.653333  58.333333   \n",
       "1742        1.0  ...       544.103333        552.763333  66.666667   \n",
       "1743        0.0  ...       544.156667        549.676667  75.000000   \n",
       "1744        0.0  ...       544.926667        551.346667  75.000000   \n",
       "1745        0.0  ...       545.980000        550.680000  66.666667   \n",
       "\n",
       "              PVOL           PVT  SLOPE_1  SMCtp_14_50_20_5  STDEV_30  Target  \\\n",
       "1437  2.657562e+10 -1.296695e+10    -1.07         -1.112537  6.497442     0.0   \n",
       "1438  2.608314e+10 -1.294209e+10     1.59         -9.946714  6.806184     1.0   \n",
       "1439  2.608439e+10 -1.293555e+10     0.42        -16.918295  7.118465     0.0   \n",
       "1440  2.429555e+10 -1.293396e+10     0.11        -24.431616  7.406816     0.0   \n",
       "1441  3.526384e+10 -1.296918e+10    -1.67        -27.228810  7.578515     0.0   \n",
       "...            ...           ...      ...               ...       ...     ...   \n",
       "1741  2.471022e+10 -1.149704e+10    -1.77         -7.034976  7.967939     0.0   \n",
       "1742  2.085247e+10 -1.148231e+10     2.09        -10.189487  7.897289     1.0   \n",
       "1743  2.102976e+10 -1.147750e+10     0.68        -20.033204  7.778476     0.0   \n",
       "1744  1.914561e+10 -1.147197e+10     0.86        -25.013835  7.748247     0.0   \n",
       "1745  4.143938e+10 -1.150193e+10    -2.15        -39.769611  7.824571     0.0   \n",
       "\n",
       "      Signal  \n",
       "1437       0  \n",
       "1438       0  \n",
       "1439       0  \n",
       "1440       0  \n",
       "1441       1  \n",
       "...      ...  \n",
       "1741       0  \n",
       "1742       1  \n",
       "1743       1  \n",
       "1744       0  \n",
       "1745       0  \n",
       "\n",
       "[309 rows x 27 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'df' is our original DataFrame containing all the data\n",
    "# y_pred is our best model's predictions on the test data\n",
    "\n",
    "# Ensure the length of y_pred matches the length of the test portion\n",
    "# Create a DataFrame for the test data (last 309 rows)\n",
    "df_test = df.iloc[-len(y_pred):].copy()\n",
    "\n",
    "# Add the predictions as a new column\n",
    "df_test['Signal'] = y_pred  # 1 for buy, 0 for sell\n",
    "\n",
    "df_test.to_csv(\"LSTM_Model_Signal_Test_Data.csv\", index = True )\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf91f7",
   "metadata": {},
   "source": [
    "- **Adding the Prediction as [Signals]:**\n",
    "   -  New column, Signal, to df_test. This column contains the predictions (y_pred) from our best model. Each row in this column indicates the model's signal for that particular day:\n",
    "      - 1: Buy Signal\n",
    "      - 0: Sell Signal\n",
    "\n",
    "  - Saving the DataFrame:\n",
    "      - The df_test DataFrame, now including the model's signals, is saved to a CSV file named LSTM_Model_Signal_Test_Data.csv. \n",
    "      - This file can be used for further analysis, such as backtesting trading strategies based on the model's signals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503448dc",
   "metadata": {},
   "source": [
    "#### Please Note that Complete Trading Strategy Logic and Backtesting Part is in Notebook-3 (DL-NayanP-Notebook-3) ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574926d",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076da9d",
   "metadata": {},
   "source": [
    "#### CQF Program Materials\n",
    "\n",
    "#### Kannan Singaravelu, CQF\n",
    "- 1.JA24P1 Introduction to Financial Times Series. Certificate in Quantitative Finance (CQF) Program, 2024.\n",
    "- 2.JA24P9 Introduction to Machine Learning using Scikit-learn. Certificate in Quantitative Finance (CQF) Program, 2024.\n",
    "- 3.JA24P10 Trend Prediction using Logistic Regression. Certificate in Quantitative Finance (CQF) Program, 2024.\n",
    "- 4.JA24P13 Application of Neural Networks using TensorFlow & Keras. Certificate in Quantitative Finance (CQF) Program, 2024. \n",
    "- 5.Advanced Machine Learning Workshop Notes and Python Files. Certificate in Quantitative Finance (CQF) Program**\n",
    "- 6.CQF Final Project Tutorial III - Deep Learning & Machine Learning. Certificate in Quantitative Finance (CQF) Program, 2024\n",
    "\n",
    "\n",
    "#### Python Libraries:\n",
    "- 1.Pandas: Used for Data manipulation and analysis.\n",
    "- 2.NumPy: Utilized for numerical operations.\n",
    "- 3.Matplotlib & Seaborn: Used for data visualization.\n",
    "- 4.Scikit-Learn: Used for various machine learning tasks.\n",
    "- 5.TensorFlow & Keras: Core libraries for building, training, and optimizing the Long Short-Term Memory (LSTM) models.\n",
    "- 6.Keras Tuner: Used for hyperparameter tuning.\n",
    "- 7.SciPy: Utilized for advanced statistical functions and operations.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
